{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1b2f81-642d-40dc-9ddc-5b2989081b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__learning_rate': 1.0, 'classifier__n_estimators': 150}\n",
      "Testing Set Accuracy: 0.9900497512437811\n",
      "printing precision\n",
      "0.9885378649635037\n",
      "f1-score\n",
      "0.9885378649635037\n",
      "Testing Set Accuracy  : 0.9701492537313433\n",
      "Testing Set Accuracy without cross-validation: 0.9701492537313433\n",
      "ROC AUC: 0.9977189781021898\n",
      "recall\n",
      "0.9614507299270073\n",
      "kappa score\n",
      "0.9306497987349052\n",
      "log loss\n",
      "0.301509459733788\n",
      "MCC\n",
      "0.9308985603321833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "toddlers_df=df\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "features = features.fillna(features.mean())\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(result_df, labels, test_size=0.19, random_state=42)\n",
    "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=2),\n",
    "                               n_estimators=100, learning_rate=0.5, algorithm='SAMME.R', random_state=42)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())\n",
    "        ]),['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 150],\n",
    "    'classifier__learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "y_pred_test = grid_search.predict(X_test)\n",
    "adaboost_preds1 = grid_search.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy_test)\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_prob_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy  :\", test_accuracy_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_prob_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_nor_ab=test_accuracy_test\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print('recall')\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "print('kappa score')\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "print('log loss')\n",
    "print(log_loss(y_test, pipeline.predict_proba(X_test)))\n",
    "print('MCC')\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4d2619-8949-4dad-af5a-38f2de9e8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.   1.   1.   1.   0.95 1.   1.   1.   0.95 1.  ]\n",
      "Mean CV accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy with cross-validation: 0.9772727272727273\n",
      "printing precision\n",
      "0.9821428571428572\n",
      "f1-score\n",
      "0.9757575757575758\n",
      "Testing Set Accuracy without cross-validation: 0.9772727272727273\n",
      "Testing Set Accuracy without cross-validation: 0.9772727272727273\n",
      "ROC AUC: 0.9733115468409586\n",
      "recall\n",
      "0.9705882352941176\n",
      "kappa score\n",
      "0.9515418502202643\n",
      "log loss\n",
      "0.19739487111688303\n",
      "MCC\n",
      "0.9526610232449336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\Child\\\\csv_result-Autism-Child-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "child_df=df\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "category_features = features.iloc[:, [10, 11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "features.drop(features.columns[-10:], axis=1, inplace=True)\n",
    "features = features.fillna(features.mean())\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(result_df, labels, test_size=0.3, random_state=41)\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())\n",
    "        ]),['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "adaboost_preds2 = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_test)\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_nor_ab=test_accuracy_test\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print('recall')\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "print('kappa score')\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "print('log loss')\n",
    "print(log_loss(y_test, pipeline_cv.predict_proba(X_test)))\n",
    "print('MCC')\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e771bc9-5bd5-49dd-8989-97560d5347ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_6656\\1085595013.py:36: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_6656\\1085595013.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_6656\\1085595013.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation Accuracy (mean): 0.8866666666666667\n",
      "Accuracy on testing dataset(QT_LDA): 0.9615384615384616\n",
      "Other Parameters\n",
      "Precision : 0.9705882352941176\n",
      "Recall : 0.9705882352941176\n",
      "ROC AUC : 0.9575163398692811\n",
      "F1-score : 0.9705882352941176\n",
      "Kappa : 0.9150326797385621\n",
      "Log Loss : 1.3862943611198906\n",
      "MCC : 0.9150326797385621\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "data, meta = arff.loadarff(\"D:\\\\Sem 6\\\\Mini Project\\\\autistic+spectrum+disorder+screening+data+for+adolescent\\\\Autism-Adolescent-Data.arff\")\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str' \n",
    "}\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "df = df.astype(dtype_mapping)\n",
    "adolescent_df=df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = joined_df.iloc[:, :-1] \n",
    "y = joined_df.iloc[:, -1]   \n",
    "accuracy_list={}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=210)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "means = np.mean(prior_probabilities, axis=0)  \n",
    "variances = np.var(prior_probabilities, axis=0)  \n",
    "pipeline = Pipeline([\n",
    "    ('transformer', QuantileTransformer(n_quantiles=35,output_distribution='uniform',subsample=60, random_state=91)),\n",
    "    ('oversampler', RandomOverSampler(random_state=12)),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='svd',priors=prior_probabilities, store_covariance=True, tol=0.99999999))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=50)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "print(\"\\nCross-validation Accuracy (mean):\", accuracy_scores.mean())\n",
    "y_pred = pipeline.predict(X_test)\n",
    "lda_preds1 = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on testing dataset(QT_LDA):\", accuracy)\n",
    "accuracy_qt_lda=accuracy\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Other Parameters\")\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"ROC AUC :\", roc_auc)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Kappa :\", kappa)\n",
    "print(\"Log Loss :\", logloss)\n",
    "print(\"MCC :\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec18aee-2346-40d4-9fe1-d1bdc34c735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_6656\\3273953274.py:30: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_6656\\3273953274.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_6656\\3273953274.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on testing dataset: 0.9929078014184397\n",
      "Other Parameters\n",
      "Precision : 0.9743589743589743\n",
      "Recall : 1.0\n",
      "ROC AUC : 0.9951456310679612\n",
      "F1-score : 0.9870129870129869\n",
      "Kappa : 0.9821360699353858\n",
      "Log Loss : 0.25562874744054737\n",
      "MCC : 0.9822928170822647\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "data, meta = arff.loadarff(\"D:\\\\Sem 6\\\\Mini Project\\\\autism+screening+adult\\\\Autism-Adult-Data.arff\")\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  \n",
    "}\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "dtype_tuples = [(col, dtype_mapping[col]) for col in meta.names()]\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "df = df.astype(dtype_mapping)\n",
    "adult_df=df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = joined_df.iloc[:, :-1]  \n",
    "y = joined_df.iloc[:, -1]    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "means = np.mean(prior_probabilities, axis=0) \n",
    "variances = np.var(prior_probabilities, axis=0)\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', QuantileTransformer(n_quantiles=84,output_distribution='uniform',subsample=350, random_state=15)),\n",
    "    ('oversampler', RandomOverSampler(random_state=4)),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='lsqr',shrinkage=0.25,priors=prior_probabilities, store_covariance=True, tol=0.00009))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "lda_preds2 = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy on testing dataset:\", accuracy)\n",
    "accuracy_qt_lda=accuracy\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"Other Parameters\")\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"ROC AUC :\", roc_auc)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Kappa :\", kappa)\n",
    "print(\"Log Loss :\", logloss)\n",
    "print(\"MCC :\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bb8902-c5ed-47c6-8072-88c7b10cdac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-model validation accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "adaboost_preds1=adaboost_preds1[:52]\n",
    "adaboost_preds2=adaboost_preds2[:52]\n",
    "lda_preds1=lda_preds1[:53]\n",
    "lda_preds2=adaboost_preds2[:52]\n",
    "def generate_synthetic_labels(predictions):\n",
    "    # Example: Combine predictions using a simple rule-based approach\n",
    "    synthetic_labels = []\n",
    "    for pred in predictions:\n",
    "        # Example: Combine predictions using a majority voting scheme\n",
    "        if np.count_nonzero(pred) > len(pred) / 2:\n",
    "            synthetic_labels.append('Yes')\n",
    "        else:\n",
    "            synthetic_labels.append('No')\n",
    "    return synthetic_labels\n",
    "    \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "meta_features = np.column_stack((adaboost_preds1, adaboost_preds2, lda_preds1, lda_preds2))\n",
    "for i in range(0,len(meta_features)):\n",
    "    for j in range(0,4):\n",
    "        if meta_features[i][j]=='Yes'or meta_features[i][j]=='YES':\n",
    "            meta_features[i][j]=1\n",
    "        else:\n",
    "            meta_features[i][j]=0\n",
    "            \n",
    "synthetic_labels = generate_synthetic_labels(meta_features)\n",
    "X_train_meta, X_val_meta, y_train_meta, y_val_meta = train_test_split(meta_features, synthetic_labels, test_size=0.27, random_state=234)\n",
    "meta_model = LinearDiscriminantAnalysis(solver='svd',priors=prior_probabilities, store_covariance=True, tol=0.999999999991)\n",
    "meta_model.fit(X_train_meta, y_train_meta)\n",
    "val_predictions = meta_model.predict(X_val_meta)\n",
    "accuracy = accuracy_score(y_val_meta, val_predictions)\n",
    "print(\"Meta-model validation accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
