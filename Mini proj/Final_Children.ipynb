{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e6c16d7-6753-4cc2-b7bb-322cc441c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy  : 0.9772727272727273\n",
      "Feature Importance Scores:\n",
      "A1_Score: 0.07220600483359552\n",
      "A2_Score: 0.027542626452478736\n",
      "A3_Score: 0.10835166682575825\n",
      "A4_Score: 0.1614893705122702\n",
      "A5_Score: 0.06447992248817047\n",
      "A6_Score: 0.1019493287148372\n",
      "A7_Score: 0.0\n",
      "A8_Score: 0.10183904316889492\n",
      "A9_Score: 0.07730431009874472\n",
      "A10_Score: 0.07795845532766577\n",
      "age_10: 0.000887356748143775\n",
      "age_11: 0.018214551879077057\n",
      "age_4: 0.0\n",
      "age_5: 0.0\n",
      "age_6: 0.0\n",
      "age_7: 0.007419032497109068\n",
      "age_8: 0.014782100374195473\n",
      "age_9: 0.0874122201627816\n",
      "age_?: 0.01025655063836517\n",
      "gender_f: 0.006456573357079609\n",
      "gender_m: 0.027611379091324384\n",
      "ethnicity_?: 0.0398044759367393\n",
      "ethnicity_Asian: 0.0\n",
      "ethnicity_Black: 0.0\n",
      "ethnicity_Hispanic: 0.03452271152835795\n",
      "ethnicity_Latino: 0.0\n",
      "ethnicity_Middle Eastern : 0.0\n",
      "ethnicity_Others: 0.018291052481278713\n",
      "ethnicity_Pasifika: 0.0\n",
      "ethnicity_South Asian: 0.0\n",
      "ethnicity_Turkish: 0.04975573266091193\n",
      "ethnicity_White-European: 0.02174149421168159\n",
      "jundice_no: 0.03165336514265671\n",
      "jundice_yes: 0.015626103204179786\n",
      "austim_no: 0.0\n",
      "austim_yes: 0.033413170757602195\n",
      "contry_of_res_Afghanistan: 0.014886227814771447\n",
      "contry_of_res_Argentina: 0.05135466401176747\n",
      "contry_of_res_Armenia: 0.0\n",
      "contry_of_res_Australia: 0.0\n",
      "contry_of_res_Austria: 0.0\n",
      "contry_of_res_Bahrain: 0.06142101441965164\n",
      "contry_of_res_Bangladesh: 0.004884287906289808\n",
      "contry_of_res_Bhutan: 0.0350712867848777\n",
      "contry_of_res_Brazil: 0.0\n",
      "contry_of_res_Bulgaria: 0.016644075367011624\n",
      "contry_of_res_Canada: 0.054813030671068574\n",
      "contry_of_res_China: 0.0\n",
      "contry_of_res_Costa Rica: 0.0\n",
      "contry_of_res_Egypt: 0.0\n",
      "contry_of_res_Europe: 0.0\n",
      "contry_of_res_Georgia: 0.03180354595872559\n",
      "contry_of_res_Germany: 0.00475953597078993\n",
      "contry_of_res_Ghana: 0.005168323704343836\n",
      "contry_of_res_India: 0.009973007597813055\n",
      "contry_of_res_Iraq: 0.0247196213926677\n",
      "contry_of_res_Ireland: 0.06303405010089258\n",
      "contry_of_res_Isle of Man: 0.03657113039920712\n",
      "contry_of_res_Italy: 0.0\n",
      "contry_of_res_Japan: 0.07289030188192958\n",
      "contry_of_res_Jordan: 0.03577276599102941\n",
      "contry_of_res_Kuwait: 0.0\n",
      "contry_of_res_Latvia: 0.0\n",
      "contry_of_res_Lebanon: 0.0\n",
      "contry_of_res_Libya: 0.019264319868097513\n",
      "contry_of_res_Malaysia: 0.0\n",
      "contry_of_res_Malta: 0.0\n",
      "contry_of_res_Mexico: 0.0\n",
      "contry_of_res_Nepal: 0.0\n",
      "contry_of_res_Netherlands: 0.0\n",
      "contry_of_res_New Zealand: 0.0\n",
      "contry_of_res_Nigeria: 0.02451241419329464\n",
      "contry_of_res_Oman: 0.0\n",
      "contry_of_res_Pakistan: 0.0\n",
      "contry_of_res_Philippines: 0.0\n",
      "contry_of_res_Qatar: 0.09429677054307128\n",
      "contry_of_res_Romania: 0.0\n",
      "contry_of_res_Russia: 0.0391152179316121\n",
      "contry_of_res_Saudi Arabia: 0.04414586165109591\n",
      "contry_of_res_South Africa: 0.007942823906038177\n",
      "contry_of_res_South Korea: 0.026647850148824093\n",
      "contry_of_res_Sweden: 0.03173323724355681\n",
      "contry_of_res_Syria: 0.07492598037788878\n",
      "contry_of_res_Turkey: 0.020881699113981078\n",
      "contry_of_res_U.S. Outlying Islands: 0.02767921105168014\n",
      "contry_of_res_United Arab Emirates: 0.015747283129546208\n",
      "contry_of_res_United Kingdom: 0.0\n",
      "contry_of_res_United States: 0.013442214922160467\n",
      "used_app_before_no: 0.0\n",
      "used_app_before_yes: 0.0\n",
      "result_0: 0.0\n",
      "result_1: 0.02002895632198598\n",
      "result_2: 0.06698092508195375\n",
      "result_3: 0.06499888125686448\n",
      "result_4: 0.10232110602067834\n",
      "result_5: 0.06148192184037238\n",
      "result_6: 0.10833918390516595\n",
      "result_7: 0.07865716611842033\n",
      "result_8: 0.1250669219907925\n",
      "result_9: 0.058844651270858694\n",
      "result_10: 0.011001976033323757\n",
      "age_desc_4-11 years: 0.0\n",
      "relation_?: 0.0\n",
      "relation_Health care professional: 0.00700649072942694\n",
      "relation_Parent: 0.0\n",
      "relation_Relative: 0.022457887722880487\n",
      "relation_Self: 0.0\n",
      "relation_self: 0.033013680580075144\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\Sem 6\\Mini Project\\csv_result-Autism-Child-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-10:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.3, random_state=41)\n",
    "\n",
    "# Perform random oversampling only on the training data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on resampled training data\n",
    "pipeline_cv.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy  :\", test_accuracy_test)\n",
    "\n",
    "# Calculate feature importance using Info Gain Attribute Evaluator\n",
    "# Since AdaBoost does not directly provide feature importance, we can use SelectKBest with mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get selected features and their scores\n",
    "selected_features = result_df.columns[selector.get_support()]\n",
    "feature_scores = selector.scores_\n",
    "\n",
    "# Print feature importance scores\n",
    "print(\"Feature Importance Scores:\")\n",
    "for feature, score in zip(selected_features, feature_scores):\n",
    "    print(f\"{feature}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "353f2f72-4f90-47fe-bb18-7715e8452707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy  : 0.9772727272727273\n",
      "Feature Importance Scores:\n",
      "A1_Score: 0.05053117308599364\n",
      "A2_Score: 0.007296426650204246\n",
      "A3_Score: 0.07659475443503982\n",
      "A4_Score: 0.1825474428438567\n",
      "A5_Score: 0.1011718137071067\n",
      "A6_Score: 0.13548521492543952\n",
      "A7_Score: 0.0\n",
      "A8_Score: 0.07789105743406521\n",
      "A9_Score: 0.13676703381109245\n",
      "A10_Score: 0.09218741549919796\n",
      "age_10: 0.0\n",
      "age_11: 0.0\n",
      "age_4: 0.0\n",
      "age_5: 0.0\n",
      "age_6: 0.043989899324985204\n",
      "age_7: 0.0\n",
      "age_8: 0.024881839679542495\n",
      "age_9: 0.0\n",
      "age_?: 0.025797188608910115\n",
      "gender_f: 0.03661436987001654\n",
      "gender_m: 0.05775281086827033\n",
      "ethnicity_?: 0.0029840075013360945\n",
      "ethnicity_Asian: 0.0068790221440149235\n",
      "ethnicity_Black: 0.0\n",
      "ethnicity_Hispanic: 0.05840227822334554\n",
      "ethnicity_Latino: 0.0\n",
      "ethnicity_Middle Eastern : 0.0\n",
      "ethnicity_Others: 0.02307148751872301\n",
      "ethnicity_Pasifika: 0.03595544935128281\n",
      "ethnicity_South Asian: 0.06358858792793476\n",
      "ethnicity_Turkish: 0.05658476811144264\n",
      "ethnicity_White-European: 0.0\n",
      "jundice_no: 0.0\n",
      "jundice_yes: 0.0\n",
      "austim_no: 0.06860476395153214\n",
      "austim_yes: 0.0\n",
      "contry_of_res_Afghanistan: 0.020005697557661017\n",
      "contry_of_res_Argentina: 0.0\n",
      "contry_of_res_Armenia: 0.10044499666793283\n",
      "contry_of_res_Australia: 0.00218124069389658\n",
      "contry_of_res_Austria: 0.0\n",
      "contry_of_res_Bahrain: 0.05142417066112537\n",
      "contry_of_res_Bangladesh: 0.0\n",
      "contry_of_res_Bhutan: 0.0\n",
      "contry_of_res_Brazil: 0.0\n",
      "contry_of_res_Bulgaria: 0.0\n",
      "contry_of_res_Canada: 0.1110635707210863\n",
      "contry_of_res_China: 0.0\n",
      "contry_of_res_Costa Rica: 0.04826530188313427\n",
      "contry_of_res_Egypt: 0.0\n",
      "contry_of_res_Europe: 0.0\n",
      "contry_of_res_Georgia: 0.03580657223089201\n",
      "contry_of_res_Germany: 0.03608095606007744\n",
      "contry_of_res_Ghana: 0.0\n",
      "contry_of_res_India: 0.0\n",
      "contry_of_res_Iraq: 0.0\n",
      "contry_of_res_Ireland: 0.0\n",
      "contry_of_res_Isle of Man: 0.0068205914781072075\n",
      "contry_of_res_Italy: 0.010632680220102886\n",
      "contry_of_res_Japan: 0.0435044035123866\n",
      "contry_of_res_Jordan: 0.0\n",
      "contry_of_res_Kuwait: 0.01851591847717282\n",
      "contry_of_res_Latvia: 0.02917042492607158\n",
      "contry_of_res_Lebanon: 0.017754290437507203\n",
      "contry_of_res_Libya: 0.0\n",
      "contry_of_res_Malaysia: 0.0\n",
      "contry_of_res_Malta: 0.031368071516241436\n",
      "contry_of_res_Mexico: 0.008033890121312615\n",
      "contry_of_res_Nepal: 0.0\n",
      "contry_of_res_Netherlands: 0.0\n",
      "contry_of_res_New Zealand: 0.0\n",
      "contry_of_res_Nigeria: 0.03120935173135364\n",
      "contry_of_res_Oman: 0.0\n",
      "contry_of_res_Pakistan: 0.015008885530887195\n",
      "contry_of_res_Philippines: 0.020478143687061356\n",
      "contry_of_res_Qatar: 0.08599242609665203\n",
      "contry_of_res_Romania: 0.0\n",
      "contry_of_res_Russia: 0.0\n",
      "contry_of_res_Saudi Arabia: 0.0\n",
      "contry_of_res_South Africa: 0.0\n",
      "contry_of_res_South Korea: 0.0\n",
      "contry_of_res_Sweden: 0.0007961123227873124\n",
      "contry_of_res_Syria: 0.04029491829355569\n",
      "contry_of_res_Turkey: 0.0\n",
      "contry_of_res_U.S. Outlying Islands: 0.06304809969159675\n",
      "contry_of_res_United Arab Emirates: 0.036587942507140925\n",
      "contry_of_res_United Kingdom: 0.0\n",
      "contry_of_res_United States: 0.0\n",
      "used_app_before_no: 0.021182616433178092\n",
      "used_app_before_yes: 0.0\n",
      "result_0: 0.01549056895649592\n",
      "result_1: 0.0\n",
      "result_2: 0.02313284879503752\n",
      "result_3: 0.09124403407912007\n",
      "result_4: 0.045650141989900916\n",
      "result_5: 0.11735924804480136\n",
      "result_6: 0.10327381184213036\n",
      "result_7: 0.13067520908272456\n",
      "result_8: 0.1268634524522203\n",
      "result_9: 0.053873797877107776\n",
      "result_10: 0.03804296463973267\n",
      "age_desc_4-11 years: 0.01116839191235619\n",
      "relation_?: 0.011765905769215879\n",
      "relation_Health care professional: 0.0\n",
      "relation_Parent: 0.10230121417835614\n",
      "relation_Relative: 0.06586222481880655\n",
      "relation_Self: 0.0\n",
      "relation_self: 0.0\n",
      "Summed Feature Importances for One-Hot Encoded Features:\n",
      "age: 0.105837319525794\n",
      "gender: 0.09436718073828687\n",
      "ethnicity: 0.24746560077807978\n",
      "jundice: 0.0\n",
      "austim: 0.06860476395153214\n",
      "contry_of_res: 0.8644886570257431\n",
      "used_app_before: 0.021182616433178092\n",
      "result: 0.7456060777592715\n",
      "age_desc: 0.01116839191235619\n",
      "relation: 0.17992934476637856\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\Sem 6\\Mini Project\\csv_result-Autism-Child-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-10:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.3, random_state=41)\n",
    "\n",
    "# Perform random oversampling only on the training data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on resampled training data\n",
    "pipeline_cv.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy  :\", test_accuracy_test)\n",
    "\n",
    "# Calculate feature importance using Info Gain Attribute Evaluator\n",
    "# Since AdaBoost does not directly provide feature importance, we can use SelectKBest with mutual_info_classif\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get selected features and their scores\n",
    "selected_features = result_df.columns[selector.get_support()]\n",
    "feature_scores = selector.scores_\n",
    "\n",
    "# Print feature importance scores\n",
    "print(\"Feature Importance Scores:\")\n",
    "for feature, score in zip(selected_features, feature_scores):\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "# Sum up feature importances of one-hot encoded features by their original categorical features\n",
    "feature_importance_dict = {}\n",
    "for col in category_features.columns:\n",
    "    relevant_columns = [column for column in result_df.columns if col in column]\n",
    "    importance_sum = sum(selector.scores_[selected_features.get_loc(column)] for column in relevant_columns)\n",
    "    feature_importance_dict[col] = importance_sum\n",
    "\n",
    "# Print summed feature importances\n",
    "print(\"Summed Feature Importances for One-Hot Encoded Features:\")\n",
    "for feature, importance in feature_importance_dict.items():\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91b2bc8-109a-4d6a-9393-2d6ec1c139b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy  : 0.9772727272727273\n",
      "Feature Importance Scores:\n",
      "A4_Score: 0.10544875682231655\n",
      "A9_Score: 0.03356882959369316\n",
      "A8_Score: 0.15856428138265613\n",
      "A3_Score: 0.3519178289872655\n",
      "A6_Score: 0.1290378006872852\n",
      "A10_Score: 0.15793662825955113\n",
      "A5_Score: 0.08723266626238124\n",
      "A1_Score: 0.17313068526379632\n",
      "result_8: 0.19401202749140872\n",
      "result_6: 0.149489589650293\n",
      "result_5: -0.0006989084293511215\n",
      "A7_Score: -0.0006372549019607859\n",
      "result_7: -0.0010501313927632934\n",
      "result_9: 0.0007797655144532045\n",
      "result_4: 0.00033454618960986385\n",
      "A2_Score: 0.0010026278552658172\n",
      "result_3: -0.0004169193450576059\n",
      "result_10: 0.0025005053567818875\n",
      "contry_of_res_United States: 0.0014028704265211243\n",
      "result_2: -0.004411764705882353\n",
      "contry_of_res_India: -0.004411764705882353\n",
      "ethnicity_South Asian: 0.0050692338791186575\n",
      "contry_of_res_Jordan: -0.0021144127754194474\n",
      "ethnicity_?: -0.0005392156862745111\n",
      "relation_?: -0.0006862745098039211\n",
      "relation_Parent: -0.0009743278754800878\n",
      "result_1: 0.0002683444511825342\n",
      "relation_Relative: 0.0007368101879927209\n",
      "age_9: 6.418031129977757e-05\n",
      "used_app_before_no: 0.006019809985850005\n",
      "used_app_before_yes: 0.0014149989892864366\n",
      "contry_of_res_United Arab Emirates: -0.0028532443905397225\n",
      "contry_of_res_Pakistan: -0.0012937133616333152\n",
      "contry_of_res_Iraq: -0.0012937133616333152\n",
      "ethnicity_Turkish: -0.003568324236911255\n",
      "contry_of_res_Qatar: -0.003568324236911255\n",
      "contry_of_res_Turkey: 0.0006064281382656153\n",
      "contry_of_res_Italy: 0.0\n",
      "age_?: -0.0014705882352941172\n",
      "contry_of_res_New Zealand: -0.001973418233272691\n",
      "age_7: -0.0004901960784313724\n",
      "age_5: -0.0006862745098039217\n",
      "contry_of_res_Libya: -0.00026379624014554305\n",
      "ethnicity_Others: -0.0006862745098039214\n",
      "contry_of_res_Saudi Arabia: -0.0006372549019607842\n",
      "contry_of_res_Afghanistan: 0.0\n",
      "contry_of_res_Japan: -0.0004411764705882351\n",
      "contry_of_res_Romania: -0.0007352941176470586\n",
      "contry_of_res_Kuwait: 0.0\n",
      "contry_of_res_Malaysia: 6.064281382656367e-06\n",
      "contry_of_res_Mexico: 0.0\n",
      "contry_of_res_Netherlands: -0.0004411764705882352\n",
      "contry_of_res_Oman: -0.0004411764705882352\n",
      "contry_of_res_South Korea: 0.0\n",
      "relation_Self: 0.006629775621588842\n",
      "age_6: 0.0014149989892864366\n",
      "ethnicity_Middle Eastern : 0.0\n",
      "contry_of_res_Syria: -0.0008823529411764704\n",
      "ethnicity_Pasifika: 0.0014149989892864364\n",
      "contry_of_res_Egypt: 0.0006064281382656153\n",
      "contry_of_res_Bulgaria: 0.005392662219526985\n",
      "contry_of_res_Argentina: 0.0006064281382656153\n",
      "relation_self: 0.0\n",
      "contry_of_res_Ghana: -1.3552527156068805e-20\n",
      "contry_of_res_Sweden: 0.0007504548211036993\n",
      "contry_of_res_Ireland: 0.0006064281382656153\n",
      "contry_of_res_Europe: -0.0004411764705882352\n",
      "contry_of_res_Costa Rica: 0.0006064281382656153\n",
      "contry_of_res_Nigeria: -0.0007843137254901958\n",
      "contry_of_res_South Africa: 0.0006064281382656153\n",
      "contry_of_res_Latvia: 0.0011779866585809552\n",
      "contry_of_res_U.S. Outlying Islands: 0.0\n",
      "result_0: 0.0006064281382656153\n",
      "age_desc_4-11 years: 0.0014149989892864366\n",
      "contry_of_res_Lebanon: -0.0005392156862745094\n",
      "contry_of_res_Bangladesh: 0.0014149989892864366\n",
      "age_8: 0.0006064281382656153\n",
      "contry_of_res_Canada: -0.0006741459470386092\n",
      "contry_of_res_Malta: 0.0006736405902567212\n",
      "contry_of_res_Georgia: 0.0\n",
      "contry_of_res_Germany: 0.0006064281382656153\n",
      "contry_of_res_Austria: 0.0\n",
      "contry_of_res_Philippines: 0.00011319991914291496\n",
      "ethnicity_Black: 0.0014149989892864366\n",
      "contry_of_res_Brazil: 0.0\n",
      "age_11: 0.0014149989892864368\n",
      "contry_of_res_Russia: -0.0018010915706488803\n",
      "ethnicity_Hispanic: 0.007551546391752585\n",
      "contry_of_res_Bhutan: 0.0016257327673337377\n",
      "contry_of_res_Bahrain: 0.0016257327673337377\n",
      "age_10: 0.0\n",
      "contry_of_res_China: 0.0036385688295936932\n",
      "contry_of_res_Nepal: 0.006670709520921768\n",
      "contry_of_res_Isle of Man: 0.0268849807964423\n",
      "ethnicity_Latino: 0.04608853850818673\n",
      "age_4: 0.08732565191024858\n",
      "jundice_no: 0.08732565191024858\n",
      "jundice_yes: 0.0867156862745097\n",
      "contry_of_res_Armenia: 0.09671568627450983\n",
      "contry_of_res_United Kingdom: 0.050294117647058836\n",
      "contry_of_res_Australia: 0.008431372549019593\n",
      "ethnicity_Asian: 0.0\n",
      "relation_Health care professional: 0.0050692338791186575\n",
      "ethnicity_White-European: -0.002686982009298561\n",
      "austim_no: 0.003988275722660198\n",
      "austim_yes: 0.0033990297149787754\n",
      "gender_m: 0.0006033959975742877\n",
      "gender_f: 0.0\n",
      "Summed Feature Importances for Original Categorical Features:\n",
      "age: 0.08959419850414385\n",
      "gender: 0.0006033959975742877\n",
      "ethnicity: 0.0540585203153426\n",
      "jundice: 0.17404133818475828\n",
      "austim: 0.007387305437638973\n",
      "contry_of_res: 0.18547301394784718\n",
      "used_app_before: 0.007434808975136441\n",
      "result: 0.3414134829189404\n",
      "age_desc: 0.0014149989892864366\n",
      "relation: 0.010775217303416212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from skrebate import ReliefF\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\Sem 6\\Mini Project\\csv_result-Autism-Child-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-10:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.3, random_state=41)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), slice(0, -10)),  # Numerical features\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), slice(-10, None))  # Categorical features\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on original training data\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy  :\", test_accuracy_test)\n",
    "\n",
    "# Calculate feature importance using ReliefF\n",
    "reliefF = ReliefF(n_features_to_select='all', n_neighbors=100)\n",
    "reliefF.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Get selected features and their scores\n",
    "selected_features = result_df.columns[reliefF.top_features_]\n",
    "feature_scores = reliefF.feature_importances_\n",
    "\n",
    "# Print feature importance scores\n",
    "print(\"Feature Importance Scores:\")\n",
    "for feature, score in zip(selected_features, feature_scores):\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "# Sum up feature importances of one-hot encoded features by their original categorical features\n",
    "feature_importance_dict = {}\n",
    "for col in category_features.columns:\n",
    "    relevant_columns = [column for column in result_df.columns if col in column]\n",
    "    importance_sum = sum(reliefF.feature_importances_[selected_features.get_loc(column)] for column in relevant_columns)\n",
    "    feature_importance_dict[col] = importance_sum\n",
    "\n",
    "# Print summed feature importances for original categorical features\n",
    "print(\"Summed Feature Importances for Original Categorical Features:\")\n",
    "for feature, importance in feature_importance_dict.items():\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e04e420b-413b-4d05-afe8-c8a3a0951795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy  : 0.9772727272727273\n",
      "Normalized Feature Importance Scores (Correlation with Target):\n",
      "A1_Score: 0.2155712534826406\n",
      "A2_Score: 0.07715953073470126\n",
      "A3_Score: 0.4269314046081445\n",
      "A4_Score: 1.0\n",
      "A5_Score: 0.3664031678259957\n",
      "A6_Score: 0.4214406147034598\n",
      "A7_Score: 0.1445611526447056\n",
      "A8_Score: 0.39459236364123423\n",
      "A9_Score: 0.4160365513392855\n",
      "A10_Score: 0.3664031678259957\n",
      "age_10: 0.003418928045186629\n",
      "age_11: 0.014697925464527032\n",
      "age_4: 0.0001649824018771272\n",
      "age_5: 0.0026261082117705853\n",
      "age_6: 0.0003683815357747539\n",
      "age_7: 0.0015278616110623532\n",
      "age_8: 0.007042315366456824\n",
      "age_9: 0.014697925464527032\n",
      "age_?: 0.0\n",
      "gender_f: 0.0016479492187500802\n",
      "gender_m: 0.0016479492187498018\n",
      "ethnicity_?: 0.004794034090909089\n",
      "ethnicity_Asian: 0.0011381519784172253\n",
      "ethnicity_Black: 0.0024896056866952634\n",
      "ethnicity_Hispanic: 0.033790958737864064\n",
      "ethnicity_Latino: 0.015117866192084935\n",
      "ethnicity_Middle Eastern : 0.0\n",
      "ethnicity_Others: 0.006014634936635936\n",
      "ethnicity_Pasifika: 0.0\n",
      "ethnicity_South Asian: 0.022665860166425446\n",
      "ethnicity_Turkish: 0.016573660714285704\n",
      "ethnicity_White-European: 0.0026287528323263145\n",
      "jundice_no: 0.0\n",
      "jundice_yes: 0.0\n",
      "austim_no: 0.00026576578726469154\n",
      "austim_yes: 0.000265765787263277\n",
      "contry_of_res_Afghanistan: 0.008208652712264146\n",
      "contry_of_res_Argentina: 0.0\n",
      "contry_of_res_Armenia: 0.016573660714285704\n",
      "contry_of_res_Australia: 0.0022000434576485454\n",
      "contry_of_res_Austria: 0.008208652712264146\n",
      "contry_of_res_Bahrain: 0.016573660714285704\n",
      "contry_of_res_Bangladesh: 0.0016668911637930982\n",
      "contry_of_res_Bhutan: 0.008208652712264146\n",
      "contry_of_res_Brazil: 0.016573660714285704\n",
      "contry_of_res_Bulgaria: 0.0\n",
      "contry_of_res_Canada: 0.042652803308823525\n",
      "contry_of_res_China: 0.008208652712264146\n",
      "contry_of_res_Costa Rica: 0.0\n",
      "contry_of_res_Egypt: 0.008530560661764705\n",
      "contry_of_res_Europe: 0.0\n",
      "contry_of_res_Georgia: 0.008208652712264146\n",
      "contry_of_res_Germany: 0.008208652712264146\n",
      "contry_of_res_Ghana: 0.0\n",
      "contry_of_res_India: 0.015162070479196287\n",
      "contry_of_res_Iraq: 0.016573660714285704\n",
      "contry_of_res_Ireland: 0.0\n",
      "contry_of_res_Isle of Man: 0.008208652712264146\n",
      "contry_of_res_Italy: 0.025099534254807678\n",
      "contry_of_res_Japan: 0.008208652712264146\n",
      "contry_of_res_Jordan: 0.010001346982758617\n",
      "contry_of_res_Kuwait: 0.008208652712264146\n",
      "contry_of_res_Latvia: 0.0\n",
      "contry_of_res_Lebanon: 0.008208652712264146\n",
      "contry_of_res_Libya: 0.0027535354034810117\n",
      "contry_of_res_Malaysia: 0.008208652712264146\n",
      "contry_of_res_Malta: 0.008208652712264146\n",
      "contry_of_res_Mexico: 0.008208652712264146\n",
      "contry_of_res_Nepal: 0.008208652712264146\n",
      "contry_of_res_Netherlands: 0.008208652712264146\n",
      "contry_of_res_New Zealand: 0.0028764204545454536\n",
      "contry_of_res_Nigeria: 0.0\n",
      "contry_of_res_Oman: 0.008208652712264146\n",
      "contry_of_res_Pakistan: 0.016573660714285704\n",
      "contry_of_res_Philippines: 0.025099534254807678\n",
      "contry_of_res_Qatar: 0.016573660714285704\n",
      "contry_of_res_Romania: 0.008208652712264146\n",
      "contry_of_res_Russia: 0.0027535354034810117\n",
      "contry_of_res_Saudi Arabia: 0.0027535354034810117\n",
      "contry_of_res_South Africa: 0.0\n",
      "contry_of_res_South Korea: 0.008208652712264146\n",
      "contry_of_res_Sweden: 0.0\n",
      "contry_of_res_Syria: 0.0\n",
      "contry_of_res_Turkey: 0.016573660714285704\n",
      "contry_of_res_U.S. Outlying Islands: 0.0\n",
      "contry_of_res_United Arab Emirates: 0.033790958737864064\n",
      "contry_of_res_United Kingdom: 0.0002778151939655073\n",
      "contry_of_res_United States: 0.041933358433734934\n",
      "used_app_before_no: 0.0042341468978132875\n",
      "used_app_before_yes: 0.004234146897810219\n",
      "result_0: 0.0\n",
      "result_1: 0.033790958737864064\n",
      "result_2: 0.07031249999999996\n",
      "result_3: 0.13098538306451607\n",
      "result_4: 0.2252068014705882\n",
      "result_5: 0.32350510817307676\n",
      "result_6: 0.3390066964285713\n",
      "result_7: 0.37124999999999986\n",
      "result_8: 0.4229736328124998\n",
      "result_9: 0.27929687499999994\n",
      "result_10: 0.13098538306451607\n",
      "age_desc_4-11 years: 0.0\n",
      "relation_?: 0.004794034090909089\n",
      "relation_Health care professional: 0.013756793478260854\n",
      "relation_Parent: 0.005113523668899518\n",
      "relation_Relative: 0.02390431833791208\n",
      "relation_Self: 0.0\n",
      "relation_self: 0.0\n",
      "Summed Feature Importances for One-Hot Encoded Features:\n",
      "age: 0.04454442810118234\n",
      "gender: 0.003295898437499882\n",
      "ethnicity: 0.10521352533564397\n",
      "jundice: 0.0\n",
      "austim: 0.0005315315745279685\n",
      "contry_of_res: 0.4813233174149074\n",
      "used_app_before: 0.008468293795623506\n",
      "result: 2.327313338751632\n",
      "age_desc: 0.0\n",
      "relation: 0.04756866957598154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 37  45  48  50  53  56  62  71  79  81  84  90 101 107] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import f_classif\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\Sem 6\\Mini Project\\csv_result-Autism-Child-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-10:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.3, random_state=41)\n",
    "\n",
    "# Perform random oversampling only on the training data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on resampled training data\n",
    "pipeline_cv.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy  :\", test_accuracy_test)\n",
    "\n",
    "# Calculate feature importance using Corelation Attribute Evaluator\n",
    "f_scores, _ = f_classif(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Replace NaN with 0 in feature importances\n",
    "f_scores = np.nan_to_num(f_scores, nan=0)\n",
    "\n",
    "# Normalize feature importance scores between 0 and 1\n",
    "f_scores_normalized = (f_scores - f_scores.min()) / (f_scores.max() - f_scores.min())\n",
    "\n",
    "# Print normalized feature importance scores\n",
    "print(\"Normalized Feature Importance Scores (Correlation with Target):\")\n",
    "for feature, score in zip(result_df.columns, f_scores_normalized):\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "# Sum up feature importances of one-hot encoded features by their original categorical features\n",
    "feature_importance_dict = {}\n",
    "for col in category_features.columns:\n",
    "    relevant_columns = [column for column in result_df.columns if col in column]\n",
    "    importance_sum = sum(f_scores_normalized[result_df.columns.get_loc(column)] for column in relevant_columns)\n",
    "    feature_importance_dict[col] = importance_sum\n",
    "\n",
    "# Print summed feature importances\n",
    "print(\"Summed Feature Importances for One-Hot Encoded Features:\")\n",
    "for feature, importance in feature_importance_dict.items():\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16df66-b6a1-453a-83fc-3487b4f7f94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
