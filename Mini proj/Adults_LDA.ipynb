{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2597645b-54ef-43b4-9bbc-1baef1ec9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_21188\\3382632498.py:36: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_21188\\3382632498.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_21188\\3382632498.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and their types:\n",
      "A1_Score              bool\n",
      "A2_Score              bool\n",
      "A3_Score              bool\n",
      "A4_Score              bool\n",
      "A5_Score              bool\n",
      "A6_Score              bool\n",
      "A7_Score              bool\n",
      "A8_Score              bool\n",
      "A9_Score              bool\n",
      "A10_Score             bool\n",
      "age                float64\n",
      "gender              object\n",
      "ethnicity           object\n",
      "jundice               bool\n",
      "austim                bool\n",
      "contry_of_res       object\n",
      "used_app_before       bool\n",
      "result             float64\n",
      "age_desc            object\n",
      "relation            object\n",
      "Class/ASD           object\n",
      "dtype: object\n",
      "DataFrame:\n",
      "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
      "0        True      True      True      True      True      True      True   \n",
      "1        True      True      True      True      True      True      True   \n",
      "2        True      True      True      True      True      True      True   \n",
      "3        True      True      True      True      True      True      True   \n",
      "4        True      True      True      True      True      True      True   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "699      True      True      True      True      True      True      True   \n",
      "700      True      True      True      True      True      True      True   \n",
      "701      True      True      True      True      True      True      True   \n",
      "702      True      True      True      True      True      True      True   \n",
      "703      True      True      True      True      True      True      True   \n",
      "\n",
      "     A8_Score  A9_Score  A10_Score  ...  gender       ethnicity jundice  \\\n",
      "0        True      True       True  ...       f  White-European    True   \n",
      "1        True      True       True  ...       m          Latino    True   \n",
      "2        True      True       True  ...       m          Latino    True   \n",
      "3        True      True       True  ...       f  White-European    True   \n",
      "4        True      True       True  ...       f               ?    True   \n",
      "..        ...       ...        ...  ...     ...             ...     ...   \n",
      "699      True      True       True  ...       f  White-European    True   \n",
      "700      True      True       True  ...       m        Hispanic    True   \n",
      "701      True      True       True  ...       f               ?    True   \n",
      "702      True      True       True  ...       m     South Asian    True   \n",
      "703      True      True       True  ...       f  White-European    True   \n",
      "\n",
      "     austim  contry_of_res used_app_before  result     age_desc relation  \\\n",
      "0      True  United States            True     6.0  18 and more     Self   \n",
      "1      True         Brazil            True     5.0  18 and more     Self   \n",
      "2      True          Spain            True     8.0  18 and more   Parent   \n",
      "3      True  United States            True     6.0  18 and more     Self   \n",
      "4      True          Egypt            True     2.0  18 and more        ?   \n",
      "..      ...            ...             ...     ...          ...      ...   \n",
      "699    True         Russia            True     7.0  18 and more     Self   \n",
      "700    True         Mexico            True     3.0  18 and more   Parent   \n",
      "701    True         Russia            True     7.0  18 and more        ?   \n",
      "702    True       Pakistan            True     6.0  18 and more     Self   \n",
      "703    True         Cyprus            True     8.0  18 and more     Self   \n",
      "\n",
      "    Class/ASD  \n",
      "0          NO  \n",
      "1          NO  \n",
      "2         YES  \n",
      "3          NO  \n",
      "4          NO  \n",
      "..        ...  \n",
      "699       YES  \n",
      "700        NO  \n",
      "701       YES  \n",
      "702        NO  \n",
      "703       YES  \n",
      "\n",
      "[704 rows x 21 columns]\n",
      "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
      "0        True      True      True      True      True      True      True   \n",
      "1        True      True      True      True      True      True      True   \n",
      "2        True      True      True      True      True      True      True   \n",
      "3        True      True      True      True      True      True      True   \n",
      "4        True      True      True      True      True      True      True   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "699      True      True      True      True      True      True      True   \n",
      "700      True      True      True      True      True      True      True   \n",
      "701      True      True      True      True      True      True      True   \n",
      "702      True      True      True      True      True      True      True   \n",
      "703      True      True      True      True      True      True      True   \n",
      "\n",
      "     A8_Score  A9_Score  A10_Score  ...  contry_of_res_United Kingdom  \\\n",
      "0        True      True       True  ...                           0.0   \n",
      "1        True      True       True  ...                           0.0   \n",
      "2        True      True       True  ...                           0.0   \n",
      "3        True      True       True  ...                           0.0   \n",
      "4        True      True       True  ...                           0.0   \n",
      "..        ...       ...        ...  ...                           ...   \n",
      "699      True      True       True  ...                           0.0   \n",
      "700      True      True       True  ...                           0.0   \n",
      "701      True      True       True  ...                           0.0   \n",
      "702      True      True       True  ...                           0.0   \n",
      "703      True      True       True  ...                           0.0   \n",
      "\n",
      "     contry_of_res_United States  contry_of_res_Uruguay  \\\n",
      "0                            1.0                    0.0   \n",
      "1                            0.0                    0.0   \n",
      "2                            0.0                    0.0   \n",
      "3                            1.0                    0.0   \n",
      "4                            0.0                    0.0   \n",
      "..                           ...                    ...   \n",
      "699                          0.0                    0.0   \n",
      "700                          0.0                    0.0   \n",
      "701                          0.0                    0.0   \n",
      "702                          0.0                    0.0   \n",
      "703                          0.0                    0.0   \n",
      "\n",
      "     contry_of_res_Viet Nam  relation_Health care professional  \\\n",
      "0                       0.0                                0.0   \n",
      "1                       0.0                                0.0   \n",
      "2                       0.0                                0.0   \n",
      "3                       0.0                                0.0   \n",
      "4                       0.0                                0.0   \n",
      "..                      ...                                ...   \n",
      "699                     0.0                                0.0   \n",
      "700                     0.0                                0.0   \n",
      "701                     0.0                                0.0   \n",
      "702                     0.0                                0.0   \n",
      "703                     0.0                                0.0   \n",
      "\n",
      "     relation_Others  relation_Parent  relation_Relative  relation_Self  \\\n",
      "0                0.0              0.0                0.0            1.0   \n",
      "1                0.0              0.0                0.0            1.0   \n",
      "2                0.0              1.0                0.0            0.0   \n",
      "3                0.0              0.0                0.0            1.0   \n",
      "4                0.0              0.0                0.0            0.0   \n",
      "..               ...              ...                ...            ...   \n",
      "699              0.0              0.0                0.0            1.0   \n",
      "700              0.0              1.0                0.0            0.0   \n",
      "701              0.0              0.0                0.0            0.0   \n",
      "702              0.0              0.0                0.0            1.0   \n",
      "703              0.0              0.0                0.0            1.0   \n",
      "\n",
      "     Class/ASD_YES  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              1.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "..             ...  \n",
      "699            1.0  \n",
      "700            0.0  \n",
      "701            1.0  \n",
      "702            0.0  \n",
      "703            1.0  \n",
      "\n",
      "[704 rows x 99 columns]\n",
      "\n",
      "Accuracy on testing dataset: 0.9929078014184397\n",
      "Scaled Feature Importance for Original Features:(Using Info Gain Attribute Evaluator)\n",
      "A1: 0.03304294032081263\n",
      "A2: 0.03304294032081261\n",
      "A3: 0.033042940320812605\n",
      "A4: 0.033042940320812626\n",
      "A5: 0.03304294032081265\n",
      "A6: 0.03304294032081265\n",
      "A7: 0.033042940320812626\n",
      "A8: 0.03304294032081261\n",
      "A9: 0.03304294032081264\n",
      "A10: 0.03304294032081262\n",
      "age: 0.03361644466298273\n",
      "jundice: 0.03304294032081262\n",
      "austim: 0.03304294032081267\n",
      "used: 0.03304294032081262\n",
      "result: 0.13409991926708914\n",
      "gender: 0.0\n",
      "ethnicity: 0.02493014777108822\n",
      "contry: 1.0\n",
      "relation: 0.18277566346193386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(\"D:\\\\Sem 6\\\\Mini Project\\\\autism+screening+adult\\\\Autism-Adult-Data.arff\")\n",
    "\n",
    "# Define data types mapping\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  # Assuming this is your target variable\n",
    "}\n",
    "\n",
    "# Replace missing value symbols ('?' or '') with NaN\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "\n",
    "# Convert nominal attributes to strings\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "\n",
    "# Convert dtype_mapping to list of tuples\n",
    "dtype_tuples = [(col, dtype_mapping[col]) for col in meta.names()]\n",
    "\n",
    "# Convert to DataFrame with specified data types\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "\n",
    "# Apply the specified data types\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "# Print columns and their types\n",
    "print(\"Columns and their types:\")\n",
    "print(df.dtypes)\n",
    "print('DataFrame:')\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Separate columns with nominal values into categorical_df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Separate remaining columns into non_categorical_df\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Check for missing values in columns with bool values\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    # Apply mean value imputation to float columns in non_categorical_df\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming categorical_df contains the one-hot encoded categorical columns\n",
    "# and non_categorical_df contains the bool and float columns\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "\n",
    "# Join encoded categorical columns with bool and float columns\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "\n",
    "# Display final DataFrame\n",
    "print(joined_df)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming joined_df contains the joined DataFrame\n",
    "\n",
    "# Separate features and labels\n",
    "X = joined_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = joined_df.iloc[:, -1]   # Labels (last column)\n",
    "\n",
    "# accuracy_list={}\n",
    "# Split the data into training and testing sets\n",
    "# for i in range(1,101):\n",
    "    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "    \n",
    "# Instantiate LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "    \n",
    "# Encode string labels into numerical values\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "# Now, you can calculate class counts\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "    \n",
    "# Calculate prior probabilities based on class proportions\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "    \n",
    "# Fit Gaussian distributions to the prior probabilities\n",
    "means = np.mean(prior_probabilities, axis=0)  # Calculate mean for each class\n",
    "variances = np.var(prior_probabilities, axis=0)  # Calculate variance for each class\n",
    "    \n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', QuantileTransformer(n_quantiles=84,output_distribution='uniform',subsample=350, random_state=15)),\n",
    "    ('oversampler', RandomOverSampler(random_state=4)),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='lsqr',shrinkage=0.25,priors=prior_probabilities, store_covariance=True, tol=0.00009))\n",
    "])\n",
    "    \n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "    \n",
    "# Perform 10-fold cross-validation on training data\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "    \n",
    "# Evaluate the model on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy on testing dataset:\", accuracy)\n",
    "# accuracy_list[i]=accuracy\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Define the number of features to select based on Information Gain\n",
    "k = 'all'  # Adjust as needed\n",
    "\n",
    "# Instantiate the SelectKBest transformer with mutual_info_classif as the scoring function\n",
    "ig_selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "\n",
    "# Fit the SelectKBest transformer on the training data\n",
    "X_train_selected = ig_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = ig_selector.get_support(indices=True)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X_train.columns[selected_feature_indices]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Train the LDA model using the selected features\n",
    "lda = LinearDiscriminantAnalysis(solver='svd', priors=prior_probabilities, store_covariance=True, tol=0.99999999)\n",
    "lda.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the feature importance of each selected feature\n",
    "feature_importance = lda.coef_[0]\n",
    "\n",
    "original_feature_importance = {}\n",
    "\n",
    "# Sum up the feature importances for original features\n",
    "for feature_name, importance in zip(feature_names, lda.coef_[0]):\n",
    "    original_feature_name = feature_name.split('_')[0]  # Extract original feature name\n",
    "    if original_feature_name not in original_feature_importance:\n",
    "        original_feature_importance[original_feature_name] = importance\n",
    "    else:\n",
    "        original_feature_importance[original_feature_name] += importance\n",
    "\n",
    "# Scale feature importances to be between 0 and 1 using Min-Max scaling\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_importance = scaler.fit_transform(pd.DataFrame(original_feature_importance.values()))\n",
    "\n",
    "# Print the scaled feature importance of each original feature\n",
    "print(\"Scaled Feature Importance for Original Features:(Using Info Gain Attribute Evaluator)\")\n",
    "for original_feature_name, importance in zip(original_feature_importance.keys(), scaled_importance):\n",
    "    print(f\"{original_feature_name}: {importance[0]}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c93a49a-c697-44dc-ad41-ee03f9e21553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_21188\\346580873.py:36: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_21188\\346580873.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_21188\\346580873.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and their types:\n",
      "A1_Score              bool\n",
      "A2_Score              bool\n",
      "A3_Score              bool\n",
      "A4_Score              bool\n",
      "A5_Score              bool\n",
      "A6_Score              bool\n",
      "A7_Score              bool\n",
      "A8_Score              bool\n",
      "A9_Score              bool\n",
      "A10_Score             bool\n",
      "age                float64\n",
      "gender              object\n",
      "ethnicity           object\n",
      "jundice               bool\n",
      "austim                bool\n",
      "contry_of_res       object\n",
      "used_app_before       bool\n",
      "result             float64\n",
      "age_desc            object\n",
      "relation            object\n",
      "Class/ASD           object\n",
      "dtype: object\n",
      "DataFrame:\n",
      "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
      "0        True      True      True      True      True      True      True   \n",
      "1        True      True      True      True      True      True      True   \n",
      "2        True      True      True      True      True      True      True   \n",
      "3        True      True      True      True      True      True      True   \n",
      "4        True      True      True      True      True      True      True   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "699      True      True      True      True      True      True      True   \n",
      "700      True      True      True      True      True      True      True   \n",
      "701      True      True      True      True      True      True      True   \n",
      "702      True      True      True      True      True      True      True   \n",
      "703      True      True      True      True      True      True      True   \n",
      "\n",
      "     A8_Score  A9_Score  A10_Score  ...  gender       ethnicity jundice  \\\n",
      "0        True      True       True  ...       f  White-European    True   \n",
      "1        True      True       True  ...       m          Latino    True   \n",
      "2        True      True       True  ...       m          Latino    True   \n",
      "3        True      True       True  ...       f  White-European    True   \n",
      "4        True      True       True  ...       f               ?    True   \n",
      "..        ...       ...        ...  ...     ...             ...     ...   \n",
      "699      True      True       True  ...       f  White-European    True   \n",
      "700      True      True       True  ...       m        Hispanic    True   \n",
      "701      True      True       True  ...       f               ?    True   \n",
      "702      True      True       True  ...       m     South Asian    True   \n",
      "703      True      True       True  ...       f  White-European    True   \n",
      "\n",
      "     austim  contry_of_res used_app_before  result     age_desc relation  \\\n",
      "0      True  United States            True     6.0  18 and more     Self   \n",
      "1      True         Brazil            True     5.0  18 and more     Self   \n",
      "2      True          Spain            True     8.0  18 and more   Parent   \n",
      "3      True  United States            True     6.0  18 and more     Self   \n",
      "4      True          Egypt            True     2.0  18 and more        ?   \n",
      "..      ...            ...             ...     ...          ...      ...   \n",
      "699    True         Russia            True     7.0  18 and more     Self   \n",
      "700    True         Mexico            True     3.0  18 and more   Parent   \n",
      "701    True         Russia            True     7.0  18 and more        ?   \n",
      "702    True       Pakistan            True     6.0  18 and more     Self   \n",
      "703    True         Cyprus            True     8.0  18 and more     Self   \n",
      "\n",
      "    Class/ASD  \n",
      "0          NO  \n",
      "1          NO  \n",
      "2         YES  \n",
      "3          NO  \n",
      "4          NO  \n",
      "..        ...  \n",
      "699       YES  \n",
      "700        NO  \n",
      "701       YES  \n",
      "702        NO  \n",
      "703       YES  \n",
      "\n",
      "[704 rows x 21 columns]\n",
      "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
      "0        True      True      True      True      True      True      True   \n",
      "1        True      True      True      True      True      True      True   \n",
      "2        True      True      True      True      True      True      True   \n",
      "3        True      True      True      True      True      True      True   \n",
      "4        True      True      True      True      True      True      True   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "699      True      True      True      True      True      True      True   \n",
      "700      True      True      True      True      True      True      True   \n",
      "701      True      True      True      True      True      True      True   \n",
      "702      True      True      True      True      True      True      True   \n",
      "703      True      True      True      True      True      True      True   \n",
      "\n",
      "     A8_Score  A9_Score  A10_Score  ...  contry_of_res_United Kingdom  \\\n",
      "0        True      True       True  ...                           0.0   \n",
      "1        True      True       True  ...                           0.0   \n",
      "2        True      True       True  ...                           0.0   \n",
      "3        True      True       True  ...                           0.0   \n",
      "4        True      True       True  ...                           0.0   \n",
      "..        ...       ...        ...  ...                           ...   \n",
      "699      True      True       True  ...                           0.0   \n",
      "700      True      True       True  ...                           0.0   \n",
      "701      True      True       True  ...                           0.0   \n",
      "702      True      True       True  ...                           0.0   \n",
      "703      True      True       True  ...                           0.0   \n",
      "\n",
      "     contry_of_res_United States  contry_of_res_Uruguay  \\\n",
      "0                            1.0                    0.0   \n",
      "1                            0.0                    0.0   \n",
      "2                            0.0                    0.0   \n",
      "3                            1.0                    0.0   \n",
      "4                            0.0                    0.0   \n",
      "..                           ...                    ...   \n",
      "699                          0.0                    0.0   \n",
      "700                          0.0                    0.0   \n",
      "701                          0.0                    0.0   \n",
      "702                          0.0                    0.0   \n",
      "703                          0.0                    0.0   \n",
      "\n",
      "     contry_of_res_Viet Nam  relation_Health care professional  \\\n",
      "0                       0.0                                0.0   \n",
      "1                       0.0                                0.0   \n",
      "2                       0.0                                0.0   \n",
      "3                       0.0                                0.0   \n",
      "4                       0.0                                0.0   \n",
      "..                      ...                                ...   \n",
      "699                     0.0                                0.0   \n",
      "700                     0.0                                0.0   \n",
      "701                     0.0                                0.0   \n",
      "702                     0.0                                0.0   \n",
      "703                     0.0                                0.0   \n",
      "\n",
      "     relation_Others  relation_Parent  relation_Relative  relation_Self  \\\n",
      "0                0.0              0.0                0.0            1.0   \n",
      "1                0.0              0.0                0.0            1.0   \n",
      "2                0.0              1.0                0.0            0.0   \n",
      "3                0.0              0.0                0.0            1.0   \n",
      "4                0.0              0.0                0.0            0.0   \n",
      "..               ...              ...                ...            ...   \n",
      "699              0.0              0.0                0.0            1.0   \n",
      "700              0.0              1.0                0.0            0.0   \n",
      "701              0.0              0.0                0.0            0.0   \n",
      "702              0.0              0.0                0.0            1.0   \n",
      "703              0.0              0.0                0.0            1.0   \n",
      "\n",
      "     Class/ASD_YES  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              1.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "..             ...  \n",
      "699            1.0  \n",
      "700            0.0  \n",
      "701            1.0  \n",
      "702            0.0  \n",
      "703            1.0  \n",
      "\n",
      "[704 rows x 99 columns]\n",
      "\n",
      "Accuracy on testing dataset: 0.9929078014184397\n",
      "Scaled Feature Importance for Original Features:(Using Info Gain Attribute Evaluator)\n",
      "A1: 0.016521470160406317\n",
      "A2: 0.016521470160406306\n",
      "A3: 0.016521470160406303\n",
      "A4: 0.016521470160406313\n",
      "A5: 0.016521470160406324\n",
      "A6: 0.016521470160406324\n",
      "A7: 0.016521470160406313\n",
      "A8: 0.016521470160406306\n",
      "A9: 0.01652147016040632\n",
      "A10: 0.01652147016040631\n",
      "age: 0.016808222331491363\n",
      "jundice: 0.01652147016040631\n",
      "austim: 0.016521470160406334\n",
      "used: 0.01652147016040631\n",
      "result: 0.06704995963354457\n",
      "gender: 0.0\n",
      "ethnicity: 0.01246507388554411\n",
      "contry: 0.5\n",
      "relation: 0.09138783173096693\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(\"D:\\\\Sem 6\\\\Mini Project\\\\autism+screening+adult\\\\Autism-Adult-Data.arff\")\n",
    "\n",
    "# Define data types mapping\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  # Assuming this is your target variable\n",
    "}\n",
    "\n",
    "# Replace missing value symbols ('?' or '') with NaN\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "\n",
    "# Convert nominal attributes to strings\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "\n",
    "# Convert dtype_mapping to list of tuples\n",
    "dtype_tuples = [(col, dtype_mapping[col]) for col in meta.names()]\n",
    "\n",
    "# Convert to DataFrame with specified data types\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "\n",
    "# Apply the specified data types\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "# Print columns and their types\n",
    "print(\"Columns and their types:\")\n",
    "print(df.dtypes)\n",
    "print('DataFrame:')\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Separate columns with nominal values into categorical_df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Separate remaining columns into non_categorical_df\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Check for missing values in columns with bool values\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    # Apply mean value imputation to float columns in non_categorical_df\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming categorical_df contains the one-hot encoded categorical columns\n",
    "# and non_categorical_df contains the bool and float columns\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "\n",
    "# Join encoded categorical columns with bool and float columns\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "\n",
    "# Display final DataFrame\n",
    "print(joined_df)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming joined_df contains the joined DataFrame\n",
    "\n",
    "# Separate features and labels\n",
    "X = joined_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = joined_df.iloc[:, -1]   # Labels (last column)\n",
    "\n",
    "# accuracy_list={}\n",
    "# Split the data into training and testing sets\n",
    "# for i in range(1,101):\n",
    "    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "    \n",
    "# Instantiate LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "    \n",
    "# Encode string labels into numerical values\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "# Now, you can calculate class counts\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "    \n",
    "# Calculate prior probabilities based on class proportions\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "    \n",
    "# Fit Gaussian distributions to the prior probabilities\n",
    "means = np.mean(prior_probabilities, axis=0)  # Calculate mean for each class\n",
    "variances = np.var(prior_probabilities, axis=0)  # Calculate variance for each class\n",
    "    \n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', QuantileTransformer(n_quantiles=84,output_distribution='uniform',subsample=350, random_state=15)),\n",
    "    ('oversampler', RandomOverSampler(random_state=4)),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='lsqr',shrinkage=0.25,priors=prior_probabilities, store_covariance=True, tol=0.00009))\n",
    "])\n",
    "    \n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "    \n",
    "# Perform 10-fold cross-validation on training data\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "    \n",
    "# Evaluate the model on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy on testing dataset:\", accuracy)\n",
    "# Define the custom gain ratio attribute evaluator function\n",
    "def gain_ratio_attribute_evaluator(X, y):\n",
    "    lda = LDA()\n",
    "    lda.fit(X, y)\n",
    "    projections = lda.transform(X)\n",
    "    \n",
    "    # Calculate mutual information for each feature\n",
    "    mutual_infos = []\n",
    "    for i in range(projections.shape[1]):\n",
    "        mi = mutual_info_score(projections[:, i], y)\n",
    "        mutual_infos.append(mi)\n",
    "    \n",
    "    # Calculate total mutual information\n",
    "    total_mi = sum(mutual_infos)\n",
    "    \n",
    "    # Calculate split information\n",
    "    split_info = -sum((np.sum(y == c) / len(y)) * np.log2(np.sum(y == c) / len(y)) for c in np.unique(y))\n",
    "    \n",
    "    # Calculate gain ratio for each feature\n",
    "    gain_ratios = []\n",
    "    for mi in mutual_infos:\n",
    "        gain_ratio = mi / split_info if split_info != 0 else 0\n",
    "        gain_ratios.append(gain_ratio)\n",
    "    \n",
    "    # Return gain ratios with None as p-values\n",
    "    return gain_ratios, [None] * len(gain_ratios)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Define the number of features to select based on Information Gain\n",
    "k = 'all'  # Adjust as needed\n",
    "\n",
    "# Instantiate the SelectKBest transformer with mutual_info_classif as the scoring function\n",
    "ig_selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "\n",
    "# Fit the SelectKBest transformer on the training data\n",
    "X_train_selected = ig_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_feature_indices = ig_selector.get_support(indices=True)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X_train.columns[selected_feature_indices]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Train the LDA model using the selected features\n",
    "lda = LinearDiscriminantAnalysis(solver='svd', priors=prior_probabilities, store_covariance=True, tol=0.99999999)\n",
    "lda.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the feature importance of each selected feature\n",
    "feature_importance = lda.coef_[0]\n",
    "\n",
    "original_feature_importance = {}\n",
    "\n",
    "# Sum up the feature importances for original features\n",
    "for feature_name, importance in zip(feature_names, lda.coef_[0]):\n",
    "    original_feature_name = feature_name.split('_')[0]  # Extract original feature name\n",
    "    if original_feature_name not in original_feature_importance:\n",
    "        original_feature_importance[original_feature_name] = importance\n",
    "    else:\n",
    "        original_feature_importance[original_feature_name] += importance\n",
    "\n",
    "# Scale feature importances to be between 0 and 1 using Min-Max scaling\n",
    "scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "scaled_importance = scaler.fit_transform(pd.DataFrame(original_feature_importance.values()))\n",
    "\n",
    "# Print the scaled feature importance of each original feature\n",
    "print(\"Scaled Feature Importance for Original Features:(Using Info Gain Attribute Evaluator)\")\n",
    "for original_feature_name, importance in zip(original_feature_importance.keys(), scaled_importance):\n",
    "    print(f\"{original_feature_name}: {importance[0]}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
