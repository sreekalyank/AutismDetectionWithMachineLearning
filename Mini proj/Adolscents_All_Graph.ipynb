{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0040310d-5c8a-4ace-ae3e-ce07028d0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88888889 1.         1.         0.875      1.         1.\n",
      " 0.75       0.75       1.         0.875     ]\n",
      "Mean CV accuracy: 0.913888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy with cross-validation: 0.9523809523809523\n",
      "printing precision\n",
      "0.9642857142857143\n",
      "f1-score\n",
      "0.9481481481481482\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "ROC AUC: 0.9663461538461539\n",
      "recall\n",
      "0.9375\n",
      "kappa score\n",
      "0.896551724137931\n",
      "log loss\n",
      "0.21421971853305724\n",
      "MCC\n",
      "0.9013878188659973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=10)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_qt_ab=test_accuracy_test\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a180e1-b5b7-46fe-bf23-d2bcb87dc1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Decision Tree): [0.88888889 1.         0.88888889 0.75       0.75       1.\n",
      " 0.875      0.875      1.         0.625     ]\n",
      "Mean CV accuracy (Decision Tree): 0.8652777777777778\n",
      "Testing Set Accuracy with cross-validation (Decision Tree): 0.9523809523809523\n",
      "printing precision\n",
      "0.9642857142857143\n",
      "f1-score\n",
      "0.9481481481481482\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "ROC AUC: 0.9375\n",
      "recall\n",
      "0.9375\n",
      "kappa score\n",
      "0.896551724137931\n",
      "log loss\n",
      "1.7163644471008168\n",
      "MCC\n",
      "0.9013878188659973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy',splitter='random',max_depth=None, min_samples_split=4,random_state=39)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training and testing\n",
    "pipeline_cv_dt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_dt = cross_val_score(pipeline_cv_dt, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Decision Tree):\", cv_scores_dt)\n",
    "print(\"Mean CV accuracy (Decision Tree):\", np.mean(cv_scores_dt))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_dt\n",
    "pipeline_cv_dt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test_dt = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Decision Tree):\", test_accuracy_test_dt)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_dt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_dt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_qt_dt=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_dt.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f27a11-6bf7-4e76-a8ec-5480673c7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Gaussian Naive Bayes): [0.88888889 0.88888889 0.88888889 0.875      0.875      0.875\n",
      " 1.         1.         1.         0.75      ]\n",
      "Mean CV accuracy (Gaussian Naive Bayes): 0.9041666666666666\n",
      "Testing Set Accuracy with cross-validation (Gaussian Naive Bayes): 0.9523809523809523\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9666666666666667\n",
      "F1 Score: 0.9442970822281167\n",
      "Recall: 0.9285714285714286\n",
      "Kappa Score: 0.8888888888888888\n",
      "Log Loss: 1.7163644471008168\n",
      "Matthews Correlation Coefficient: 0.8944271909999159\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import GaussianNB  # Import Gaussian Naive Bayes\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=40)\n",
    "\n",
    "\n",
    "# Define Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Gaussian Naive Bayes classifier for training and testing\n",
    "pipeline_cv_gnb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gnb)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_gnb = cross_val_score(pipeline_cv_gnb, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Gaussian Naive Bayes):\", cv_scores_gnb)\n",
    "print(\"Mean CV accuracy (Gaussian Naive Bayes):\", np.mean(cv_scores_gnb))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_gnb\n",
    "pipeline_cv_gnb.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_gnb.predict(X_test)\n",
    "test_accuracy_test_gnb = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Gaussian Naive Bayes):\", test_accuracy_test_gnb)\n",
    "accuracy_qt_gnb=test_accuracy_test_gnb\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_gnb.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d2c870-d9da-4fbf-a2f6-cd494a714121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (KNN): [0.88888889 0.77777778 0.44444444 0.88888889 1.         1.\n",
      " 0.875      1.         0.75       1.        ]\n",
      "Mean CV accuracy (KNN): 0.8625\n",
      "Testing Set Accuracy with cross-validation (KNN): 0.95\n",
      "printing precision\n",
      "0.9642857142857143\n",
      "f1-score\n",
      "0.9430199430199431\n",
      "Testing Set Accuracy without cross-validation: 0.95\n",
      "Testing Set Accuracy without cross-validation: 0.95\n",
      "ROC AUC: 0.956043956043956\n",
      "recall\n",
      "0.9285714285714286\n",
      "kappa score\n",
      "0.8863636363636364\n",
      "log loss\n",
      "0.27544444339485824\n",
      "MCC\n",
      "0.8921425711997711\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.19, random_state=42)\n",
    "\n",
    "\n",
    "# Define KNN classifier\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=5, weights='distance',algorithm='auto', p=3, n_jobs=3)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for training and testing\n",
    "pipeline_cv_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_knn = cross_val_score(pipeline_cv_knn, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (KNN):\", cv_scores_knn)\n",
    "print(\"Mean CV accuracy (KNN):\", np.mean(cv_scores_knn))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_knn\n",
    "pipeline_cv_knn.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test_knn = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (KNN):\", test_accuracy_test_knn)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_qt_knn=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_knn.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40eff7ae-fc74-49e3-85bd-cc537927cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\81392801.py:42: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\81392801.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\81392801.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation Accuracy (mean): 0.8866666666666667\n",
      "Accuracy on testing dataset(QT_LDA): 0.9615384615384616\n",
      "Other Parameters\n",
      "Precision : 0.9705882352941176\n",
      "Recall : 0.9705882352941176\n",
      "ROC AUC : 0.9575163398692811\n",
      "F1-score : 0.9705882352941176\n",
      "Kappa : 0.9150326797385621\n",
      "Log Loss : 1.3862943611198906\n",
      "MCC : 0.9150326797385621\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\autistic+spectrum+disorder+screening+data+for+adolescent\\\\Autism-Adolescent-Data.arff\")\n",
    "\n",
    "# Define data types mapping\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  # Assuming this is your target variable\n",
    "}\n",
    "\n",
    "# Replace missing value symbols ('?' or '') with NaN\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "\n",
    "# Convert nominal attributes to strings\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "\n",
    "# Convert to DataFrame with specified data types\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "\n",
    "# Apply the specified data types\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "# Separate columns with nominal values into categorical_df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Separate remaining columns into non_categorical_df\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Check for missing values in columns with bool values\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    # Apply mean value imputation to float columns in non_categorical_df\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "\n",
    "# Join encoded categorical columns with bool and float columns\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming joined_df contains the joined DataFrame\n",
    "\n",
    "# Separate features and labels\n",
    "X = joined_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = joined_df.iloc[:, -1]   # Labels (last column)\n",
    "\n",
    "accuracy_list={}\n",
    "# Split the data into training and testing sets\n",
    "  \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=210)\n",
    "        \n",
    "# Instantiate LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "        \n",
    "# Encode string labels into numerical values\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "        \n",
    "# Now, you can calculate class counts\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "        \n",
    "# Calculate prior probabilities based on class proportions\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "        \n",
    " # Fit Gaussian distributions to the prior probabilities\n",
    "means = np.mean(prior_probabilities, axis=0)  # Calculate mean for each class\n",
    "variances = np.var(prior_probabilities, axis=0)  # Calculate variance for each class\n",
    "        \n",
    "    # Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', QuantileTransformer(n_quantiles=35,output_distribution='uniform',subsample=60, random_state=91)),\n",
    "    ('oversampler', RandomOverSampler(random_state=12)),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='svd',priors=prior_probabilities, store_covariance=True, tol=0.99999999))\n",
    "])\n",
    "        \n",
    "    # Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "        \n",
    "    # Perform 10-fold cross-validation on training data\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=50)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "print(\"\\nCross-validation Accuracy (mean):\", accuracy_scores.mean())\n",
    "        \n",
    "    # Evaluate the model on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on testing dataset(QT_LDA):\", accuracy)\n",
    "accuracy_qt_lda=accuracy\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Cohen's kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "# Calculate log loss\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "\n",
    "# Calculate Matthews correlation coefficient (MCC)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Other Parameters\")\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"ROC AUC :\", roc_auc)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Kappa :\", kappa)\n",
    "print(\"Log Loss :\", logloss)\n",
    "print(\"MCC :\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "330a9368-d42e-4904-865a-9b09754c827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Logistic Regression): [1.  1.  1.  0.5 1.  1.  0.  1.  1.  1. ]\n",
      "Mean CV accuracy (Logistic Regression): 0.85\n",
      "Testing Set Accuracy with cross-validation (Logistic Regression): 0.9318181818181818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9226579520697167\n",
      "F1 Score: 0.9272727272727272\n",
      "Recall: 0.9330357142857143\n",
      "Kappa Score: 0.8546255506607929\n",
      "Log Loss: 0.3700342029344679\n",
      "Matthews Correlation Coefficient: 0.8556307338403571\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression  # Import Logistic Regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.84, random_state=41)\n",
    "\n",
    "\n",
    "# Define Logistic Regression classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Logistic Regression classifier for training and testing\n",
    "pipeline_cv_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_lr = cross_val_score(pipeline_cv_lr, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Logistic Regression):\", cv_scores_lr)\n",
    "print(\"Mean CV accuracy (Logistic Regression):\", np.mean(cv_scores_lr))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_lr\n",
    "pipeline_cv_lr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_lr.predict(X_test)\n",
    "test_accuracy_test_lr = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Logistic Regression):\", test_accuracy_test_lr)\n",
    "accuracy_qt_lr=test_accuracy_test_lr\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_lr.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f578e3a0-a212-4eb2-9ce5-cc2c63772ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88888889 0.88888889 1.         1.         0.88888889 0.88888889\n",
      " 1.         1.         1.         1.        ]\n",
      "Mean CV accuracy: 0.9555555555555555\n",
      "Testing Set Accuracy with cross-validation (Random Forest): 0.9285714285714286\n",
      "printing precision\n",
      "0.9545454545454546\n",
      "f1-score\n",
      "0.9047619047619047\n",
      "Testing Set Accuracy without cross-validation: 0.9285714285714286\n",
      "Testing Set Accuracy without cross-validation: 0.9285714285714286\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.875\n",
      "kappa score\n",
      "0.8108108108108107\n",
      "log loss\n",
      "0.4238944648710584\n",
      "MCC\n",
      "0.8257228238447705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.13, random_state=42)\n",
    "\n",
    "# Define Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest classifier for training and testing\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest)\n",
    "])\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline_rf, X_train, y_train, cv=10)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test_rf = pipeline_rf.predict(X_test)\n",
    "test_accuracy_test_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "print(\"Testing Set Accuracy with cross-validation (Random Forest):\", test_accuracy_test_rf)\n",
    "accuracy_qt_rf=test_accuracy_test_rf\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test_rf, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test_rf,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_test_rf = pipeline_rf.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test_rf)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_test_rf = pipeline_rf.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test_rf)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_rf_svm=test_accuracy_test\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test_rf,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test_rf))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_rf.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test_rf))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55883943-2c13-437d-b2a2-966d60ca3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (SVM): [0.8  0.5  0.75 1.   1.   1.   0.75 0.75 0.75 1.  ]\n",
      "Mean CV accuracy (SVM): 0.8300000000000001\n",
      "Testing Set Accuracy with cross-validation (SVM): 0.9206349206349206\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9375\n",
      "F1 Score: 0.9176470588235295\n",
      "Recall: 0.9107142857142857\n",
      "Kappa Score: 0.8363636363636364\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.svm import SVC  # Import SVM\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.6, random_state=36)\n",
    "\n",
    "# Define SVM classifier\n",
    "svm = SVC()  # Change here to SVC\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and SVM classifier for training and testing\n",
    "pipeline_cv_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svm)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_svm = cross_val_score(pipeline_cv_svm, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (SVM):\", cv_scores_svm)\n",
    "print(\"Mean CV accuracy (SVM):\", np.mean(cv_scores_svm))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_svm\n",
    "pipeline_cv_svm.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test_svm = pipeline_cv_svm.predict(X_test)\n",
    "test_accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "print(\"Testing Set Accuracy with cross-validation (SVM):\", test_accuracy_test_svm)\n",
    "accuracy_qt_svm=test_accuracy_test_svm\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test_svm))\n",
    "# Note: Log Loss, Matthews Correlation Coefficient, and ROC AUC Score might not be available for SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a96381-8cfd-4fd5-b83f-e2468b4fd82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.875      0.875      1.         1.         1.         0.875\n",
      " 0.875      0.875      0.85714286 0.71428571]\n",
      "Mean CV accuracy: 0.8946428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy with cross-validation: 0.9615384615384616\n",
      "printing precision\n",
      "0.9705882352941176\n",
      "f1-score\n",
      "0.9585326953748007\n",
      "Testing Set Accuracy without cross-validation: 0.9615384615384616\n",
      "Testing Set Accuracy without cross-validation: 0.9615384615384616\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.95\n",
      "kappa score\n",
      "0.9171974522292994\n",
      "log loss\n",
      "0.14847094446210707\n",
      "MCC\n",
      "0.9203579866168445\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.25, random_state=35)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer(method='yeo-johnson', standardize=False))\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_pt_ab=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d047b33a-158c-4ba8-9eb0-53c6a4536c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Decision Tree): [1.         0.77777778 0.88888889 1.         0.875      1.\n",
      " 1.         0.875      0.875      0.875     ]\n",
      "Mean CV accuracy (Decision Tree): 0.9166666666666666\n",
      "Testing Set Accuracy with cross-validation (Decision Tree): 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini',splitter='random',max_depth=None, min_samples_split=3,random_state=39)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer(method='yeo-johnson', standardize=False))  # Using PowerTransformer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training and testing\n",
    "pipeline_cv_dt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=35)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_dt = cross_val_score(pipeline_cv_dt, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Decision Tree):\", cv_scores_dt)\n",
    "print(\"Mean CV accuracy (Decision Tree):\", np.mean(cv_scores_dt))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_dt\n",
    "pipeline_cv_dt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test_dt = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test_dt = accuracy_score(y_test, y_pred_test_dt)\n",
    "print(\"Testing Set Accuracy with cross-validation (Decision Tree):\", test_accuracy_test_dt)\n",
    "accuracy_pt_dt=test_accuracy_test_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e7b36ae-64d7-4e50-9d76-dcf4eed00dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Gaussian Naive Bayes): [0.75       1.         0.875      1.         1.         0.875\n",
      " 0.875      1.         0.71428571 1.        ]\n",
      "Mean CV accuracy (Gaussian Naive Bayes): 0.9089285714285713\n",
      "Testing Set Accuracy with cross-validation (Gaussian Naive Bayes): 0.9615384615384616\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.96875\n",
      "F1 Score: 0.9600614439324117\n",
      "Recall: 0.9545454545454546\n",
      "Kappa Score: 0.9202453987730062\n",
      "Log Loss: 1.3867124348661606\n",
      "Matthews Correlation Coefficient: 0.9231861823449954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.25, random_state=38)\n",
    "\n",
    "# Define Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer(method='yeo-johnson', standardize=True))  # Changed QuantileTransformer to PowerTransformer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Gaussian Naive Bayes classifier for training and testing\n",
    "pipeline_cv_gnb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gnb)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_gnb = cross_val_score(pipeline_cv_gnb, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Gaussian Naive Bayes):\", cv_scores_gnb)\n",
    "print(\"Mean CV accuracy (Gaussian Naive Bayes):\", np.mean(cv_scores_gnb))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_gnb\n",
    "pipeline_cv_gnb.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_gnb.predict(X_test)\n",
    "test_accuracy_test_gnb = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Gaussian Naive Bayes):\", test_accuracy_test_gnb)\n",
    "accuracy_pt_gnb=test_accuracy_test_gnb\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_gnb.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "182691c3-1d54-4c60-bd30-a92e059ba2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (KNN): [0.8        1.         1.         1.         0.77777778 1.\n",
      " 0.55555556 0.77777778 0.88888889 0.88888889]\n",
      "Mean CV accuracy (KNN): 0.868888888888889\n",
      "Testing Set Accuracy with cross-validation (KNN): 0.9230769230769231\n",
      "printing precision\n",
      "0.95\n",
      "f1-score\n",
      "0.9022556390977443\n",
      "Testing Set Accuracy without cross-validation: 0.9230769230769231\n",
      "Testing Set Accuracy without cross-validation: 0.9230769230769231\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.875\n",
      "kappa score\n",
      "0.8059701492537313\n",
      "log loss\n",
      "0.15114283325617534\n",
      "MCC\n",
      "0.8215838362577492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.12, random_state=45)\n",
    "\n",
    "# Define KNN classifier\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=5, weights='distance', algorithm='auto', p=3, n_jobs=3)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer(method='yeo-johnson', standardize=False))  # Using PowerTransformer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for training and testing\n",
    "pipeline_cv_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_knn = cross_val_score(pipeline_cv_knn, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (KNN):\", cv_scores_knn)\n",
    "print(\"Mean CV accuracy (KNN):\", np.mean(cv_scores_knn))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_knn\n",
    "pipeline_cv_knn.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test_knn = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (KNN):\", test_accuracy_test_knn)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_pt_knn=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_knn.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "047175cc-e2ba-47a3-96f7-7945afb17490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\430977123.py:42: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\430977123.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\430977123.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation Accuracy (mean): 0.8714285714285713\n",
      "Accuracy on testing dataset(PT_LDA) : 0.9411764705882353\n",
      "Other Parameters\n",
      "Precision : 1.0\n",
      "Recall : 0.9047619047619048\n",
      "ROC AUC : 0.9523809523809523\n",
      "F1-score : 0.9500000000000001\n",
      "Kappa : 0.8790035587188613\n",
      "Log Loss : 2.1202149052421855\n",
      "MCC : 0.8855094489202158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\autistic+spectrum+disorder+screening+data+for+adolescent\\\\Autism-Adolescent-Data.arff\")\n",
    "\n",
    "# Define data types mapping\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  # Assuming this is your target variable\n",
    "}\n",
    "\n",
    "# Replace missing value symbols ('?' or '') with NaN\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "\n",
    "# Convert nominal attributes to strings\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "\n",
    "# Convert to DataFrame with specified data types\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "\n",
    "# Apply the specified data types\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "# Separate columns with nominal values into categorical_df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Separate remaining columns into non_categorical_df\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Check for missing values in columns with bool values\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    # Apply mean value imputation to float columns in non_categorical_df\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "\n",
    "# Join encoded categorical columns with bool and float columns\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "\n",
    "# Separate features and labels\n",
    "X = joined_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = joined_df.iloc[:, -1]   # Labels (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.32, random_state=42)\n",
    "\n",
    "# Instantiate LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode string labels into numerical values\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Calculate class counts and prior probabilities\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', PowerTransformer(method='yeo-johnson', standardize=True)),  # Power Transformer\n",
    "    ('oversampler', RandomOverSampler(random_state=12)),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='svd', priors=prior_probabilities, store_covariance=True, tol=0.99999999))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Perform 10-fold cross-validation on training data\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=50)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "print(\"\\nCross-validation Accuracy (mean):\", accuracy_scores.mean())\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy on testing dataset(PT_LDA) :\", accuracy)\n",
    "accuracy_pt_lda=accuracy\n",
    "print(\"Other Parameters\")\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"ROC AUC :\", roc_auc)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Kappa :\", kappa)\n",
    "print(\"Log Loss :\", logloss)\n",
    "print(\"MCC :\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "424370f1-cdc4-4162-8ba4-0f3bed0e670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Logistic Regression): [1.  1.  0.5 1.  1.  1.  1.  1.  1.  1. ]\n",
      "Mean CV accuracy (Logistic Regression): 0.95\n",
      "Testing Set Accuracy with cross-validation (Logistic Regression): 0.9529411764705882\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9492234169653524\n",
      "F1 Score: 0.9492234169653524\n",
      "Recall: 0.9492234169653524\n",
      "Kappa Score: 0.8984468339307049\n",
      "Log Loss: 0.22777608731666524\n",
      "Matthews Correlation Coefficient: 0.8984468339307049\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer  # Import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.81, random_state=41)\n",
    "\n",
    "# Define Logistic Regression classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer(method='yeo-johnson'))  # Change QuantileTransformer to PowerTransformer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Logistic Regression classifier for training and testing\n",
    "pipeline_cv_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_lr = cross_val_score(pipeline_cv_lr, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Logistic Regression):\", cv_scores_lr)\n",
    "print(\"Mean CV accuracy (Logistic Regression):\", np.mean(cv_scores_lr))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_lr\n",
    "pipeline_cv_lr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_lr.predict(X_test)\n",
    "test_accuracy_test_lr = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Logistic Regression):\", test_accuracy_test_lr)\n",
    "accuracy_pt_lr=test_accuracy_test_lr\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_lr.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e527c690-ce93-4b7a-88ac-dad8c719f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Random Forest with PowerTransformer): [0.88888889 0.88888889 1.         1.         0.88888889 0.88888889\n",
      " 1.         1.         1.         1.        ]\n",
      "Mean CV accuracy (Random Forest with PowerTransformer): 0.9555555555555555\n",
      "Testing Set Accuracy with cross-validation (Random Forest with PowerTransformer): 0.9285714285714286\n",
      "printing precision\n",
      "0.9545454545454546\n",
      "f1-score\n",
      "0.9047619047619047\n",
      "Testing Set Accuracy without cross-validation: 0.9285714285714286\n",
      "Testing Set Accuracy without cross-validation: 0.9285714285714286\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.875\n",
      "kappa score\n",
      "0.8108108108108107\n",
      "log loss\n",
      "0.4238944648710584\n",
      "MCC\n",
      "0.8257228238447705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.13, random_state=42)\n",
    "\n",
    "# Define Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer())\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest classifier for training and testing\n",
    "pipeline_rf_pt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest)\n",
    "])\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores_rf_pt = cross_val_score(pipeline_rf_pt, X_train, y_train, cv=10)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Random Forest with PowerTransformer):\", cv_scores_rf_pt)\n",
    "print(\"Mean CV accuracy (Random Forest with PowerTransformer):\", np.mean(cv_scores_rf_pt))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_rf_pt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_rf_pt.predict(X_test)\n",
    "test_accuracy_test_rf_pt = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Random Forest with PowerTransformer):\", test_accuracy_test_rf_pt)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf_pt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_rf_pt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf_pt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_rf_pt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_pt_rf=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_rf_pt.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "814b092d-674a-4fd5-bae1-e5069f39d435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (SVM): [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "Mean CV accuracy (SVM): 0.9\n",
      "Testing Set Accuracy with cross-validation (SVM): 0.9285714285714286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9482758620689655\n",
      "F1 Score: 0.9210031347962382\n",
      "Recall: 0.90625\n",
      "Kappa Score: 0.8428927680798005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PowerTransformer  # Updated import to PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.8, random_state=38)\n",
    "\n",
    "# Define SVM classifier\n",
    "svm = SVC()  # Change here to SVC\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('power', PowerTransformer(method='yeo-johnson'))  # Change QuantileTransformer to PowerTransformer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and SVM classifier for training and testing\n",
    "pipeline_cv_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svm)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_svm = cross_val_score(pipeline_cv_svm, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (SVM):\", cv_scores_svm)\n",
    "print(\"Mean CV accuracy (SVM):\", np.mean(cv_scores_svm))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_svm\n",
    "pipeline_cv_svm.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test_svm = pipeline_cv_svm.predict(X_test)\n",
    "test_accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "print(\"Testing Set Accuracy with cross-validation (SVM):\", test_accuracy_test_svm)\n",
    "accuracy_pt_svm=test_accuracy_test_svm\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test_svm))\n",
    "# Note: Log Loss, Matthews Correlation Coefficient, and ROC AUC Score might not be available for SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ee1e999-6fef-4e77-a7d8-e17911336fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.    0.875 1.    1.    1.    1.    0.875 1.    0.875 1.   ]\n",
      "Mean CV accuracy: 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy with cross-validation: 0.96\n",
      "printing precision\n",
      "0.9705882352941176\n",
      "f1-score\n",
      "0.9554367201426025\n",
      "Testing Set Accuracy without cross-validation: 0.96\n",
      "Testing Set Accuracy without cross-validation: 0.96\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.9444444444444444\n",
      "kappa score\n",
      "0.9110320284697508\n",
      "log loss\n",
      "0.3462486361697495\n",
      "MCC\n",
      "0.9146591207600472\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.24, random_state=35)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=32, learning_rate=0.1, algorithm='SAMME.R', random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_nor_ab=test_accuracy_test\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60f6b8c2-da49-484c-ab5a-fcdf4d9efed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Decision Tree): [1.         0.85714286 1.         1.         0.83333333 0.83333333\n",
      " 1.         0.83333333 0.66666667 0.66666667]\n",
      "Mean CV accuracy (Decision Tree): 0.869047619047619\n",
      "Testing Set Accuracy with cross-validation (Decision Tree): 0.9512195121951219\n",
      "printing precision\n",
      "0.9457671957671958\n",
      "f1-score\n",
      "0.9457671957671958\n",
      "Testing Set Accuracy without cross-validation: 0.9512195121951219\n",
      "Testing Set Accuracy without cross-validation: 0.9512195121951219\n",
      "ROC AUC: 0.9457671957671957\n",
      "recall\n",
      "0.9457671957671958\n",
      "kappa score\n",
      "0.8915343915343915\n",
      "log loss\n",
      "1.7582269945910807\n",
      "MCC\n",
      "0.8915343915343915\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.39, random_state=38)\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini',splitter='random',max_depth=None, min_samples_split=3,random_state=39)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training and testing\n",
    "pipeline_cv_dt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=35)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_dt = cross_val_score(pipeline_cv_dt, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Decision Tree):\", cv_scores_dt)\n",
    "print(\"Mean CV accuracy (Decision Tree):\", np.mean(cv_scores_dt))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_dt\n",
    "pipeline_cv_dt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test_dt = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Decision Tree):\", test_accuracy_test_dt)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_dt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_nor_dt=test_accuracy_test\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_dt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_dt.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fe1913c-dc7b-4947-a16d-e18ff095116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Gaussian Naive Bayes): [1.         1.         0.875      1.         1.         0.875\n",
      " 0.875      1.         0.71428571 1.        ]\n",
      "Mean CV accuracy (Gaussian Naive Bayes): 0.9339285714285713\n",
      "Testing Set Accuracy with cross-validation (Gaussian Naive Bayes): 0.9615384615384616\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.96875\n",
      "F1 Score: 0.9600614439324117\n",
      "Recall: 0.9545454545454546\n",
      "Kappa Score: 0.9202453987730062\n",
      "Log Loss: 1.4085261685492\n",
      "Matthews Correlation Coefficient: 0.9231861823449954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.25, random_state=38)\n",
    "\n",
    "# Define Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Changed PowerTransformer to Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Gaussian Naive Bayes classifier for training and testing\n",
    "pipeline_cv_gnb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gnb)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_gnb = cross_val_score(pipeline_cv_gnb, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Gaussian Naive Bayes):\", cv_scores_gnb)\n",
    "print(\"Mean CV accuracy (Gaussian Naive Bayes):\", np.mean(cv_scores_gnb))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_gnb\n",
    "pipeline_cv_gnb.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_gnb.predict(X_test)\n",
    "test_accuracy_test_gnb = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Gaussian Naive Bayes):\", test_accuracy_test_gnb)\n",
    "accuracy_nor_gnb=test_accuracy_test_gnb\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_gnb.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4363f501-b1ea-45af-a8ff-4fc2571a0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (KNN): [0.77777778 0.88888889 0.77777778 0.88888889 0.88888889 0.77777778\n",
      " 0.77777778 0.88888889 0.77777778 0.875     ]\n",
      "Mean CV accuracy (KNN): 0.8319444444444443\n",
      "Testing Set Accuracy with cross-validation (KNN): 0.9333333333333333\n",
      "printing precision\n",
      "0.9545454545454546\n",
      "f1-score\n",
      "0.9206349206349207\n",
      "Testing Set Accuracy without cross-validation: 0.9333333333333333\n",
      "Testing Set Accuracy without cross-validation: 0.9333333333333333\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.9\n",
      "kappa score\n",
      "0.8421052631578947\n",
      "log loss\n",
      "0.16215125302265554\n",
      "MCC\n",
      "0.8528028654224417\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.14, random_state=45)\n",
    "\n",
    "# Define KNN classifier\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=5, weights='distance', algorithm='auto', p=3, n_jobs=3)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Using Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for training and testing\n",
    "pipeline_cv_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_knn = cross_val_score(pipeline_cv_knn, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (KNN):\", cv_scores_knn)\n",
    "print(\"Mean CV accuracy (KNN):\", np.mean(cv_scores_knn))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_knn\n",
    "pipeline_cv_knn.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test_knn = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (KNN):\", test_accuracy_test_knn)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_knn.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_knn.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_nor_knn=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_knn.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9157d0d3-c098-49b0-bd68-0d30c01ea576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on testing dataset(Normalizer_LDA) : 0.9375\n",
      "Other Parameters\n",
      "Precision : 0.9\n",
      "Recall : 1.0\n",
      "ROC AUC : 0.9285714285714286\n",
      "F1-score : 0.9473684210526316\n",
      "Kappa : 0.8709677419354839\n",
      "Log Loss : 2.252728336819822\n",
      "MCC : 0.8783100656536799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\942203202.py:42: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\942203202.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\942203202.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\autistic+spectrum+disorder+screening+data+for+adolescent\\\\Autism-Adolescent-Data.arff\")\n",
    "\n",
    "# Define data types mapping\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  # Assuming this is your target variable\n",
    "}\n",
    "\n",
    "# Replace missing value symbols ('?' or '') with NaN\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "\n",
    "# Convert nominal attributes to strings\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "\n",
    "# Convert to DataFrame with specified data types\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "\n",
    "# Apply the specified data types\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "# Separate columns with nominal values into categorical_df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Separate remaining columns into non_categorical_df\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Check for missing values in columns with bool values\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    # Apply mean value imputation to float columns in non_categorical_df\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "\n",
    "# Join encoded categorical columns with bool and float columns\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "\n",
    "# Separate features and labels\n",
    "X = joined_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = joined_df.iloc[:, -1]   # Labels (last column)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=15)\n",
    "\n",
    "# Instantiate LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode string labels into numerical values\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', Normalizer()),  # Normalizer\n",
    "    ('oversampler', RandomOverSampler(random_state=4)),  # Oversampling for class imbalance\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.25, priors=None, store_covariance=True, tol=0.00009))  # LDA classifier\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "precision = precision_score(y_test_encoded, y_pred)\n",
    "recall = recall_score(y_test_encoded, y_pred)\n",
    "roc_auc = roc_auc_score(y_test_encoded, y_pred)\n",
    "f1 = f1_score(y_test_encoded, y_pred)\n",
    "kappa = cohen_kappa_score(y_test_encoded, y_pred)\n",
    "logloss = log_loss(y_test_encoded, y_pred)\n",
    "mcc = matthews_corrcoef(y_test_encoded, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nAccuracy on testing dataset(Normalizer_LDA) :\", accuracy)\n",
    "accuracy_nor_lda=accuracy\n",
    "print(\"Other Parameters\")\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)\n",
    "print(\"ROC AUC :\", roc_auc)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Kappa :\", kappa)\n",
    "print(\"Log Loss :\", logloss)\n",
    "print(\"MCC :\", mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85bc3bfd-daab-4110-985b-f7fb774cd9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Logistic Regression): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean CV accuracy (Logistic Regression): 1.0\n",
      "Testing Set Accuracy with cross-validation (Logistic Regression): 0.95\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9625\n",
      "F1 Score: 0.945635759589248\n",
      "Recall: 0.9347826086956521\n",
      "Kappa Score: 0.891566265060241\n",
      "Log Loss: 0.20682541399072735\n",
      "Matthews Correlation Coefficient: 0.8968544062928813\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.57, random_state=41)\n",
    "\n",
    "# Define Logistic Regression classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Changed PowerTransformer to Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Logistic Regression classifier for training and testing\n",
    "pipeline_cv_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_lr = cross_val_score(pipeline_cv_lr, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Logistic Regression):\", cv_scores_lr)\n",
    "print(\"Mean CV accuracy (Logistic Regression):\", np.mean(cv_scores_lr))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_lr\n",
    "pipeline_cv_lr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_lr.predict(X_test)\n",
    "test_accuracy_test_lr = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Logistic Regression):\", test_accuracy_test_lr)\n",
    "accuracy_nor_lr=test_accuracy_test_lr\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_lr.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd27fcd6-bb40-4a61-a40e-587d88ddfcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88888889 0.88888889 0.88888889 0.77777778 1.         1.\n",
      " 0.77777778 1.         1.         1.        ]\n",
      "Mean CV accuracy: 0.9222222222222222\n",
      "Testing Set Accuracy with cross-validation (Random Forest with Normalizer): 0.9411764705882353\n",
      "printing precision\n",
      "0.9285714285714286\n",
      "f1-score\n",
      "0.9377289377289377\n",
      "Testing Set Accuracy without cross-validation: 0.9411764705882353\n",
      "Testing Set Accuracy without cross-validation: 0.9411764705882353\n",
      "ROC AUC: 0.9848484848484849\n",
      "recall\n",
      "0.9545454545454546\n",
      "kappa score\n",
      "0.8759124087591241\n",
      "log loss\n",
      "0.34211958145284127\n",
      "MCC\n",
      "0.8827348295047495\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.16, random_state=42)\n",
    "\n",
    "# Define Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalize', Normalizer())\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest classifier for training and testing\n",
    "pipeline_rf_normalize = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest)\n",
    "])\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline_rf_normalize, X_train, y_train, cv=10)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_rf_normalize.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_rf_normalize.predict(X_test)\n",
    "test_accuracy_test_rf_normalize = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Random Forest with Normalizer):\", test_accuracy_test_rf_normalize)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf_normalize.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_rf_normalize.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf_normalize.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_rf_normalize.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_nor_rf=test_accuracy_test\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_rf_normalize.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f24726de-482f-42ab-b0df-a2e7689eeeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (SVM): [1.    1.    1.    1.    1.    0.875 1.    1.    1.    1.   ]\n",
      "Mean CV accuracy (SVM): 0.9875\n",
      "Testing Set Accuracy with cross-validation (SVM): 0.9615384615384616\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9722222222222222\n",
      "F1 Score: 0.9563025210084033\n",
      "Recall: 0.9444444444444444\n",
      "Kappa Score: 0.912751677852349\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.25, random_state=40)\n",
    "\n",
    "# Define SVM classifier\n",
    "svm = SVC()  # Change here to SVC\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalizer', Normalizer())  # Changed PowerTransformer to Normalizer\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and SVM classifier for training and testing\n",
    "pipeline_cv_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svm)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_svm = cross_val_score(pipeline_cv_svm, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (SVM):\", cv_scores_svm)\n",
    "print(\"Mean CV accuracy (SVM):\", np.mean(cv_scores_svm))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_svm\n",
    "pipeline_cv_svm.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test_svm = pipeline_cv_svm.predict(X_test)\n",
    "test_accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "print(\"Testing Set Accuracy with cross-validation (SVM):\", test_accuracy_test_svm)\n",
    "accuracy_nor_svm=test_accuracy_test_svm\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test_svm))\n",
    "# Note: Log Loss, Matthews Correlation Coefficient, and ROC AUC Score might not be available for SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0d46fa4-e777-4381-8d16-119eb2edcf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (AdaBoost with MaxAbsScaler): [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.85714286 1.        ]\n",
      "Mean CV accuracy (AdaBoost with MaxAbsScaler): 0.9857142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy with cross-validation (AdaBoost with MaxAbsScaler): 0.9696969696969697\n",
      "printing precision\n",
      "0.9761904761904762\n",
      "f1-score\n",
      "0.9678048780487805\n",
      "Testing Set Accuracy without cross-validation: 0.9696969696969697\n",
      "Testing Set Accuracy without cross-validation: 0.9696969696969697\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.9615384615384616\n",
      "kappa score\n",
      "0.935672514619883\n",
      "log loss\n",
      "0.05749336966060032\n",
      "MCC\n",
      "0.9376144618769908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.31, random_state=42)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2), n_estimators=100, learning_rate=0.1, algorithm='SAMME.R', random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', MaxAbsScaler())\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training and testing\n",
    "pipeline_cv_mas = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv_mas, X_train, y_train, cv=cv)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (AdaBoost with MaxAbsScaler):\", cv_scores)\n",
    "print(\"Mean CV accuracy (AdaBoost with MaxAbsScaler):\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv_mas.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_mas.predict(X_test)\n",
    "test_accuracy_test_mas = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (AdaBoost with MaxAbsScaler):\", test_accuracy_test_mas)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_mas.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_mas.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_mas.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_mas.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_mas_ab=test_accuracy_test\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_mas.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a95147-6ccc-47d9-8417-af4b039479ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Decision Tree with MaxAbsScaler): [0.77777778 0.77777778 1.         0.625      0.625      0.875\n",
      " 0.875      0.875      0.75       0.75      ]\n",
      "Mean CV accuracy (Decision Tree with MaxAbsScaler): 0.7930555555555555\n",
      "Testing Set Accuracy with cross-validation (Decision Tree with MaxAbsScaler): 0.9545454545454546\n",
      "printing precision\n",
      "0.9705882352941176\n",
      "f1-score\n",
      "0.9393939393939394\n",
      "Testing Set Accuracy without cross-validation: 0.9545454545454546\n",
      "Testing Set Accuracy without cross-validation: 0.9545454545454546\n",
      "ROC AUC: 0.9166666666666667\n",
      "recall\n",
      "0.9166666666666667\n",
      "kappa score\n",
      "0.8791208791208791\n",
      "log loss\n",
      "0.23632183443029042\n",
      "MCC\n",
      "0.8856148855400954\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.21, random_state=45)\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy', splitter='random', max_depth=2, min_samples_split=2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', MaxAbsScaler())\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training and testing\n",
    "pipeline_cv_dt = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv_dt, X_train, y_train, cv=cv)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Decision Tree with MaxAbsScaler):\", cv_scores)\n",
    "print(\"Mean CV accuracy (Decision Tree with MaxAbsScaler):\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv_dt.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test_dt = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Decision Tree with MaxAbsScaler):\", test_accuracy_test_dt)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_dt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_cv_dt.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_cv_dt.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_mas_dt=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_cv_dt.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cbff7cd-1cf3-4908-9358-593557b2d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Gaussian Naive Bayes): [0.85714286 0.85714286 0.83333333 0.83333333 1.         0.83333333\n",
      " 1.         0.83333333 1.         1.        ]\n",
      "Mean CV accuracy (Gaussian Naive Bayes): 0.9047619047619048\n",
      "Testing Set Accuracy with cross-validation (Gaussian Naive Bayes): 0.9285714285714286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9516129032258065\n",
      "F1 Score: 0.9145762711864407\n",
      "Recall: 0.8928571428571428\n",
      "Kappa Score: 0.8301886792452831\n",
      "Log Loss: 2.480404201968371\n",
      "Matthews Correlation Coefficient: 0.842423539174232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.4, random_state=38)\n",
    "\n",
    "# Define Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('maxabs', MaxAbsScaler())  # Changed PowerTransformer to MaxAbsScaler\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Gaussian Naive Bayes classifier for training and testing\n",
    "pipeline_cv_gnb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gnb)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_gnb = cross_val_score(pipeline_cv_gnb, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Gaussian Naive Bayes):\", cv_scores_gnb)\n",
    "print(\"Mean CV accuracy (Gaussian Naive Bayes):\", np.mean(cv_scores_gnb))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_gnb\n",
    "pipeline_cv_gnb.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_gnb.predict(X_test)\n",
    "test_accuracy_test_gnb = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Gaussian Naive Bayes):\", test_accuracy_test_gnb)\n",
    "accuracy_mas_gnb=test_accuracy_test_gnb\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_gnb.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a517aff3-c8f4-4253-a611-34584b37cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (KNN with MaxAbsScaler): [0.88888889 0.77777778 0.77777778 0.75       1.         0.875\n",
      " 0.75       0.875      0.875      0.75      ]\n",
      "Mean CV accuracy (KNN with MaxAbsScaler): 0.8319444444444445\n",
      "Testing Set Accuracy with cross-validation (KNN with MaxAbsScaler): 0.9523809523809523\n",
      "printing precision\n",
      "0.96875\n",
      "f1-score\n",
      "0.9384164222873901\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "ROC AUC: 0.9888888888888889\n",
      "recall\n",
      "0.9166666666666667\n",
      "kappa score\n",
      "0.8771929824561403\n",
      "log loss\n",
      "0.15911151468709372\n",
      "MCC\n",
      "0.8838834764831843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=45)\n",
    "\n",
    "# Define KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', MaxAbsScaler())\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for training and testing\n",
    "pipeline_knn_mas = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_knn_mas, X_train, y_train, cv=cv)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (KNN with MaxAbsScaler):\", cv_scores)\n",
    "print(\"Mean CV accuracy (KNN with MaxAbsScaler):\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_knn_mas.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test= pipeline_knn_mas.predict(X_test)\n",
    "test_accuracy_test_knn_mas = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (KNN with MaxAbsScaler):\", test_accuracy_test_knn_mas)\n",
    "from sklearn.metrics import precision_score, f1_score, roc_curve, auc, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# # F1 Score\n",
    "print(f1_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (your existing code)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_knn_mas.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_knn_mas.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_knn_mas.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_knn_mas.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_mas_knn=test_accuracy_test\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# # Recall\n",
    "print(recall_score(y_test, y_pred_test,average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# # Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# # Log Loss\n",
    "print(log_loss(y_test, pipeline_knn_mas.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# # Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22716e38-7e6a-4731-8611-8bdd4b830828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\3922384378.py:36: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  data[attr][data[attr] == ''] = np.nan\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\3922384378.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categorical_df[col].fillna(mode_val, inplace=True)\n",
      "C:\\Users\\shanm\\AppData\\Local\\Temp\\ipykernel_13460\\3922384378.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation Accuracy (mean): 0.8678571428571429\n",
      "\n",
      "Accuracy on testing dataset:(MAS_LDA) 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\autistic+spectrum+disorder+screening+data+for+adolescent\\\\Autism-Adolescent-Data.arff\")\n",
    "\n",
    "# Define data types mapping\n",
    "dtype_mapping = {\n",
    "    'A1_Score': 'bool',\n",
    "    'A2_Score': 'bool',\n",
    "    'A3_Score': 'bool',\n",
    "    'A4_Score': 'bool',\n",
    "    'A5_Score': 'bool',\n",
    "    'A6_Score': 'bool',\n",
    "    'A7_Score': 'bool',\n",
    "    'A8_Score': 'bool',\n",
    "    'A9_Score': 'bool',\n",
    "    'A10_Score': 'bool',\n",
    "    'age': 'float',\n",
    "    'gender': 'str',\n",
    "    'ethnicity': 'str',\n",
    "    'jundice': 'bool',\n",
    "    'austim': 'bool',\n",
    "    'contry_of_res': 'str',\n",
    "    'used_app_before': 'bool',\n",
    "    'result': 'float',\n",
    "    'age_desc': 'str',\n",
    "    'relation': 'str',\n",
    "    'Class/ASD': 'str'  # Assuming this is your target variable\n",
    "}\n",
    "\n",
    "# Replace missing value symbols ('?' or '') with NaN\n",
    "for attr in meta.names():\n",
    "    data[attr] = np.char.strip(np.char.mod('%s', data[attr].astype(str)))\n",
    "    data[attr][data[attr] == ''] = np.nan\n",
    "\n",
    "# Convert nominal attributes to strings\n",
    "for attr in meta.names():\n",
    "    if meta[attr][0] == 'nominal':\n",
    "        data[attr] = data[attr].astype(str)\n",
    "\n",
    "# Convert dtype_mapping to list of tuples\n",
    "dtype_tuples = [(col, dtype_mapping[col]) for col in meta.names()]\n",
    "\n",
    "# Convert to DataFrame with specified data types\n",
    "df = pd.DataFrame(data, columns=meta.names())\n",
    "\n",
    "# Apply the specified data types\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "# Print columns and their types\n",
    "# print(\"Columns and their types:\")\n",
    "# print(df.dtypes)\n",
    "# print('DataFrame:')\n",
    "# print(df)\n",
    "\n",
    "\n",
    "# Separate columns with nominal values into categorical_df\n",
    "nominal_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "categorical_df = df[nominal_columns]\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "for col in categorical_df.columns:\n",
    "    mode_val = categorical_df[col].mode()[0]\n",
    "    categorical_df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Separate remaining columns into non_categorical_df\n",
    "non_categorical_columns = [col for col in df.columns if col not in nominal_columns]\n",
    "non_categorical_df = df[non_categorical_columns]\n",
    "\n",
    "# Check for missing values in columns with bool values\n",
    "bool_columns_with_missing = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'bool' and non_categorical_df[col].isnull().any()]\n",
    "if bool_columns_with_missing:\n",
    "    print(\"Missing values found in columns with bool values. Cannot proceed with mean value imputation.\")\n",
    "else:\n",
    "    # Apply mean value imputation to float columns in non_categorical_df\n",
    "    float_columns = [col for col in non_categorical_df.columns if non_categorical_df[col].dtype == 'float64']\n",
    "    non_categorical_df[float_columns] = non_categorical_df[float_columns].fillna(non_categorical_df[float_columns].mean())\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming categorical_df contains the one-hot encoded categorical columns\n",
    "# and non_categorical_df contains the bool and float columns\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_data = encoder.fit_transform(categorical_df)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_df.columns))\n",
    "\n",
    "# Join encoded categorical columns with bool and float columns\n",
    "joined_df = pd.concat([non_categorical_df, encoded_df], axis=1)\n",
    "\n",
    "# Display final DataFrame\n",
    "# print(joined_df)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming joined_df contains the joined DataFrame\n",
    "\n",
    "# Separate features and labels\n",
    "X = joined_df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = joined_df.iloc[:, -1]   # Labels (last column)\n",
    "   \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.28, random_state=15)\n",
    "    \n",
    "# Instantiate LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "    \n",
    "# Encode string labels into numerical values\n",
    "labels_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "# Now, you can calculate class counts\n",
    "class_counts = np.bincount(labels_encoded)\n",
    "    \n",
    "# Calculate prior probabilities based on class proportions\n",
    "prior_probabilities = class_counts / len(labels_encoded)\n",
    "    \n",
    "# Fit Gaussian distributions to the prior probabilities\n",
    "means = np.mean(prior_probabilities, axis=0)  # Calculate mean for each class\n",
    "variances = np.var(prior_probabilities, axis=0)  # Calculate variance for each class\n",
    "    \n",
    "# ... (your code till separating features and labels)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('normalizer', Normalizer()),  # Normalizer\n",
    "    ('oversampler', RandomOverSampler(random_state=4)),  # Oversampling for class imbalance\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.25, priors=None, store_covariance=True, tol=0.00009))  # LDA classifier\n",
    "])\n",
    "# Note: priors argument in LDA is set to None as class probabilities are not explicitly provided.\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Perform 10-fold cross-validation on training data (optional for evaluation)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracy_scores = cross_val_score(pipeline, X_train, y_train, cv=cv)\n",
    "print(\"\\nCross-validation Accuracy (mean):\", accuracy_scores.mean())\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy on testing dataset:(MAS_LDA)\", accuracy)\n",
    "accuracy_mas_lda=accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92017066-d135-4adc-b6cb-176a8eb2c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Logistic Regression): [0.5 1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n",
      "Mean CV accuracy (Logistic Regression): 0.95\n",
      "Testing Set Accuracy with cross-validation (Logistic Regression): 0.9166666666666666\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9119122257053291\n",
      "F1 Score: 0.9085678743585757\n",
      "Recall: 0.9055555555555556\n",
      "Kappa Score: 0.8171641791044776\n",
      "Log Loss: 0.25367439669520475\n",
      "Matthews Correlation Coefficient: 0.8174430659955473\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16,17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.8, random_state=41)\n",
    "\n",
    "# Define Logistic Regression classifier\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('maxabs', MaxAbsScaler())  # Changed PowerTransformer to MaxAbsScaler\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Logistic Regression classifier for training and testing\n",
    "pipeline_cv_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_lr = cross_val_score(pipeline_cv_lr, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (Logistic Regression):\", cv_scores_lr)\n",
    "print(\"Mean CV accuracy (Logistic Regression):\", np.mean(cv_scores_lr))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_lr\n",
    "pipeline_cv_lr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_cv_lr.predict(X_test)\n",
    "test_accuracy_test_lr = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Logistic Regression):\", test_accuracy_test_lr)\n",
    "accuracy_mas_lr=test_accuracy_test_lr\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test))\n",
    "print(\"Log Loss:\", log_loss(y_test, pipeline_cv_lr.predict_proba(X_test)))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "021792d6-73c0-40db-8eff-8dd174dfd30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.88888889 1.         0.88888889 0.875      1.         0.875\n",
      " 1.         1.         1.         1.        ]\n",
      "Mean CV accuracy: 0.9527777777777778\n",
      "Testing Set Accuracy with cross-validation (Random Forest with MaxAbsScaler): 0.9523809523809523\n",
      "printing precision\n",
      "0.9583333333333333\n",
      "f1-score\n",
      "0.9519450800915332\n",
      "Testing Set Accuracy without cross-validation: 0.9523809523809523\n",
      "ROC AUC: 1.0\n",
      "recall\n",
      "0.95\n",
      "kappa score\n",
      "0.904109589041096\n",
      "log loss\n",
      "0.45084715471535053\n",
      "MCC\n",
      "0.9082951062292475\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=43)\n",
    "\n",
    "# Define Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('normalize', MaxAbsScaler())\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest classifier for training and testing\n",
    "pipeline_rf_mas = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest)\n",
    "])\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline_rf_mas, X_train, y_train, cv=10)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_rf_mas.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_rf_mas.predict(X_test)\n",
    "test_accuracy_test_rf_mas = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy with cross-validation (Random Forest with MaxAbsScaler):\", test_accuracy_test_rf_mas)\n",
    "\n",
    "from sklearn.metrics import precision_score, f1_score, roc_auc_score, recall_score, cohen_kappa_score, log_loss, matthews_corrcoef\n",
    "\n",
    "print(\"printing precision\")\n",
    "print(precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score\")\n",
    "\n",
    "# F1 Score\n",
    "print(f1_score(y_test, y_pred_test, average='macro'))\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_prob_test = pipeline_rf_mas.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = pipeline_rf_mas.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n",
    "accuracy_mas_rf=test_accuracy_test\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "print('recall')\n",
    "# Recall\n",
    "print(recall_score(y_test, y_pred_test, average='macro'))\n",
    "\n",
    "print('kappa score')\n",
    "# Kappa Score\n",
    "print(cohen_kappa_score(y_test, y_pred_test))\n",
    "\n",
    "print('log loss')\n",
    "# Log Loss\n",
    "print(log_loss(y_test, pipeline_rf_mas.predict_proba(X_test)))\n",
    "\n",
    "print('MCC')\n",
    "# Matthews Correlation Coefficient\n",
    "print(matthews_corrcoef(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a0c4af8-5331-4ebb-82c3-9c0778f31e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (SVM): [1.   0.75 1.   1.   0.75 1.   1.   1.   1.   1.  ]\n",
      "Mean CV accuracy (SVM): 0.95\n",
      "Testing Set Accuracy with cross-validation (SVM): 0.9552238805970149\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision: 0.9659090909090908\n",
      "F1 Score: 0.9517406962785113\n",
      "Recall: 0.9423076923076923\n",
      "Kappa Score: 0.9036895064686152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler  # Updated import\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, cohen_kappa_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\shanm\\\\OneDrive\\\\Desktop\\\\csv_result-Autism-Adolescent-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-9:], axis=1, inplace=True)\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.64, random_state=38)\n",
    "\n",
    "# Define SVM classifier\n",
    "svm = SVC()  # Change here to SVC\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('maxabs', MaxAbsScaler())  # Changed PowerTransformer to MaxAbsScaler\n",
    "        ]), ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), category_encoded_columns)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and SVM classifier for training and testing\n",
    "pipeline_cv_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svm)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores_svm = cross_val_score(pipeline_cv_svm, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores (SVM):\", cv_scores_svm)\n",
    "print(\"Mean CV accuracy (SVM):\", np.mean(cv_scores_svm))\n",
    "\n",
    "# Train the model on the entire training set using pipeline_cv_svm\n",
    "pipeline_cv_svm.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test_svm = pipeline_cv_svm.predict(X_test)\n",
    "test_accuracy_test_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "print(\"Testing Set Accuracy with cross-validation (SVM):\", test_accuracy_test_svm)\n",
    "accuracy_mas_svm=test_accuracy_test_svm\n",
    "for i in range(5):\n",
    "    print()\n",
    "# Calculate and print additional evaluation metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test_svm, average='macro'))\n",
    "print(\"Kappa Score:\", cohen_kappa_score(y_test, y_pred_test_svm))\n",
    "# Note: Log Loss, Matthews Correlation Coefficient, and ROC AUC Score might not be available for SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b267cc4-63de-47a8-bd4b-8d85a1a7e866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd1zU9R/A8dcNjmPvpaIIDsC9c29xVGpqZcM9MivbpVmWZv7amblXppZlmpq5NffeWxEQRGXvDXff3x9fOSFAAYE78PN8PHiId5/v9/u+Ow7e9xnvj0KSJAlBEARBEASh0lMaOwBBEARBEAShbIjEThAEQRAEoYoQiZ0gCIIgCEIVIRI7QRAEQRCEKkIkdoIgCIIgCFWESOwEQRAEQRCqCJHYCYIgCIIgVBEisRMEQRAEQagiRGInCIIgCIJQRYjEThCqqMjISAYPHoyTkxMKhYIffvjB2CEVMGLECLy8vEp1bJcuXejSpUuZxGHqz9XNmzdRKBT8/PPP+W7ftm0bTZs2RavVolAoSEhIAGDlypX4+vpiZmaGvb19hccr3FfUayQI5UUkdoJRzJs3D4VCQZs2bYwdSpX11ltvsX37diZPnszKlSvp3bt3kW0VCgUKhYIxY8YUev9HH31kaBMTE1NeIRtNSZ6rspD7XCoUCtRqNY6OjrRo0YJJkyZx+fLlYp0jNjaWZ599FgsLC+bOncvKlSuxsrLi6tWrjBgxAh8fHxYvXsyiRYvK9bE8isuXL/Ppp59y8+bNB7bLTWyL8/Wwc1Wkol4jQShPamMHIDyeVq9ejZeXF8ePH+fGjRvUqVPH2CFVOXv27KF///68++67xWqv1WpZt24d8+bNQ6PR5Lvvt99+Q6vVkpGRUR6hGl1Jn6uy0LNnT4YNG4YkSSQmJnLu3DlWrFjBvHnz+PLLL3n77bcNbWvVqkV6ejpmZmaG206cOEFycjIzZsygR48ehtv37t2LXq9n9uzZJv++unz5Mp999hldunR5YM+ti4sLK1euzHfbt99+S3h4ON9//32BtqaiqNdIEMqTSOyEChcSEsLhw4dZv34948ePZ/Xq1UybNs3YYRUqNTW10n7CjoqKKtEwXO/evdm0aRNbt26lf//+htsPHz5MSEgIgwYNYt26deUQqfGV9Ll6mIyMDDQaDUpl0YMi9erV46WXXsp32//+9z+eeuop3nnnHXx9fenbty8g9/BptdoCMQMF4i7q9kdh7PeBlZVVgedqzZo1xMfHF7g9L0mSyMjIwMLCorxDLFRVfC1MJQahaGIoVqhwq1evxsHBgX79+jF48GBWr15daLuEhATeeustvLy8MDc3p0aNGgwbNizfUGBGRgaffvop9erVQ6vV4uHhwTPPPENQUBAg914oFAr27t2b79yFzVkaMWIE1tbWBAUF0bdvX2xsbHjxxRcBOHDgAEOGDKFmzZqYm5vj6enJW2+9RXp6eoG4r169yrPPPouLiwsWFhbUr1+fjz76CIB///0XhULBX3/9VeC4X3/9FYVCwZEjRx74/AUHBzNkyBAcHR2xtLTkiSee4J9//jHc//PPP6NQKJAkiblz5xqGqB6mevXqdOrUiV9//TXf7atXr6ZRo0Y0bNiw0OPWrl1LixYtsLCwwNnZmZdeeonbt28XaLdhwwYaNmyIVqulYcOGhT4HAHq9nh9++IEGDRqg1Wpxc3Nj/PjxxMfHP/QxzJkzhwYNGmBpaYmDgwMtW7Ys8Hjyethz9bDnGu7/jK1Zs4apU6dSvXp1LC0tSUpKemi8/+Xk5MSaNWtQq9XMnDnTcPt/f167dOnC8OHDAWjVqhUKhcIwXzH3Q5KLiwsKhYJPP/3UcJ6tW7fSsWNHrKyssLGxoV+/fly6dClfDA96HxT3tfHy8uLJJ5/k4MGDtG7dGq1Wi7e3N7/88ku+537IkCEAdO3a1fDc//e9WhK5192+fTstW7bEwsKChQsXArB8+XK6deuGq6sr5ubm+Pv7M3/+/CLP8aDYAbKzs/nss8+oW7cuWq0WJycnOnTowM6dO4GiX6NcxXnfPOi1UCgUvPbaa6xduxZ/f38sLCxo27YtFy5cAGDhwoXUqVMHrVZLly5dCh2iPnbsGL1798bOzg5LS0s6d+7MoUOH8rX59NNPUSgUXL58mRdeeAEHBwc6dOgAQEREBCNHjqRGjRqYm5vj4eFB//79TWo4/HEkeuyECrd69WqeeeYZNBoNQ4cOZf78+Zw4cYJWrVoZ2qSkpNCxY0euXLnCqFGjaN68OTExMWzatInw8HCcnZ3R6XQ8+eST7N69m+eff55JkyaRnJzMzp07uXjxIj4+PiWOLScnh4CAADp06MA333yDpaUlIP8STktLY8KECTg5OXH8+HHmzJlDeHg4a9euNRx//vx5OnbsiJmZGePGjcPLy4ugoCD+/vtvZs6cSZcuXfD09GT16tUMHDiwwPPi4+ND27Zti4wvMjKSdu3akZaWxhtvvIGTkxMrVqzg6aef5s8//2TgwIF06tSJlStX8vLLLxuG+4rrhRdeYNKkSaSkpGBtbU1OTg5r167l7bffLnQY9ueff2bkyJG0atWKWbNmERkZyezZszl06BBnzpwx9FTs2LGDQYMG4e/vz6xZs4iNjTX8Qfiv8ePHG877xhtvEBISwk8//cSZM2c4dOhQvuHIvBYvXswbb7zB4MGDmTRpEhkZGZw/f55jx47xwgsvFHrMg56r4jzXec2YMQONRsO7775LZmZmgeHs4qpZsyadO3fm33//JSkpCVtb2wJtPvroI+rXr8+iRYuYPn06tWvXxsfHhwEDBvDLL7/w119/MX/+fKytrWncuDEgL6gYPnw4AQEBfPnll6SlpTF//nw6dOjAmTNn8g2FFvU+KMlrc+PGDQYPHszo0aMZPnw4y5YtY8SIEbRo0YIGDRrQqVMn3njjDX788UemTJmCn58fgOHf0rp27RpDhw5l/PjxjB07lvr16wMwf/58GjRowNNPP41arebvv//m1VdfRa/XM3HixHzneFjsICc8s2bNYsyYMbRu3ZqkpCROnjzJ6dOn6dmzZ5GvERT/ffOg1wLkD5ybNm0yxD9r1iyefPJJ3n//febNm8err75KfHw8X331FaNGjWLPnj2GY/fs2UOfPn1o0aIF06ZNQ6lUGpLfAwcO0Lp163zPyZAhQ6hbty5ffPEFkiQBMGjQIC5dusTrr7+Ol5cXUVFR7Ny5k7CwsFIvihLKgCQIFejkyZMSIO3cuVOSJEnS6/VSjRo1pEmTJuVr98knn0iAtH79+gLn0Ov1kiRJ0rJlyyRA+u6774ps8++//0qA9O+//+a7PyQkRAKk5cuXG24bPny4BEgffvhhgfOlpaUVuG3WrFmSQqGQQkNDDbd16tRJsrGxyXdb3ngkSZImT54smZubSwkJCYbboqKiJLVaLU2bNq3AdfJ68803JUA6cOCA4bbk5GSpdu3akpeXl6TT6Qy3A9LEiRMfeL7/to2Li5M0Go20cuVKSZIk6Z9//pEUCoV08+ZNadq0aRIgRUdHS5IkSVlZWZKrq6vUsGFDKT093XCuzZs3S4D0ySefGG5r2rSp5OHhke8x79ixQwKkWrVqGW47cOCABEirV6/OF9+2bdsK3N65c2epc+fOhv/3799fatCgQbEeb1GPP6/iPte5P2Pe3t6F/pwU93p5TZo0SQKkc+fOSZJU+M/r8uXLJUA6ceJEvmP/+zrlxm1vby+NHTs2X9uIiAjJzs4u3+1FvQ9K8trUqlVLAqT9+/cbbouKipLMzc2ld955x3Db2rVrC31/Fke/fv3y/ezkve62bdsKtC/stQkICJC8vb0LPcfDYm/SpInUr1+/B8ZY2GtUkvfNg34nAZK5ubkUEhJiuG3hwoUSILm7u0tJSUmG2ydPniwBhrZ6vV6qW7euFBAQkO93U1pamlS7dm2pZ8+ehttyf56GDh2a7/rx8fESIH399dcPfA6EiieGYoUKtXr1atzc3OjatSsgDyc899xzrFmzBp1OZ2i3bt06mjRpUqBXJPeY3DbOzs68/vrrRbYpjQkTJhS4Le8cndTUVGJiYmjXrh2SJHHmzBkAoqOj2b9/P6NGjaJmzZpFxjNs2DAyMzP5888/Dbf9/vvv5OTkPHC+EMCWLVto3bq1YSgEwNramnHjxnHz5s1ir6gsioODA7179+a3334D5OHhdu3aUatWrQJtT548SVRUFK+++mq++V/9+vXD19fXMGR59+5dzp49y/Dhw7GzszO069mzJ/7+/vnOuXbtWuzs7OjZsycxMTGGrxYtWmBtbc2///5bZOz29vaEh4dz4sSJR3oOcpX0uR4+fHiZzeWytrYGIDk5uUzOt3PnThISEhg6dGi+51WlUtGmTZtCn9f/vg9K+tr4+/vTsWNHw/9dXFyoX78+wcHBZfKYilK7dm0CAgIK3J73tUlMTCQmJobOnTsTHBxMYmJivrbFid3e3p5Lly4RGBhYoviK+77Jq7DfSQDdu3fP1zOWW2Vg0KBB2NjYFLg9N/6zZ88SGBjICy+8QGxsrOG1TE1NpXv37uzfvx+9Xp/vWq+88kq+/1tYWKDRaNi7d2+xpkkIFUckdkKF0el0rFmzhq5duxISEsKNGze4ceMGbdq0ITIykt27dxvaBgUFFTmnK2+b+vXro1aX3YwCtVpd6PBgWFgYI0aMwNHREWtra1xcXOjcuTOA4Y9C7i/Nh8Xt6+tLq1at8s0tXL16NU888cRDVzGGhoYahpbyyh2+Cg0NfeDxxfHCCy8YhlM2bNhQ5DBm7rUKi8fX19dwf+6/devWLdDuv8cGBgaSmJiIq6srLi4u+b5SUlIMk9EL88EHH2BtbU3r1q2pW7cuEydOLDBfqCRK+lzXrl271Nf6r5SUFIB8f5wfRW7y0a1btwLP644dOwo8r4W9D0r62vz3ww3IHxzKOwko6nU4dOgQPXr0wMrKCnt7e1xcXJgyZQpAgcSuOLFPnz6dhIQE6tWrR6NGjXjvvfc4f/78Q+Mr7vsmV1G/kwqLM/eDk6enZ6G358af+/MwfPjwAq/lkiVLyMzMLPCc/Pd5NTc358svv2Tr1q24ubnRqVMnvvrqKyIiIop+8EKFEHPshAqzZ88e7t69y5o1a1izZk2B+1evXk2vXr3K9JpF9dzl7R3My9zcvMBKRp1OR8+ePYmLi+ODDz7A19cXKysrbt++zYgRIwp8si2OYcOGMWnSJMLDw8nMzOTo0aP89NNPJT5PeXj66acxNzdn+PDhZGZm8uyzz1bYtfV6Pa6urkUuqHlQKQs/Pz+uXbvG5s2b2bZtm6F0yyeffMJnn31WXiEblOXKy4sXL6JSqcosWcz9GV25ciXu7u4F7v/vh6PC3gclfW1UKlWh7aR787PKS2GvQ1BQEN27d8fX15fvvvsOT09PNBoNW7Zs4fvvvy/wHi5O7J06dSIoKIiNGzeyY8cOlixZwvfff8+CBQuKrAdZGoW9Fg+L82Hx5z7er7/+mqZNmxbaNrfXOFdhz+ubb77JU089xYYNG9i+fTsff/wxs2bNYs+ePTRr1qzQ8wrlTyR2QoVZvXo1rq6uzJ07t8B969ev56+//mLBggVYWFjg4+PDxYsXH3g+Hx8fjh07RnZ2dpET6h0cHAAKVHsvSc/WhQsXuH79OitWrMg3uT539Vsub29vgIfGDfD888/z9ttv89tvvxnqkz333HMPPa5WrVpcu3atwO1Xr1413P+oLCwsGDBgAKtWraJPnz44OzsXGQvIk9W7deuW775r164Z7s/9t7Ahq/8+Fh8fH3bt2kX79u1LlShZWVnx3HPP8dxzz5GVlcUzzzzDzJkzmTx5coFyIQ9TEc91YcLCwti3bx9t27Ytsx673En7rq6upa6n9qivTWEeZcpESfz9999kZmayadOmfL1cDxraLw5HR0dGjhzJyJEjSUlJoVOnTnz66acPTOyK+74pT7k/D7a2to9cX8/Hx4d33nmHd955h8DAQJo2bcq3337LqlWryiJUoRTEUKxQIdLT01m/fj1PPvkkgwcPLvD12muvkZyczKZNmwB5jsi5c+cKLYkh5VmRFRMTU2hPV26bWrVqoVKp2L9/f777582bV+zYcz/95v20LkkSs2fPztfOxcWFTp06sWzZMsLCwgqNJ5ezszN9+vRh1apVrF69mt69exeZQOXVt29fjh8/nq8kSmpqKosWLcLLy6vAnLXSevfdd5k2bRoff/xxkW1atmyJq6srCxYsIDMz03D71q1buXLlCv369QPAw8ODpk2bsmLFinzDOzt37iwwT+3ZZ59Fp9MxY8aMAtfLycl54HZMsbGx+f6v0Wjw9/dHkiSys7Mf+HgLU1HPdV5xcXEMHToUnU5nKJFTFgICArC1teWLL74o9LmIjo5+6Dke5bUpSm4ttPLeZquw93BiYiLLly8v9Tn/+/NmbW1NnTp18r0XClPc9015atGiBT4+PnzzzTeGYf+8ivPzkJaWVmClvI+PDzY2Ng99DoTyJXrshAqxadMmkpOTefrppwu9/4knnsDFxYXVq1fz3HPP8d577/Hnn38yZMgQRo0aRYsWLYiLi2PTpk0sWLCAJk2aMGzYMH755Rfefvttjh8/TseOHUlNTWXXrl28+uqr9O/fHzs7O4YMGcKcOXNQKBT4+PiwefPmB87V+i9fX198fHx49913uX37Nra2tqxbt67QuUI//vgjHTp0oHnz5owbN47atWtz8+ZN/vnnH86ePZuv7bBhwxg8eDBAoX8sC/Phhx/y22+/0adPH9544w0cHR1ZsWIFISEhrFu37oEFcUuiSZMmNGnS5IFtzMzM+PLLLxk5ciSdO3dm6NChhrINXl5evPXWW4a2s2bNol+/fnTo0IFRo0YRFxdnqDmX9w9L586dGT9+PLNmzeLs2bP06tULMzMzAgMDWbt2LbNnzzY8Z//Vq1cv3N3dad++PW5ubly5coWffvqJfv36larnq7yf6+vXr7Nq1SokSSIpKYlz586xdu1aUlJS+O6778p0WzNbW1vmz5/Pyy+/TPPmzXn++edxcXEhLCyMf/75h/bt2z90KsCjvDZFadq0KSqVii+//JLExETMzc0NtebKUq9evdBoNDz11FOMHz+elJQUFi9ejKurK3fv3i3VOf39/enSpQstWrTA0dGRkydP8ueff/Laa6898LiSvG/Ki1KpZMmSJfTp04cGDRowcuRIqlevzu3bt/n333+xtbXl77//fuA5rl+/Tvfu3Xn22Wfx9/dHrVbz119/ERkZyfPPP1/uj0F4AOMsxhUeN0899ZSk1Wql1NTUItuMGDFCMjMzk2JiYiRJkqTY2Fjptddek6pXry5pNBqpRo0a0vDhww33S5K8PP+jjz6SateuLZmZmUnu7u7S4MGDpaCgIEOb6OhoadCgQZKlpaXk4OAgjR8/Xrp48WKh5U6srKwKje3y5ctSjx49JGtra8nZ2VkaO3asdO7cuQLnkCRJunjxojRw4EDJ3t5e0mq1Uv369aWPP/64wDkzMzMlBwcHyc7OLl/Zg4cJCgqSBg8ebDh/69atpc2bNxdoRynKnTxIYWU0JEmSfv/9d6lZs2aSubm55OjoKL344otSeHh4gePXrVsn+fn5Sebm5pK/v7+0fv16afjw4QVKVkiSJC1atEhq0aKFZGFhIdnY2EiNGjWS3n//fenOnTuGNv8td7Jw4UKpU6dOkpOTk2Rubi75+PhI7733npSYmFjqx1+c5zq33MnatWsfep2818v9UiqVkr29vdSsWTNp0qRJ0qVLlwq0f9RyJ3ljDQgIkOzs7CStViv5+PhII0aMkE6ePGlo86D3gSQV77WpVatWoaVA/vuaSZIkLV68WPL29pZUKlWJSp8UVe6kqBIkmzZtkho3bixptVrJy8tL+vLLLw0lk/KWDClu7J9//rnUunVryd7eXrKwsJB8fX2lmTNnSllZWYY2Rb1GklS8982DXovCfmZzf07+W4KkqJ/RM2fOSM8884zhPVOrVi3p2WeflXbv3m1oU9TPU0xMjDRx4kTJ19dXsrKykuzs7KQ2bdpIf/zxR6HxChVHIUnlPJNVEIRC5eTkUK1aNZ566imWLl1q7HAEQRCEKkDMsRMEI9mwYQPR0dEl2hlCEARBEB5E9NgJQgU7duwY58+fZ8aMGTg7O3P69GljhyQIgiBUEaLHThAq2Pz585kwYQKurq4FNhYXBEEQhEcheuwEQRAEQRCqCNFjJwiCIAiCUEWIxE4QBEEQBKGKEAWKC6HX67lz5w42NjYVtuWNIAiCIAhCYSRJIjk5mWrVqj20OLpI7Apx584dPD09jR2GIAiCIAiCwa1bt6hRo8YD24jErhC52w/dunULW1tbI0cjCIIgCMLjLCkpCU9Pz2JtjygSu0LkDr/a2tqKxE4QBEEQBJNQnOlhYvGEIAiCIAhCFSESO0EQBEEQhCpCJHaCIAiCIAhVhEjsBEEQBEEQqgiR2AmCIAiCIFQRIrETBEEQBEGoIkRiJwiCIAiCUEWIxE4QBEEQBKGKMInEbu7cuXh5eaHVamnTpg3Hjx8vsm12djbTp0/Hx8cHrVZLkyZN2LZtW742Xl5eKBSKAl8TJ04s74ciCIIgCIJgNEZP7H7//Xfefvttpk2bxunTp2nSpAkBAQFERUUV2n7q1KksXLiQOXPmcPnyZV555RUGDhzImTNnDG1OnDjB3bt3DV87d+4EYMiQIRXymARBEARBEIxBIUmSZMwA2rRpQ6tWrfjpp58A0Ov1eHp68vrrr/Phhx8WaF+tWjU++uijfL1vgwYNwsLCglWrVhV6jTfffJPNmzcTGBhYrO04kpKSsLOzIzExUWwpJgiCIAiCUZUkLzFqj11WVhanTp2iR48ehtuUSiU9evTgyJEjhR6TmZmJVqvNd5uFhQUHDx4s8hqrVq1i1KhRRSZ1mZmZJCUl5fsSBEEQBEGobIya2MXExKDT6XBzc8t3u5ubGxEREYUeExAQwHfffUdgYCB6vZ6dO3eyfv167t69W2j7DRs2kJCQwIgRI4qMY9asWdjZ2Rm+PD09S/2YikvS68kMDin36wiCIAiC8Pgw+hy7kpo9ezZ169bF19cXjUbDa6+9xsiRI1EqC38oS5cupU+fPlSrVq3Ic06ePJnExETD161bt8orfABy4uIIHTaMm0OHkhMdXa7XEgRBEATh8WHUxM7Z2RmVSkVkZGS+2yMjI3F3dy/0GBcXFzZs2EBqaiqhoaFcvXoVa2trvL29C7QNDQ1l165djBkz5oFxmJubY2trm++rPKlsbJDS0tEnJhIxfUa5XksQBEEQhMeHURM7jUZDixYt2L17t+E2vV7P7t27adu27QOP1Wq1VK9enZycHNatW0f//v0LtFm+fDmurq7069evzGN/FAozMzy+mAlqNck7d5K0bbuxQxIEQRAEoQow+lDs22+/zeLFi1mxYgVXrlxhwoQJpKamMnLkSACGDRvG5MmTDe2PHTvG+vXrCQ4O5sCBA/Tu3Ru9Xs/777+f77x6vZ7ly5czfPhw1Gp1hT6m4tD6+uI0Vu5JjJgxg5z4eCNHJAiCIAhCZWf0jOe5554jOjqaTz75hIiICJo2bcq2bdsMCyrCwsLyzZ/LyMhg6tSpBAcHY21tTd++fVm5ciX29vb5zrtr1y7CwsIYNWpURT6cEnGeMIHknTvJuhFE5KxZVP/qK2OHJAiCIAhCJWb0OnamqCLr2KWfO8fNoS+AXk+NBfOx6dKlXK8nCIIgCELlUmnq2Alg0aQJjsOGARAx7VN0yclGjkgQBEEQhMpKJHYmwGXSG5jVrElOZCRRX39j7HAEQRAEQaikRGJnApQWFnh8Lpc9SfjjD1KPHjVyRIIgCIIgVEYisTMRVq1bY//8cwDcnfox+rQ0I0ckCIIgCEJlIxI7E+L67ruoPTzIDg8nevZsY4cjCIIgCEIlIxI7E6KytsZj+mcAxP2ykrQzZ4wckSAIgiAIlYlI7EyMdceO2PXvD5LE3Y+mos/MNHZIgiAIgiBUEiKxM0Fukz9E5exMVnAwMfPmGzscQRAEQRAqCZHYmSCVvT3un3wMQOySJWRcvmzkiARBEARBqAxEYmeibHv1wiYgAHQ67nw0FSk729ghCYIgCIJg4kRiZ8LcP56Kys6OzCtXiF261NjhCIIgCIJg4kRiZ8LUzs64fTQFgJi588i8ccPIEQmCIAiCYMpEYmfibJ96CqvOnZCys7n70VQknc7YIQmCIAiCYKJEYmfiFAoFHp9+itLKivRz54hbudLYIQmCIAiCYKJEYlcJmHl44Pr++wBE/zCbrLAwI0ckCIIgCIIpEoldJWH/7BAs27RBysjg7sefIOn1xg5JEARBEAQTIxK7SkKhUOAxYzoKrZa0Y8dI+GOtsUMSBEEQBMHEiMSuEtHUrInrW28CEPX112TfvWvcgARBEARBMCkisatkHF56CYumTdGnpnL300+RJMnYIQmCIAiCYCJEYlfJKFQqPGZ+jsLMjNR9+0n6+29jhyQIgiAIgokQiV0lZO7jg/PEiQBEzvyCnJgYI0ckCIIgCIIpEIldJeU0ehTmfn7oEhOJmPG5scMRBEEQBMEEiMSuklKYmVFt5uegUpG8fTtJ23cYOyRBEARBEIxMJHaVmNbfH6exYwCImDEDXUKCcQMSBEEQBMGoRGJXyTm/+ioaHx90MTFEzvqfscMRBEEQBMGIRGJXySk1Gjw+nwEKBYkbN5Kyf7+xQxIEQRAEwUhEYlcFWDZrhuOwlwG4+8k0dCkpRo5IEARBEARjEIldFeEyaRJmnp7kREQQ9c03xg5HEARBEAQjEIldFaG0tMRjxgwAEtb8Tuqx40aOSBAEQRCEiiYSuyrE6ok22D/7LAB3P/4YfXq6kSMSBEEQBKEiicSuinF9713U7u5kh4URPftHY4cjCIIgCEIFEoldFaOyscHjs08BiPvlF9LPnTNuQIIgCIIgVBiR2FVB1p07Y/v0U6DXc+ejj9BnZRk7JEEQBEEQKoBI7Koot8mTUTk5kXUjiJj5840djiAIgiAIFUAkdlWU2sEB948/BiB28RIyrl41ckSCIAiCIJQ3kdhVYba9A7Dp2RNycrgzZQpSdraxQxIEQRAEoRyJxK6Kc//kY5R2dmRevkLssuXGDkcQBEEQhHIkErsqTu3igtvkDwGImTuXzOBgI0ckCIIgCEJ5EYndY8Cuf3+sOnZEysri7kdTkXQ6Y4ckCIIgCEI5EIndY0ChUODx2acoraxIP3OG+NW/GjskQRAEQRDKgUjsHhNm1arh+t67AER9/z1Zt24ZOSJBEARBEMqaSOweI/bPPotlq1ZI6enc/eQTJEkydkiCIAiCIJQhkdg9RhRKJR6fz0Ch1ZJ25CgJf/5p7JAEQRAEQShDIrF7zGhq1cJl0iQAor78iuyICCNHJAiCIAhCWRGJ3WPIcdjLaJs0Rp+SQsSnn4khWUEQBEGoIkRiZww5WXBxHWycCHp9hV9eoVJR7fPPwcyMlL17Sdr8T4XHIAhCxZL0ejbs/oCrV/8ydihCJZOancqaq2uISosydigmadaWK6w6Gkpiumns7iQSO2OQ9PD3m3BmFYQfN0oI5nXr4vLqBAAiZ84kJzbWKHEIglAxdh3/no/DtzDsyFRO7vzAKB8qhconNTuV8TvHM/PYTKYenGrscExOXGoWiw4EM3XDRTKyTaNGrEjsjMFMC75Pyt9fXGe0MJzGjMHc1xddQgIRn39utDgEQSh/fwRvAiBdqeTV8M2c+XUApMUZNyjBpKVlp/Hqrlc5F30OgCN3j3Ap9pKRozIth27EIElQ380GN1utscMBRGJnPA2fkf+99BfocowSgsLMDI+Zn4NKRfLWbSTv2mWUOARBKF9hiaEczY5DIUk0VdmQrlQyITuIc0s6w+1Txg5PMEHpOem8tuc1TkedxsbMhpZuLQFYemGpkSMzLfuvRwPQqZ6zkSO5TyR2xuLdBSwcIDUaQg8aLQyLBg1wGj0agLuffYYuMdFosQiCUD7WnVsEQLuMbBYN+ofWDv6kKpW8YqPn0son4dgiEIuohHsycjJ4fc/rnIg4gZWZFQt6LuCjNh8BsCt0FyGJIUaO0DRIksT+wNzEzsXI0dwnEjtjUZmBf3/5eyMOxwI4T3wVjbc3uugYIv/3pVFjEQShbGXrstkQtgOAIVbeWFg4MKfPcpq7NCFFqWSsqyNXdk+BP0dCRpKRoxWMLVOXyZv/vsmxu8ewVFuyoMcCGrs0po5DHbp4dkFC4udLPxs7TJNwPTKFyKRMtGZKWnk5GjscA5HYGVPDQfK/lzfJK2WNRGlujsfnn4NCQeJff5FywHg9iIIglK3dt3YTp8vAJSeHzvUHAmBpZsm8ngtp6tKUZJWSse5uXLu+GRZ1gYiLxg1YMJosXRZv732bQ3cOYaG2YF6PeTR1bWq4f3RDeXRnU9AmIlJFDdTcYdg2tZ3QmqmMHM19Rk/s5s6di5eXF1qtljZt2nD8eNGrRLOzs5k+fTo+Pj5otVqaNGnCtm3bCrS7ffs2L730Ek5OTlhYWNCoUSNOnjxZng+jdGq1B2s3yEiA4L1GDcWyeTMcXn4JgLvTPkGXkmrUeARBKBt/XlkDwMDkVNT1+hhutzKzYn6P+TRybkSiSsnYau7cSA6DJd3h9EpjhSsYSbY+m3f3vcv+8P1oVVrmdp9LC7cW+do0dW1KS7eW5OhzWHlZ/IzkDsN2rGs68+vAyInd77//zttvv820adM4ffo0TZo0ISAggKiowmvlTJ06lYULFzJnzhwuX77MK6+8wsCBAzlz5oyhTXx8PO3bt8fMzIytW7dy+fJlvv32WxwcHCrqYRWfUgUN5E/Qxh6OBXB9803MatQg585dor/71tjhCILwiMKSwjgWdQqFJDHIvBrYe+a731pjzYKeC/B38ideqWBMjRoEK3Jg02uw4VXISjNS5EJFytZn88H+D/j31r+Yq8z5sduPtHJvVWjb0Y3kXru119eSkJFQgVGaloxsHcdC5FXlnU1ofh0YObH77rvvGDt2LCNHjsTf358FCxZgaWnJsmXLCm2/cuVKpkyZQt++ffH29mbChAn07duXb7+9n4R8+eWXeHp6snz5clq3bk3t2rXp1asXPj4+FfWwii09J/3+cOzVfyA73ajxKC0t8ZgxHYD4X38j7cQJo8YjCMKj+fO6vB90h/QMqtXtXWgbW40ti3ouwtfRl1h0jKnlQ6iZBs6ulnvvoq9XZMhCBcvR5zDlwBR2hu7ETGnG7K6zaVutbZHt21drj6+jL+k56fx27bcKjNS0HAuJIytHj4edljqu1sYOJx+jJXZZWVmcOnWKHj163A9GqaRHjx4cOXKk0GMyMzPRavPXibGwsODgwftzwjZt2kTLli0ZMmQIrq6uNGvWjMWLFz8wlszMTJKSkvJ9laeUrBQ+P/o5z2x8hnT3hmBXE7KSIXBnuV63OKzatsV+yBAA7kydij7duMmmIAilk6XLYsMNeZeJwckpUK/wxA7AztyORT0XUdehLtG6dEZ5+3LL1g2iLsPirnDhz4oKW6hAOr2OqYemsu3mNtRKNT90/YH21ds/8BiFQmGYa/frlV9Jy348e3UNZU7quqBQKIwcTX5GS+xiYmLQ6XS4ubnlu93NzY2IIjamDwgI4LvvviMwMBC9Xs/OnTtZv349d+/eNbQJDg5m/vz51K1bl+3btzNhwgTeeOMNVqxYUWQss2bNws7OzvDl6elZZNuyoFQo2Re+j/CUcJZeXAYNBsh3mMBwLIDr+++hdnMjOzSM6Dk/GTscQRBKYU/YHuIzE3DNyaGTpIUahQ+t5XLQOrC452J87HyIykpgVI0ahHs9AVkpsG40bH4bcjIrKHqhvOklPZ8c/oR/gv9BrVDzbedv6VSjU7GO7VmrJ542niRkJrAu0DT+blW0+/XrTGsYFkxg8URJzJ49m7p16+Lr64tGo+G1115j5MiRKJX3H4Zer6d58+Z88cUXNGvWjHHjxjF27FgWLFhQ5HknT55MYmKi4evWrVvl+jgszSz5oNUHACy7uIww7w7yHde3Q2ZyuV67OFQ2Nrh/Og2AuJ9/Jv3CBSNHJAhCSa29vhaAZ5JTUdfpIc/pfQgnCyeWBCzBy9aLiPRoxljD3XavyneeXApLe0GcqGFW2eklPZ8d+YxNQZtQKVR81fkrutXsVuzjVUoVIxuOBGDFpRVk60xjj9SKcichncCoFJQKaF/HydjhFGC0xM7Z2RmVSkVkZGS+2yMjI3F3dy/0GBcXFzZs2EBqaiqhoaFcvXoVa2trvL29DW08PDzw9/fPd5yfnx9hYWFFxmJubo6trW2+r/LWvWZ32lVrR7Y+m1k3NyA5ekNOOlwruMrXGGy6dsX2qadAr+fulI+QsoxXjkUQhJK5mXiT4xHHUUrwzEOGYf/L2cKZpQFLqWlTk9updxiVfJaIwUvBwhHunoWFneU5wUKlJEkSM4/OZH3gepQKJf/r+D961upZ4vP09+mPi4ULkWmRbA7eXA6Rmq4D91bDNq5hj72lxsjRFGS0xE6j0dCiRQt2795tuE2v17N7927ati164iaAVqulevXq5OTksG7dOvr372+4r3379ly7di1f++vXr1OrVq2yfQCPSKFQMLn1ZNRKNQdvH2SP9xPyHSYyHAvgNmUyKkdHMgMDiVm4yNjhCIJQTLnDYx3S0/HQS+BT/N4YAFdLV5YGLKWGdQ3CU8IZE/gzUcM3QI3WkJkIa16A7R/BY9ZTU9lJksSs47P44/ofKFDwefvP6V27+El/XhqVhpf9XwbkkSe9pC/LUE3a/sAYwDSHYcHIQ7Fvv/02ixcvZsWKFVy5coUJEyaQmprKyJFyF++wYcOYPHmyof2xY8dYv349wcHBHDhwgN69e6PX63n//fcNbd566y2OHj3KF198wY0bN/j1119ZtGgREydOrPDH9zBedl6MbCA/1i9Tr5KuUMCNXZAeb+TIZGoHB9w/ngpAzMKFZPwnYRYEwfRk6bLYeGMjAEOSUsCzDViWvCq+u5U7SwOWUs2qGqFJoYw5+jExz6+Etq/JDY78BD/3g8TbZRm+UE4kSeLrk1/z29XfUKBgevvpPOXz1COdc0i9IdhobLiZdJM9YXvKKFLTptNLHLyX2HU2of1h8zJqYvfcc8/xzTff8Mknn9C0aVPOnj3Ltm3bDAsqwsLC8i2MyMjIYOrUqfj7+zNw4ECqV6/OwYMHsbe3N7Rp1aoVf/31F7/99hsNGzZkxowZ/PDDD7z44osV/fCKZUyjMXhYeXA3I4bF1XxAn21Swxw2vXtj07MH5OTIQ7I5OcYOSRCEB9gVuov4zHjcUNMhPR3qBZT6XNWsq7E0YCnuVu6EJIYwZtcrxHV+B55bBeZ2cOsYLOwIN3Y//GSC0UiSxPenvzcUFZ7WdhoD6gx45PNaa6x5vv7zACy9sBTpMdhv+Hx4Aonp2dho1TSpYW/scAqlkB6HV6KEkpKSsLOzIzExsULm2+0O3c2be9/EDCV/3QqnVq1O8PJf5X7d4sqOiiL4yafQJyXh+u47OI0ZY+yQBEEowshtIzkZeZIJiam8GhcLE46Am//DD3yAsKQwRm4bSVR6FPUc6rG011Ls0+Lgj+EQcR5QQKf3oMuHxVqkIVQcSZKYc2YOiy/IZb+mtpnKc77Pldn54zLiCPgzgAxdBot7LeYJjyfK7NymaPauQL7fdZ0+Dd2Z/1KLhx9QRkqSl1SqVbFVVbea3WhfvT3Z6Jnl5IAUvA9Soo0dloGZqytuH34IQPSPc8gMFqviBMEUhSSGcDLyJEoUPJOYAHae4Or3yOetaVuTpQFLcbZw5nr8dcbtHEeilROM3gktRwES7P8KVg6AlMJ3DhKMY8G5BYak7sPWH5ZpUgfgqHVkYF15B6WlF5aW6blNUe42YqY6vw5EYmcSchdSmCnNOGRpwR4LDVzZaOyw8rEbOACrDh2QsrK4+/HHSPrHZ6KsIFQWuTtNdDJzwl2nk4dhy6h4qpedF0t7LcVR68iVuCuM3zmeJCkLnvwenlkCZlYQsh8WdISbh8rkmsKjWXx+MfPOzQPgvZbv8aJf+UxJGtFgBCqFiqN3j3Ip5lK5XMMUJKZnc/ZWAmB6+8PmJRI7E1HLtpahLtCXTg6kXTStSu8KhQKPzz5FaWlJ+qlTxP/6+G4lIwimKFOXycage4smYu+Vkapb+vl1hfG292ZJryU4mDtwKfYSE3ZOICUrBRoPgXH/gosfpETAiifhwHcgPgAazfKLy/nxzI8AvNXiLYY1GFZu16pmXY2+tfsCsPRi1e21OxIUg04v4e1iRQ0HS2OHUySR2JmQMY3GUM3ClbtqNUuSrpjcajOz6tVxefcdAKK++46scNOKTxAeZ7tCd5GYmYi71on2sbdBbQG1O5b5deo61GVxr8XYmdtxPuY8E3ZNIDU7FVzqw9jd0GQoSHrY/Rn89jykxZV5DMKD/XLpF7479R0Arzd7nVENR5X7NXOvsSt0F8GJweV+PWPYd/1emZO6pjsMCyKxMykWags+eOIjAJbb2XDz7M/GDagQDs8/j2XLlkhpaUR88vFjsQpKECoDw04TWk9UAN6dwcyiXK5V37E+i3ouwkZjw9nos7y661V5z1CNFQyYD0/PAbUWArfDwk4QfrJc4hAK+vXKr3x98msAJjSZwLjG4yrkunUc6tDFswsSEj9f/LlCrlmRJEkybCPW2YTn14FI7ExOV8+udLTyIkehYFbwOpNLnBRKJR6fz0Bhbk7q4SMkrl9v7JAE4bEXnBDMqchTKBVKnom5I99Yt1e5XtPfyZ9FPRdhbWbN6ajTvL7nddJz0uU5fc2HwZhd4OgNibdgWW84ugBM7PdZVfPHtT+YdXwWAGMbjWVCkwkVev0xjeSKCX8H/01EauF7vldWwTGp3E5IR6NS0sa75HUhK5JI7EyMQqFgcocZaCSJw8psdl3+1dghFaDx8sLljTcAiPzfl2RHilVwgmBMub11ndzb4hZ+Wr6xnBM7gIbODZnfYz6WakuORxxn0p5JZOoy5TvdG8G4feDfX67Pue0DWDscMhLLPa7H0brr65hxdAYAIxuM5PVmr6Moo4UzxdXEpQmt3FuRo8/hl8u/VOi1y1tub12r2g5YatRGjubBRGJngjzdmzJS4QDAl2d+lIc4TIzj8GFoGzVCn5xMxGefmVzPoiA8LjJ1mWwK2gTAEAtPeX6bW0Ow96yQ6zd1bcr8HvOxUFtw5O4RJv07iSzdvb2ltbYwZAX0+QqUZnB5IyzqAnfPV0hsj4uNNzby2ZHPAHjJ7yXeavFWhSd1uUY3HA3IK7QTMhKMEkN5yE3sOpr4/DoQiZ3JGt1gBNWzc4jUpbHovOnt06pQq/GY+TmYmZGyZw9JW7YYOyRBeCztuLmDpKwkPKw8aB9xQ76xAnrr8mru1py53eeiVWk5dPsQb+99m+zcfWQVCmgzHkZtk+vqxQXDkh5waoUYmi0Dm4M38/Ghj5GQGOo7lPdbvW+0pA6gXbV2+Dn6kZ6Tzm9Xq0b1hMwcHUeD5UVApr5wAkRiZ7Is/AfyQXwSACsurTDJVUbaevVwfmU8AJGfzyQnTqx+E4SKllu7blCdgaiC7m3t9QjbiJVWK/dW/NT9J8xV5uwL38d7+98jW599v0GNljB+v1yCRZcJf78Bf70CWakVHmtVsS1kGx8d/AgJiSH1hjC59WSjJnUgTyca1UheIbv66mqTHHEqqVM340nP1uFiY46fh42xw3kokdiZKktHuni0o1NaOjlSDrOOzTLJ4U7nsWMxr1cPXXw8kZ/PNHY4gvBYCUoI4nTUaVQKFQMtasrz1ywcoEYro8TTxqMNP3b9EY1Sw+6w3Xy4/0Ny9Hn2l7Z0hKFroMenoFDB+TWwuBtEXzNKvJXZztCdfHjgQ/SSnmfqPsPUJ6YaPanL1bNmT2ra1CQxM5F1geuMHc4j2xeYOwzrbDLP8YOIxM6EKRoN5sPYeDQSHL17lB2hO4wdUgEKjQaPL74AlYqkLVtI3rPH2CEJwmMjt7euc43OuIYdk2+s09Oo+7W2q96O77t+j5nSjB2hO5hycAo6ve5+A6USOrwFw/8Ga3eIvgqLusL5tUaLubLZE7aH9/e9j07S8bTP00xrOw2lwnT+nKuUKkPB/RWXVtwflq+k9t+rX2fqZU5ymc5PglBQ/T54omZ0gryK7OsTX5tkt7ZFwwY4jZLfxBHTPkWXlGTkiASh6svIybi/00T9IXD93gc/IwzD/lenGp34rst3qBVqtoZs5eNDH+dP7gC82sMrB6B2Z8hOhfVj4O83ITvDKDFXFvvD9/POvnfIkXLoW7sv09tNN6mkLtfTPk/jYuFCZFokm4M3GzucUotKzuDKXflvWoc6pruNWF6m99Mg3Ke1hbq9GJWYRHWVJZFpkSw8v9DYURXKeeJENF5e5ERHE/nll8YORxCqvB2hO0jOSqaaVTXaWlSD6Cvy8KZPN2OHBkAXzy583flrVAoVfwf/zbTD09BL/9lizNoVXv4LOn8AKODUcljaU15gIRRw6PYh3vz3TXL0OQR4BTCzw0xURuydfRCNSsMwf3kbs2UXlxVM7CuJA/d66xpWt8XJ2tzI0RSPSOxMXcNBaCWJyYlyT90vl34hOMH0fukptVo8vpgJCgWJ69aTckhsAi4I5cmwaKLeIFQ37i2a8Gwjz2MzET1q9eB/nf6HUqFkY9BGph+ZXjC5U6qg6xR4aR1YOkHEeVjYBa78bZSYTdXRu0eZ9O8ksvXZ9KjZg1kdZ6FWmnY9tSH1h2CjseFm0k323Kqc03QO3JtfVxlWw+YSiZ2pq9sLNNZ0jg6ji3NTcqQcvjj+hUkupLBs3hyHF18EIOLjT9CnitVuglAebsTf4EzUGdQKNQPrDITr2+U76lVsmZPi6O3Vmy86fIFSoWRd4Dq+OFbE76863WH8AfB8AjIT4feXYNsUyMmq+KBNzImIE7y++3UydZl08ezCV52+wkxpZuywHsrKzIqhvkMBWHphqUn+3XoQvV7iQOC9/WEryfw6EImd6dNYQv2+AHyAI+Yqc47dPcb20O1GDqxwrm+9iVn16mTfuUPUd98bOxxBqJJyd5ro4tkFF7UlhOyX76jX24hRFa2fdz9mtJ+BAgW/X/udL098WfgfebvqMGIztHtd/v/RufBzP0gMr9iATcipyFNM3D2RDF0GHat35NvO32KmMv2kLteLfi+iVWm5FHuJo3ePGjucErl8N4nY1CysNCqa13QwdjjFJhK7yqDhIABqXNnG6IZyfaCvj39Narbp9YgprazwmDEdgPjVq0k7dcrIEQlC1ZKek87fQfIw5eB6g+WkTpcJdjXBxdfI0RXtaZ+n+aydvDvC6iur+fbkt4Undyoz6PU5PP8raO0g/Dgs6AiBOys4YuM7G3WWV3e9SnpOOu2qyauNNSqNscMqEUetI8/UfQaApReXGjmaktl3b7eJtj7OaNSVJ12qPJE+zny6yb/gUiIYZetHDesaRKVHsfCcaS6ksGrXDrvBcjJ696Op6DPEKjdBKCs7bu4gOTuZ6tbVaVutbf5hWBOvsTWw7kA+afsJACsur2D26dlFD8/59pMLGns0hfQ4WD0Yds8AXU7h7auYC9EXeGXXK6TlpNHGow2zu87GXFU5Ju//1/AGw1Er1By7e4yLMReNHU6x5W4j1rle5VgNm0skdpWBWgN+TwFgfnkTk9tMBmDl5ZUEJQQZM7Iiub3/PmpXV7Ju3iRm7lxjhyMIVUbuMOzgeoNRooDA3DInpjkM+19D6g1hSpspgNyDM/fsA34/OHjB6B3Qaoz8/wPfwMoBkBxZ7nEa06XYS4zfOZ7U7FRaurVkTrc5aNVaY4dVatWsq9HXW55StPRC5ei1S8nM4VRoPFA59ofNSyR2lcW94Vgub6STR1u6eHaRF1IUNRHZyFS2trh/Og2A2KXLSL9QeT6lCYKpuh5/nXPR51Ar1AyoMwAiL0LSbVBbgFcHY4dXbEN9h/JBqw8AWHh+IQvOLSi6sdoc+n0Lg5aCxhpuHoAFHSDkQAVFW7Guxl1l3I5xJGcn09xV3oPXQm1h7LAe2ah704h2h+02yS0y/+toUCw5eomajpZ4OVsZO5wSEYldZeHVCSydIS0WQvbxQasPMFeZczziONtubjN2dIWy6dYN2379QK/n7kcfIWWJ1W2C8ChyS5x0rdkVZwvn+8Ow3p3BrHL98X/J/yXeafEOAHPPzmXJhSUPPqDRYBi3F1z9ITUKfnka9n8Dev2Dj6tErsdfZ+yOsSRlJdHYpTHzeszD0szS2GGVCR97H7p6dkVCYvnF5cYO56H255Y5qWTDsCASu8pDpYYGA+TvL66nhk0NxjSShye+PmGaCykA3D6agsrBgczr14lZvNjY4QhCpZWek87mILmC/+B6g+UbA01nt4nSGNFwBJOaTwJg9unZ/Hzx5wcf4FwXxuyGpi+CpIc9M+DXZyEtrvyDLWdBCUGM3TGWhMwEGjo1ZEGPBViZmUZPkS4xkYgvviAzMPCRzjO60WgANgdtJiI1oixCKze58+sqU/26XCKxq0xyh2OvbIacTEY2HImnjSfR6dHMPzvfuLEVQe3oiNvUjwCIWbCQjOvXjRyRIFRO20K2kZydTA3rGjzh8QSkxsKt4/KddU2vfl1xjWk0hlebvgrAt6e+ZeXllQ8+QGMJA+ZB/7mg1sKNnfKq2dznohIKSQxh9PbRxGXE4efox4KeC7DR2Bg7LIPYpcuI/2Ult99+B+kRekibuDShlXsrcqQcVlxaUYYRlq2w2DRuxqahVipo6+Nk7HBKTCR2lYnnE2BTTS7eeWM35ipzJreWF1KsurKKG/E3jBxg4Wz79sW6e3fIzubuR1ORch6PVW2CUJby7jShVCjhxi5AAreGYFfDuME9oglNJjCu8TgAvjrxFb9d/e3hBzV7Se69c6oDSeGwvA8cmQcmOOf4QcKSwhizfQyxGbHUd6jPop6LsDO3M3ZY+aTs3QtAZmAgSVu2PtK5xjSUR5rWBa4jPiP+UUMrF/vuDcM2r+WAjbby1AzMJRK7ykSphIZyPSAurgOgY42OdPPshk7SmeyOFAqFAvdPPkFpY0PGhQvErfjF2CEJQqVyLe4a52PO3180ARCYW+akcg7D/tdrTV8zTLD/4tgXhtW/D+TeEMb+Cw0Ggj4Htk+GP16GjMRyjrZs3Eq+xajto4hKj6KOfR0W9VqEvdbe2GHlk33nDpl5Rlpi5sx5pA/nbau1xc/Rj/Sc9OIl8EZwfxi28s2vA5HYVT65id21LZAlz6t7v/X7aFVaTkScYGvIo32aKi9mbq64fSivgov+8UcyQ0KMHFHlI0kS2XfukLznX1L27SM7MsokE3mh7OUmOd1qdpMXTehy7vXYAXWrRmKnUCh4s/mbho3jpx+Zzl+Bfz38QK0tDF4Ofb8BpZm8x+zCTnD3XDlH/GjupNxh9PbRRKZF4m3nzeJei3HUms4+v7lS9su7mpj7+aFycCArNJTEjZtKfT6FQmGYa7f6ymrSstPKJM6ykq3TcyQoFqhc24jlJRK7yqZac7m2U3aaYUVcdevqjG08FoBvTn5DSlaKEQMsmt0zz2DVrh1SZiZ3P/74keZqVHWSTkdmUBCJf28m8quvCR05ksC27bjRrTvhr77KrfGvcKNzZwI7dCRszFiivv2OpK1bybp5UzyvVUxadhr/BP8D5Fk0ceuY3Ctl4Qg1WhoxurKlUCh4t+W7vOgn7zk97fA0NgUVI4lQKKD1WBi9HexrQvxNWNITTi4zyaHZiNQIRm0fxd3Uu3jZerGk1xI5YTdBKXv3AWAbEIDTWPnvTMzcuegfocpBj5o9qGVbi6SsJMMUA1NxJiyBlMwcHK00NKxmWkPixaU2dgBCCSkU0OAZOPidPBx7rwdvRIMRbLyxkbDkMOafm897rd4zcqAFKRQK3KdPJ/jpp0k/eYr4NWtwfOEFY4dldPrMTDKvB5Jx5TIZV66QefkKGdevI6WnF2ysVmPu4wN6HZlBwehiY0k9eJDUgwcNTZSWlpj7+qL180Pr74fWzw/zOnVQaCrXVkSCbPvN7aRkp+Bp40kbjzbyjbnDsHV7glJlvODKgUKh4INWH5Cjz+H3a7/z8aGPUSlU9PPu9/CDq7eQd6v4awJc3wqb34LQI/Dk92BuXf7BF0NkaiSjt4/mdsptPG08WdJrCS6WptkzpM/IIPWovL+rdZfOaLy8iFu+nOw7d0j4889S//5WKVWMbDCST498yorLK3je93mT2Sotdxi2Qx1nlErT3smlKCKxq4waDpITu8Cd8qd2rR0alYbJbSYzYdcEVl9ZzYA6A6jrUNfYkRagqVEd17ffJvLzz4n+5ltsOnfGrHp1Y4dVYXRJSWRcvUrmlStkXL4iJ3JBQaDTFWirsLREW78+Wj9fzP380Pr5Y16vLsp7CZo+I4PM69cN58m4coXMa9fQp6WRfvo06adP3z+ZmRnmderIyd69hM+8vi8qa9MopyAULd9OE4p7gyy59esq8WrYB1EoFExpM4UcfQ7rAtcx5eAU1Eo1AV7FGHa2cIChv8HhH2HXZ3DhD3lY9tlfwNW4e+lGp0UzZscYwpLDqG5dnWUBy3CzcjNqTA+Sdvw4UkYGand3zOvXR6FQ4DThFSKnzyB2/gLsn3kGpbZ0O2I85fMU887OIyotis3Bmw37yRrb/fp1pplsF4dI7CojtwbgXB9irsHVLdB0KAAdqnege83u7A7bzcxjM1kesByFCe4d6fDCUJK2biX91CnufjINzyWLTTLORyFJEjlR0WRcuZwvicsODy+0vcrB4X7CdS+J09SqiUJVdG+MUqvFonFjLBo3vn/dnByyQkLkRC9PwqdPSiLzyhUyr1zBMK1coUBTsybm/vL1cq+vdqp8y/urqqtxV7kQcwG1Uk1/n/7yjfGhEH0VFCqo0924AZYjpULJJ20/IUefw8agjXyw/wPUCjXdaxXjMSsU0H4S1GgNf46Uf1cu7ir33DV5vvyDL0RMegxjdozhZtJNPKw8WBqwFHcrd6PEUly5w7DWnToZfkfbDx5M3JKlZN+5Q/yvv+E0amSpzq1RaRjWYBjfnPyG5ReX09+nPyoj9z7HpWZx4bb8G7KyLpwAkdhVTgqF3Gu39wu4tN6Q2AG83+p9Dt0+xKnIU/wT8g9Pej9pxEALp1Aq8fh8BiEDBpJ66BCJf23A/pmBxg6r1CS9nuywsALJlC42ttD2ZtWq3Uum7iVU/n6o3dzKJLlVqNWY162Led262D39tByfJJF9+06BJDMnMpKs0FCyQkNJ3np/9xK1q6s8fJsbo78/ZtWrV7nkuzJYe03uretesztOFvcS7tyixJ5t5N6pKkypUPJZu8/QS3r+Dv6bd/e9y3ddvqNrza7FO0GttjD+AKwfA8F74a/xEHoY+nxZoTt1xGfEM3bHWIITg3GzdGNpwFKqW5v2SIUkSYYyJ9ZdOhtuV2o0OE98lbsfTSV28WLsn3221D3/g+sNZtH5RdxMusnusN308jJuD/SBwGgkCXzdbXC1rbx78yoksayugKSkJOzs7EhMTMTW1tbY4RQuJhB+aglKNbwbCJb3V1MtPr+YH8/8iLOFM5sGbDKpQpd5xS5ZQtQ336K0tcV789+YuboaO6SHkrKyyAwKyj/8efUq+tRCdv5QKtF4187XG6b19UVlb1/hcRcmJy7u3uO4n/BlhYYWOtlcaWuL9t68PXM/X3lY2McbhVp8NiwvadlpdFvbjdTsVJb0WnJ/ft2qQfKK2B6fQYc3jRpjRdHpdUw+MJmtN7eiVqqZ3XU2nWp0Kv4J9DrY/zXs/R8ggXsjGLICnHzKLeZciZmJjN4+mmvx13CxcGF57+XUsq1V7td9VJmBgQQ/9TQKjYZ6R4+gtLy/tZmUk0NwvyfJCg3F5c1JOL/ySqmv89OZn1h4fiH+Tv6s6bfGqB8g3117jj9PhTOukzdT+voZLY7ClCQvEYldISpFYgdytfWI8/DUbGgxwnBzli6LZzY9Q2hSKC/5vcQHrT8wXowPIOXkcPP5oWRcvIh1j+7UmDPHpHqF9KmpZFy7Zkh+Mq5cISvwBlJ2doG2CnNzzOvVy79goV49lBaVa//Owh5zZuANKOwxazQFH3P9+pXuMZuqddfX8emRT6lpU5PNAzfL742sVPiyNugy4dWj4Gpaf3zKU44+h/f3v8/O0J1olBrmdJtDu+rtSnaSoH9h3RhIiwGNDQyYC/79yydg5KRu7I6xXIm7gpPWieW9l1Pbrna5Xa8s5X7wturYkZqLFxW4P3HzP9x5912UNjbU2bUTlV3pVpDGZ8TT689eZOgyWNhzIe2qlfA1LSOSJPHErN1EJmWyanQbOpjYUGxJ8hLxcbsyazhITuwursuX2GlUGia3nswru17ht6u/MaDOAOo71jdenEVQqNV4zJxJyODBpOzaTfK2bdj26WOUWErbe5U7J87cu2r0XimtrLBs3hzL5s0Nt+Xrpbx69d5zJPdSZly8SMbFi3lOoERTu3a+RRpaPz+T6aWsTPIumjB84AnZLyd1djXBxbgLASqaWqnmy05foturY8+tPbzx7xv81P0neXu14vLpCq8cgD9HQdgR+GMYtJkAPaeDumxXZSZnJfPKzle4EncFR60jSwOWVpqkDvLMr+vcudD7bfv2IXbhQjIDA4ldvhzXN98s1XUctA4MqjeI1VdWs+zCMqMldtcik4lMykRrpqSlV+We4iB67ApRaXrs4kNhdmNAAe9cBZv8E3Hf3vs2O0N30ty1OT/3/tmkesPyip7zEzFz56JydMT7n82oHcrvTSXPN7tNxuU8pUWuXiUnMrLQ9mo3twKLGsyqVzPZ57KiSHo92bduFZxXGBNTaHt1NY/8Q9J+fqjd3R/757Eol2Mv89zm5zBTmrFryK77hWv/ngSnfoZWY6HfN0aN0Viyddm8tfct9oXvQ6vSMq/HPFq5tyrZSXQ5sGcGHPpB/n/1ljDkZ7D3LJMYU7NTGb9zPOeiz2Fvbs/SgKXUc6hXJueuCLrERK63aw86HT67dqKpUfiWdcm7dhH+2usoLC2ps2snasfSFVi+m3KXvuv7kiPl8GvfX2nk0uhRwi+VRfuD+GLLVbrUd+Hnka0r/PoPI3rsHhcOtaBGKwg/AZc3Qpvx+e5+r+V7HLx9kNNRp9kcvJmnfJ4yUqAP5jx+HMk7dpAZGEjkzC+o/s3XZXJeKSeHzODgfAsGMq5eRZ+UVLCxQoGmVq18CZzWz1esEC2CQqlEU6sWmlq1sO3d23B7dlSU/HznXQl86xY5d+6ScucuKbt3G9qq7O3zP9/+fmhq1XrgSuDHRW7R1h41e9xP6iRJLnEEVWYbsdIwU5nxXZfveOPfNzh0+xATd09kQY8FNHdr/vCDc6nU0PMzqPkE/PUK3D4JCzvCwEVQ79Em8Kdlp/Hqrlc5F30OW40ti3strlRJHUDqoUOg06Hx8SkyqQOw7t4dbcOGZFy8SOyixYbdhUrKw9qDvt592RS0iaUXl/JD1x9KGXnp7b8ufyjtVLfyljnJJXrsClFpeuwAjs6HbR/KK+RG7yhw95ILS5h9ejZOWif+Hvi3yS6kSL9wgZvPPQ96PTXmz8OmazFXvd2jT0+Xa7rlrQ93/TpSZmbBxmZmmNetk29Vqnm9+qKmWznRJSfLr0dxavdZWKCtX//eAo08tfvMzY0QuXGkZqfS7Y9upOWksSxg2f3eqIgLsKADqC3gg5AKXdVpijJyMnh9z+scvXsUS7Uli3otoolLk5KfKD4U1o6AO6dBoZT3nq3WtFQxpeekM3H3RE5EnMDGzIbFAYtp4NSgVOcypjsffEDixk04jhqF2/sPLnafcuAgt8aORWFujs+O7Zi5la4uX3BCMP03yvMdN/bfiLe9d6nOUxrpWTqaTN9BVo6eXW93oo6r6f2dFD12jxP/AbBtsrzFUMKtAkMJw/2Hs/HGRm4m3WTe2Xkmu5DColEjHEeOIG7pMiI+/QzLli1R2RT+5tIlJMhzvQxDgJfJCg6BQrbSUlpa3usRylOY18dH7MJQgVQ2Nli1bo1V6/vDG4XutnHtGlJ6Oulnz5J+9uz9E6jVmHt7/2dI3K/In4/KbkvIFtJy0vCy9aKlW57twq7fK0nj3eWxT+oAtGotP3b7kdd2v8bxiOO8svMVFvdaTEPnhiU7kUMtGLUN/hgu71Zx8Ht4dkWJ48lNNE9EnMDKzIoFPRdUyqRO0ulI2SfvD1vU/Lq8rDq0x6JFC9JPnSJ24ULcP/mkVNf1tvemm2c39tzaw7KLy/i8w+elOk9pHAuJJStHTzU7LT4uprFDyaMQPXaFqKgeO71eKpstS35+Em4egJ4zoP0bBe4+fOcw43eOR6lQ8seTf5jkQgqQd1II6T+ArNBQ7IcMwX36Z+RERuZfoXn5Ctl37hR6vMrJqcCkfbOaNVEoxZbIlYGk05F182a+hD3z8hV0iYmFtjfz9My/ItfPr1KUzHmY5zY/x+XYy7zb8l2GNxh+/44lPSH8uFxkt+Uo4wVoYtKy05iwawKno05jo7FhSa8l+Dv5l/xEkZdhflu51+61kyUqhZKpy2TSnkkcunMIS7UlC3supKlr05LHYALSzpwhdOgLKG1sqHf4EAozs4cek3r8OGHDhoOZGT5bt6KpUboafeejz/PilhdRK9RseWYLHtYepTpPSU3/+zLLDoXwfCtP/jeo8cMPMALRY2fiUjJzmPfvDXZfieLv1zugUT9i4tHwGTmxu7iu0MSuXbV29KrVix2hO5h5bCYreq8wyUnrSq0Wj5mfE/rSyySsXUvyrl3o4uMLbZv3j7q8L6o/alcXk3xcZUnS6zn882SiM81IajqGJjXs8fWwwVxd+eelKVQqzH18MPfxwe4pubC2JEnk3L1bYJFGzt27ZN+6RfatWyTvuD8FQeXsjEXjxrhP+6TUQ0LGdCn2EpdjL2OmNONpn6fv35EaK8+lhRJvI5aUkc2F8ETO3krgakQyvfzdeKpJtTKM2rgszSyZ12Mer+x8hbPRZxm3cxxLey0t+QdYN3+oGyDvw3t4Djz1Q7EOy9Jl8da/b3HoziEs1BbM6zGv0iZ1ACn75NWwVh3aFyupA+Qe+XbtSD18mJh586j2xcxSXbuxS2Nau7fmeMRxfrn8S4WNMFWFbcTyEomdEaiVCv48FU5UciYbztzm2VaPuBLLrz/88y7cPQuxQYV+0nyv1XscuH2AM1Fn+Dv47/x/NEyIZcuWOLz4IvGrV8tJ3b0/9vmG4Xx9UZn63MdycvHABtqHLQCg6yYvQiQPNColfh42NPG0p0kNe5p42uPtbFVpN7DOS6FQYFatGmbVqmHT/f5WUjnx8fcXaVy5KtcYDAlBFxNDyp49xDg54jFjhhEjL53cnSZ61OqBgzbP6vAbOwEJ3BqBXdGT2TNzdFy5m8y5Wwmcu5XA2fAEgqPzF8/eeTmCVl6OuNtV3sr6/2VlZsX8HvMZv3M852POM3bHWJYGLC35ftkd3pQTu7O/QpfJYPPgDwfZumze2fcOB24fQKvSMrf7XFq4tSj9AzEBJRmGzctl0hukHj5M4oYNOI0Zg7l36Uq7jG40muMRx1kXuI5xjcflfx+UgzsJ6dyISkGpgPY+plW7rrREYmcEWjMVYzrW5ostV1mwL4hBLWqgepQ/wlZOcn2mG7vg4nroXHCyq7uVO+Mbj+eH0z/w7clv6eLZBVuNaSZHbpM/xKp9O9Quro/dxPmHUR76zvD9uy7HmZoymPi0bM6FJ3IuPBEIBcDGXE1jTzsa15CTvaae9lXqD7nawQF1u3ZYtbtf80qflkbK/v3cfvMtEjZsxHniRMzcTXsvzrxSs1PZErIFgCH1huS/8/p2+d88Kzb1eongmBTO3krkfLicyF2+m0S2ruDsGk9HC5rUsCcwMoVrkcl8u+MaXw8pxUIDE2atsWZ+z/mM2zGOS7GXGLNjDMsDlpdsEn7NtvL+suHH4dgC6DGtyKbZ+mze3/8+e2/txVxlzo/dfix52RUTkx0ZSeaVK6BQYN2pBDt7ABZNmmDdtSsp//5LzE8/Uf27b0sVQ1uPtvg5+nEl7gq/Xv2ViU0nluo8xbX/utxb18TTHjvL4vVQmjoxx64QFTHHLiUzh/b/20NiejZzX2hOv8aPOJfgzGrY+Cq4+MHEo4U2ydZl88ymZ7iZdJMXfF9gcpvJj3ZNoUJdPb4T3y2D799g7Yb01iXCE7M5e6+H5lx4AhduJ5KRXXAhiZutuaFHr6mnPY1q2GGrrRq/yPIKfell0k6exHH4MNwmV56f8T+u/cGMozOobVebjf033p9WoMuGr30gI5GjXX5jX4Y3524lcCE8keTMnALncbTS0LiGnSGhb1zDDidr+cPRqdB4Bs0/jEIBWyd1xNfdND/cPYrEzETG7BjD1birOFs4syxgWckKA1/9B9a8AOZ28NZF0BZ8jnL0OXx44EO239yOmdKMOd3m0L56+zJ8FMYR/8cfRHwyDW2TxtT+/fcSH59x9SohA+R9v2tv3IC2funmc++4uYN39r2DrcaWHYN3YGVWfhULJq4+zT8X7jKpe13e6mm6ZWnEHLtKwNpczYh2XszeHcjcf2/Qt9EjFmv17QebNRB9RZ4E7FZw8rCZyowpbaYwbuc41lxbw8C6A/F1fLyq11dmGf/KBWlP2femRdZJSIlEEbgTT9++eDpaGuZN5ej0XI9M4Vx4brKXyLWIJCKTMtlxOZIdl+8XY/Z2saLpvWSviac9flVgvp7T+PGknTxJ/B9rcXrllXIteF1WJEky1K4bXHcwSRk5XAhP5Fx4AmnX9/FeRiJxkjUvbNOhJ8hwnNZMSaPqdvkS9hoOFkX+LmlRy4G+jdzZciGCWVuusmKU6RVifVR25nYs7rmYUTtGERgfyJjtY1jeezk1bWsW7wT1+oBzfYi5JheD/s+8ZZ1ex0cHP2L7ze2olWp+6PpDlUjqoPTDsLm0vr7Y9OlN8tZtRP84B8+5P5XqPN1rdsfL1oubSTf58/qf+RcRlSGdXuLgjXv166rI/DoQPXaFqqhVsfGpWbT/cg9pWTqWj2xF1/qPuKLvtxfg2j/Q8V3o/nGRzd7d9y7bb26nqUtTVvRZgVIhVo2auqALR/FZF4BOUnDn5QN4Bq2BIz9B/b4w9LeHHp+WlcOlO0nyvKt7PXu34tILtDNTKfD3sM0zX88Ob2frSjVfT5Ikbg4aTMblyzi/OgGXNwouKDIlGdk6/rl2jE9PjUeJGQ6xM7gZdf/+D9W/8op6M3/pOrDI+UOaet5P5Oq6WqNWlez9ezMmlZ7f7yNbJ5nknphlJTY9ltHbRxOUGIS7lTvLA5ZTw6bo+Yn5nFkFGyeCjQdMOgdqucdTL+n5+NDHbArahFqh5tsu39KtZrdyfBQVR5+ZyfW27ZDS0vBa9ycWDUpXqiUzOJjgJ58CvR6vtX9g0ah0u0isD1zPtMPTcLVwZeugrWhUZV+i6nRYPM/MO4ytVs3pj3uW+L1UkUqSl5juo3gMOFhpeKG1/Cly/r9BD2ldDA2fkf+9uK7QPU5zvdvyXSzUFpyNPsumoE2Pfl2h3CXs+BKAs7Zd8KzTCJoPk++4vh2SIx56vKVGTSsvR8Z09OanF5pz4P1unJrag+UjW/Fmj7p0re+Co5WGbJ3EufBEfjkSyjtrz9Hju/00+WwHLyw+ypfbrrLtYgQRiRnl+VAfmUKhwGm8vAtL3KrV6FJSjBzRfXq9xI2oZP48Fc7HGy7y9E8HafTpdqbsWgJAZmIDQ1JX814v7HN2lwHo+8xwtk7qyKxnGvN865r4ediW6g+Rl7MVL7apBcAXW66g11fNz/ZOFk4sCViCl60XEakRjN4+mjsphZdKKqDRs2BTDZLvwvk/ADmp++zIZ2wK2oRKoeKrzl9VmaQOIO34CaS0NNSurmj9S1Eu5h5zb2/snpYX50XP/rHU53nS+0lcLVyJSo9ic/DmUp/nQXLn13Wo62zSSV1JiaFYIxvT0ZtfjoRy/GYcx0PiaF27dHvtAVC/D5hZQnwI3DkD1QvfYsfdyp0JTSbw3anv+P7U93T17IqduV3pryuUq/AbF2ma9C8owL7Xh1yLu4ZGo6F27iTvc79Bh7dKfF4na3O61nc19BRLkkR4fHq++XoXbyeRnJnD4aBYDgfFGo7NO1+vSQ15vp6dhenM17Pp2QNN7dpkhYSQ8PvvOI0eXeExSJJERFLGvV5SeYHD+fBEUv47L06ZgY3dOQAG+AwiIKAVTWrY42ilgfibMDsYFCrMfXuWWWxvdK/LulPhXL6bxF9nbjOoRTF7sioZZwtnlgYsZdT2UYQmhTJ6+2iW916Ou9VDFtWoNdD2VdgxFQ7/iNTkBWYe/4L1getRKpT8r+P/6Fmr7F4PU5Bb5sS6c6dHLhvlPPFVEjdvJvXgQdJOnsSyZcuHH/QfGpWGYQ2G8c3Jb1h2cRn9ffqjUpbtNJHcxK4qbCOWl0jsjMzdTsugFtX57fgt5u29QevajzDnRWMF9XrDpfXyVxGJHcBLfi+x4cYGghOD+enMT3z0xEelv65Qru5s+R81FBLnLNpwVnmNb/7+Bq1Ky/oGL+EZflweNmr/JjziL2OFQoGno2WB+XqBUSmGRO/srUSuRyab/Hw9hVKJ09ix3J0yhdjlP+Pw0kvlvro6MT3bkLzlJsdRyQW3tLMwU8nz4jztaOJpT3jObuZeyMLbzptZffvn/6N6/V6NvppPgEXZzRV0tNLwatc6fLntKt/uuEa/xh5ozSr33MqiuFq6sqTXEkZuG0l4SrghuXO1fMjUl+bDYd/XSDHXmbVzAn9EHkGBgs/bf07v2r0ffGwlI0lSnsSudPPr8tJ4emI/aBAJv/9O1A8/UGvlylIli4PrDWbR+UWEJoWyK2wXAV5lt0dyYpq86AygYxWaXwdijl2hKnqv2JsxqXT7di96Cf55owMNqj1C79mVzfD7i2BbA968AA/YdeHY3WOM2TEGpULJmn5r8HPyK/11hXIRdTsE+0UtUCt0TGnxEv/E7Tfc94RbKxad2oYiOxVGboNabSskprzz9c6FJ3LuVgJhcWkF2pmpFPh52OaZ2F+x8/Wk7GxuBASQc+cu7tM+wWHo0DI7d0a2jit38z8HwTGpBdqplArqu+XWGLQrMC9OkiSG/D2Ea/HXeL/V+7zs/3L+E6waJJcx6vGZXGOtDGVk6+j2zV7uJGbwfu/6vNqlTpme39TcSbnDyG0juZN6By9bL5b3Xo6zxYPnF0o7P+XrK8tZaWeLAgXT209nQJ0BFRNwBcoMDia4bz8UZmbUO3oEpdWjr0LNjoggqFcAUlYWnkuXYN2+dAtM5p6dy4JzC/Bz9OP3J38vsyL0Wy/cZcLq0/i4WLH7nS5lcs7yJFbFVjJezlY82bgam87dYd7eIOa+UHRP20PV6QHmtpAULg/T1XyiyKZtPNrQx6sPW29uZeaxmfzS5xexkMLEBG/6kmZKHa+4+nDkXlI3osEIfrv6G0cjT7C5XjueurQTzqyssMQud75eK6/70wbiUrPur8K9l+zEpWZxPjyR8+GJrDwq19ezNlfLpTjyJDruttpy2TFEYWaG08hRRM6cSeySpdgPGYJCXfJfeXq9RFB0imHRyfnwRK4UUS+upqOl4bE19bSnQTU7LDRF94RdjLnItfhraJSagkXDs1Ih5ID8fb2y7yHSmql4N6A+b/9xjvn/BvFcS09DWZSqqJp1NZYGLGXk9pHcTLrJmO1jWBqwFCcLp0LbS5LE99ZqVtrJf0Sn1XupSiZ1ACl75d46y1atyiSpAzBzd8dh6PPErfiF6B9mY9WuXane5y/4vsCKSyu4EneFI3eO0K56u4cfVAxVbbeJvERiZyImdPFh07k7bLlwl+DoFLxLuxGxmRZ8n4Rzv8qLKB6Q2AG80/Id9oXv41z0OTbe2MjAugNLd12hzCXEROAV9Rfj3Vw5ZZGNWqnm8/af08+7H3bmdsw+PZuvsm/TQanE4dJf0Pt/hdbcqgiOVppC5+vdT/YSuXBbnl/23/l6rjbmhlIdZT1fz37wIGLmzyf79m2StmwxTOouiiRJ3E3M4Py9YedztxIMcf+Xk5Um3+rhxrnz4kpg7XV5p4kAr4CC81yD94EuE+xrgkv57O88oGl1lhwI4fLdJObsucGnT1e+TetLooZNDZb2WsrIbSMJSgxi7M6xLO21tMDuBpIkMefMHJZfl2u5TY2JY5D6JFTMZ6cKZxiG7fLow7B5OY0dS/wfa8m4cIGUf//FplvJF5s4aB0YVHcQq66sYunFpWWS2EmSxP7rVa/MSS6T6J6ZO3cuXl5eaLVa2rRpw/Hjx4tsm52dzfTp0/Hx8UGr1dKkSRO2bduWr82nn36KQqHI9+Xra9r12vw8bOnu64okwcJ9wY92stzVsZf+Al3BP0h5uVm58WrTVwH4/tT3JGYWvuG6UPEObZzBK9XsOWWhxdrMmgU9FtDPux8AwxsMp65DXRKyU/jGoyZkp8nzKk1E7ny9JxtX46N+/vzxSlsufNqLrZM68uWgRgxtXRN/D1tUSgVRyZnsvBzJ19uv8dLSYzT5bAfdvtnLW7+f5edDIZwJiycjW1eqOJQWFjgOl2tgxSxahKTPX7g5MS2bA4HR/LQnkDErTtL6i920+98eXll1mgX7gjgSHEtKZg4WZipa13ZkXCdvfnqhGQfe78rJqT1YNqIVk3rUpUt91xIndclZyWy7Kf/uGlxvcMEGgfd2m6gb8MjzJ4uiVCqY0leegrHqaCghhQwnVzU1bWuyNGApzhbOBMYHMm7nuAK/9+afm8/iC4sB+LDBGJ5LSZNfj8jLxgi5XOmSk0k7dQoom/l1eamdnXF8WZ5eED37xwLvv+Ia3mA4aoWa4xHHOR99/pHjCopO5XZCOhq1kidqF95jW5kZvcfu999/5+2332bBggW0adOGH374gYCAAK5du4ara8HJrVOnTmXVqlUsXrwYX19ftm/fzsCBAzl8+DDNmjUztGvQoAG7du0y/F9diiGYivZq1zrsvhrF+jPhTOpRl2r2FqU7kXcXeaJ1ajSEHpT//wAv+L3AX4F/EZQYxJwzc5j6xNTSXVcoM2dvneQb9hKj0WCvtGJJ75/zbWpupjTj07af8tKWl9ik0fOk1py2p1dCixHGC/oh1Colfh62+HnY8ty9nZfSs3RcunNvsUG4vHI0NDaN4JhUgmNS+evMbaDgfL0mNezwcSnefD2HF4YSu3gxWTeCOPfH35zxbMz5Ys6La3pvgUMdl5LXi3uYf4L/IT0nHR87H5q5Nst/pyTdXzhRDsOweXWo60znei7sux7N19uvMu/Fyr3XaXF42XnJw7LbRnI17irjdo5jca/F2GpsWXR+EfPPzQfgvZbv8WKDYRB8Gi5vgEOz4ZmFxg2+jKUeOgQ5OWhq10ZTq1aZn99p1Ejif/2VzGvXSN62Ddu+fUt8Dncrd/p592Nj0EaWXljK7G6zHymm3NWwrb0cHzhVorIy+uKJNm3a0KpVK376Sa5Qrdfr8fT05PXXX+fDDz8s0L5atWp89NFHTJx4f/+4QYMGYWFhwapVqwC5x27Dhg2cPXu2VDFV9OKJvJ5beIRjIXGMbO/FtKceYVjk70ly1fTmw+DpOQ9tfiLiBKO2j0KBgt+e/I0GTlV7SMaUHbt7jNd3vEI6OdTMklj47FZq2HkW2nbWsVn8evVXamTnsP72XSwmHAHXyr0IRp6bJw/f5g7lxqZmFWhnba6+t7r0fgKWO19Pp5cIzjMvzuOP5XQ7vZWrDp681emNfD1gtZws8y3w8Pd48Ly4siBJEoP/Hsz1+Ot82PpDXvR7MX+Du+dhYUe5fNH7IfIUi3J0NSKJvrMPoJdg3YR2tKhl+rt1lIUb8TcYtX0U8ZnxNHJuRMfqHZl3bh4Ab7V4i1ENR8kN75yBRV1AqYY3zoJ94e/HyujOh5NJ3LABxxEjcPvwg3K5RvTcucTM+QlN7dp4/72pVHNdgxOCGbBxABISG/pvwMfep9TxjFh+nL3Xopncx5fxnUt/nopUaRZPZGVlcerUKSbn2c9RqVTSo0cPjhw5UugxmZmZaLX5f8lZWFhw8ODBfLcFBgZSrVo1tFotbdu2ZdasWdSsWfiWMpmZmWRm3i9LkJSUVNqH9Mgmdq3DsZDjrDl+i9e61in9ZOaGg+TE7vIm6PutXJfpAVq5t6JP7T5sDdnKF0e/YGXflWIhhRH8E/wPUw9NJYccWqRnMMJ1XJFJHcAbzd9gd9huwtMiWWhvy5unV0LvLyow4rLnaKWhS31XuhQyXy+3lMiFe/XgjgTHciQ4/3y9Gg4WXI9MyTcvzs6tNe2VO/GNv8VIixgcOrY37KfqUMIh1LJwPuY81+OvY64y50nvJws2yB2Grd253JM6AF93Wwa3qMEfJ8P5YssV/nylbbksaDE1dRzqsLjXYkbvGM2FmAtciLkAwOvNXr+f1AFUaya/FiH74Mhc6PM/I0VctiS9npQD8gKdsp5fl5fj8OHEr1xFVkgIiX9vxn7ggBKfw9vem241u7E7bDfLLi5jZoeZpYolM0fH0Xu/M6ri/Dow8hy7mJgYdDodbm5u+W53c3MjIqLwavoBAQF89913BAYGotfr2blzJ+vXr+fu3buGNm3atOHnn39m27ZtzJ8/n5CQEDp27EhycnKh55w1axZ2dnaGL09P430a61jXmUbV7UjP1vHz4ZulP1Gt9mDtBhkJELy3WIe82/JdLNWWnI85z4YbG0p/baHEJEli+cXlfHjgQ3L0OQSkpDI9Uk+7fq8/8DgrMys+aiPXIPzZzpZrl3+HnIK9W5VZ3vl6U/r68cd4eb7etjcLn693OiyBlMwcLDUq2tybF/fFyM5YPzMIgBGh+3ijuzwvzhhJHWDYF7bQRRMg7ygCUK/s6nY9zNs966M1U3IqNJ7tlx6+m0lVUd+xPot6LsJGYwPAhCYTGNd4XMGGueVmTq+AtLiKC7AcZVy8iC42FqWVFZbNH6Eaw0OorK1xGjsGgJiffkLKKt3vqNEN5ULjW4K3cDfl7kNaF+7kzXgysvW42pjj625TqnOYukrXJTN79mzq1q2Lr68vGo2G1157jZEjR6LMU6+tT58+DBkyhMaNGxMQEMCWLVtISEjgjz/+KPSckydPJjEx0fB169atino4BSgUCiZ2lbuGfz58k+SM7NKdSKmCBvdWuF5cV6xDXC1dxUIKI9Dpdfzv+P/47tR3ADyTmMNX0bHcqTcajfnDe2u61uxKz5rd0SkUfGalQnftn/IO2ejUKiW+7rY816oms55pxJZJHbn4aQDrJrRl9vNN2f5mJy58GsDv49sypa8f/Rp7UGvCWFCrSTtylPRz54wWe1JWEttC5EUTQ+oNKdggNQbCT8rf1+1VYXG522kZ29EbgC+3XSNbV7qJ7pWRv5M/659ez7KAZUxoMqHwRt5dwb2xvFDpxJKKDbCc5JY5sWrfHoWmfD/kOLzwAioXZ7Jv3yZhfekWejVyaUQb9zbkSDmsuLyiVOfInV/Xsa5Lle2VNmpi5+zsjEqlIjIyMt/tkZGRuLsXvuWLi4sLGzZsIDU1ldDQUK5evYq1tTXe3t5FXsfe3p569epx48aNQu83NzfH1tY235cx9fJ3x8fFiuSMHFYfCyv9iRrKPRRc/QeyC274XpgX/F6gjn0dEjIT+PF06ff5E4onIyeD9/a/x69XfwXgeYv2fBZ3hwRsafL0g3vr8vqwzRSsFWouaM35/dRP5RWuSbPQqGhRy5H+TatT390G1X8WVphVr47dU08BELNosTFCBGBz0GYydBnUsa9DE5cmBRvc2AVI4NYI7KpXaGzjO/vgbK0hJCaVXx/ld08l5G7lTiv3VkX/sVcooP0k+ftjCyCrYFHuyqYsd5t4GKWFBc7jXwEgZt589Bml23N6dCO5127d9XXEZZS853Rf7jZi9R5cnLoyM2pip9FoaNGiBbt37zbcptfr2b17N23bPrhgkFarpXr16uTk5LBu3Tr69+9fZNuUlBSCgoLw8PAos9jLk1KpYMK9KvBLDoSUutQDNVqBXU3ISobAncU6xExpxpQ2UwC5xtalmEulu7bwUImZiYzfOZ6doTsxU5rxZYcvefHqIQCue72MhVXxhwlcLV15s4H8C2+2LoKIu2fLI+RKz2nsGFAoSNm9m8zAwAq/viRJhtp1g+sNLjyJuH6vfFMFDsPmsjZXM6lHPQBm7w4kqbQjBlWV/wCwrwVpsXB2tbGjeSTZUVFkXJJ/v1t36lgh17R/dghqDw9yoqKIX7OmVOd4wuMJ/J38ydBl8OuVX0t0bFRSBlcjklEo5B67qsroQ7Fvv/02ixcvZsWKFVy5coUJEyaQmprKyJEjARg2bFi+xRXHjh1j/fr1BAcHc+DAAXr37o1er+f99983tHn33XfZt28fN2/e5PDhwwwcOBCVSsXQMtxSqLz1b1qN6vYWxKRksvZkKYeGFQpoMED+vpjDsSAvpOjn3Q8JiZnHZqKXHp8hmYpyJ+UOw7YO43TUaWzMbFjYcyHVghPw0oeRLFng1//tEp9zSPNXaSppSFMqmXlgMmK3wILMvb2x6Slv3h6zuOJ77c5Fn+NGwg20Ki1P+TxVsIEuG27skb83QmIH8HwrT7xdrIhLzWLB3iCjxGCyVGpod68n/fCPD60TaspS98s72WgbNULtUjFJjlKjwflVeag7dtFi9Kklr5uoUCgY00ier/fr1V9JzS7+OfYHykWJG1azK3HdycrE6Indc889xzfffMMnn3xC06ZNOXv2LNu2bTMsqAgLC8u3MCIjI4OpU6fi7+/PwIEDqV69OgcPHsTe3t7QJjw8nKFDh1K/fn2effZZnJycOHr0KC4V9MNbFsxUSsZ1koeXF+4PLv18l9zh2OvbIbPwxSOFeafFO1iZWXEh5gJ/Bf5VumsLhboad5WXtrxEcGIwbpZurOizgpauLbA89j0AF6s/i51DyYcJlAol03yHo5Yk9qaHszu0eL20jxuncfLE+KR/tpBVwfNp8+40YaspZMrHrWOQmQiWTlDdOPXkzFRKPuwtF3RfejCEOwnFm8bx2Gj2Elg6Q0KYXNuukqrIYdi87AcMwKxWTXRxccStKl2vZzfPbnjZepGclWxYiFQcBwKr/jAsmEBiB/Daa68RGhpKZmYmx44do02bNob79u7dy88//2z4f+fOnbl8+TIZGRnExMTwyy+/UK1atXznW7NmDXfu3CEzM5Pw8HDWrFmDj0/lqFWT13OtPHG21hAen87f5+6U7iQeTcDRB3LS4dq2h7e/x8XShYlN5VqBP5z+gYSMhNJdX8jn8J3DjNg2guj0aOo61GVV31XUdajLpcObqZdznQzJjHr933/4iYpQp/kYRqXIpXu+OPIZyVnFT+YfFxYNG2DVvj3odMQuXVph103MTGT7TXm1a6E7TcD9Ydg6PeUFUEbS09+NVl4OZObo+W7ndaPFYZLMLKCNPFeMgz/IxaQrGX1WFqmHDgMVn9gpzMxwee01AGKXLkVXivJiKqXKUI7ml0u/kKV7+CpbvV7iwL0eu05VeBgWTCSxEwqnNVMxqkNtAObtDUKvL8UvEIXifq9dCYZjAYb6DpW3rcpM4MczYiHFo/o76G8m7ppIanYqrd1bs6L3Ctyt5EVC0gF5Rew5l6dxcqtR+otoLBlXsze1srOJzkpi9ulHq9BeVTmNl3vtEtf/RXZUVIVcc3PwZjJ1mdR1qFv4ognIs9tExa2GLYxCcX+rsXWnw7l8x3i1PU1Sq9FgZgWRFyBo98Pbm5j0kyfRp6WhcnZG28C/wq9v27cvmjo+6JOSiMvTcVMST3o/iaulK1HpUfwd9PdD21+6k0RcahbW5mqaV/EC3CKxM3EvPVELG3M1N6JS2Hkl8uEHFCY3sbuxC9Lji32YWqk21Ej78/qfXIy5WLrrP+YkSWLJhSVMOTiFHCmHPl59mN9jvqFu1vXTe2mUeYZsSUXNpx698rt5ixFMi5FXi/1+7XfORJ155HNWNZatWmHRrBlSVhZxK0pXNqEkJEkyDBkNqTek8EUTcSEQcw0UKvDpXu4xPUyzmg70a+yBJMGsrVeMHY5psXS8v33fwR+MGUmpGIZhO3VCoaz4NEChUuHyxhsAxP28gpz44v9dymWmMmO4v7wP9PJLy9HpH7zIcP+9Ydi2Pk6YlfH2gKamaj+6KsBWa8awdvL+ffP+vVG6CfGuvuDaAPTZcumTEmjh1oInvZ9EQuLzo58/9M0j5KfT65h5bKah52xkg5H8r9P/0KjuT9xN3fUVAGcdeuJRq36h5ymRas1pZVuHgckpAHx2+DOydWJ1Y14KhcLQa5fw2xp0ieVbs/Fs9FnDoolCd5oACLzXW1ezLVjYl2s8xfVBgC9mKgUHAmMM9b+Ee9q+Km8xdvMA3D5l7GhKJLd+XUUPw+Zl07MnWn9/9GlpxC4uXV3AwfUGY2duR2hSKLvCdj2w7f0yJ1V7GBZEYlcpjGxfG62ZknPhiRy6EfvwAwrT8Bn53xIOxwK80/IdrM2suRR7ifU3SldY8nGUkZPB23vf5vdrv6NAwYetP+Ttlm/n26ot9MopmqUdQi8pcO1dcG/kUlEooNlLvBOXgKOkICgxiGUXl5XNuasQ686dMa9fH31aGnGry7d0xdpr8qKJ3rV7G3pqCzDsNmHcYdi8ajpZ8vITXgB8seUKutJMB6mq7GpAo3sFpg9VnikPmSEhZIWGgpkZVu3bGS0OhUKBy5tyXcD41atLNSXC0sySF3xfAGDphaVFdnwkZ2RzOlTuFexUt2ovnACR2FUKztbmPN9K3ud23t7Ciyw/VG5iF7wPUkr2ydvZwtmwkGL26dnEZ5S82/xxk5CRwJgdY9hzaw8apYZvu3xbcKN3IGqbvOfkWeuO1PJtVnYBNH4OO1R8EC2/1gvPLyQkMaTszl8FKBQKnMaNBSB+xS+lKr1QHHkXTRS60wRAZorc8wNQ1zhlToryerc62GjVXI1IZv3pcGOHY1pyCxZf3gSxlaM0TO4wrGXLFqisrY0ai1XHjvKUiMxMYhcsLNU5XvB9AQu1BVfirnD4zuFC2xwNjiNHL1HLyZJaTlaPEnKlIBK7SmJsJ2/USgWHg2I5HVaKxMrRW97IWtLBlY0lPvx53+ep61CXxMxEMSH/IcKTw3l568uciz6HrcaWRb0W0bNWzwLt7oRcpVmCPHxg07P0K2ELZeUEvv3ok5pGezNnsvXZTD8yXdS2+w/b3r3l0guJicSvXVsu1/g76G+y9FnUd6hPI+dGhTcK2Qe6LLn4rUsZDMeXIQcrDa91lQumf7vjOulZYjqGgasf1OsNSHJdu0rAWGVOCqNQKHCZdK/Xbu1asm/fLvE57LX2DKorzyNferHwVe650wiq+mrYXCKxqySq21swsJm8vdC8f0v5ydCwOrbkw6l5F1KsD1zP+ejzpYuhirsce5mXtrzEzaSbeFh5sLLPSlq4FV6P7NY/X6JW6DmvbUHdpuVQ+b35yyiAqbdDsFBpORl5kg03NpT9dSoxhUqF02h5x4645T+jL+Xm5EUp1k4TkGcYNkAeSjcxw9t5Ud3egoikDJYdEj2/+bR/U/737G+QXMoFbhVEl5JK2kl5PqApJHYAVk+0wbLtE5CdTfT8+aU6x/AGw1Er1ZyIOMG56IL7QO8PfHzm10EpEjsvLy+mT59OWNjjtY+gKXiliw8KBey6Esm1iFLUJ2swUP439DAklvyTUQu3Fjzt87RhRwqxkCK/Q7cPMXLbSGIzYqnvUJ9VfVfhbV/4HsYxEWE0jZaX6Ks6vVs+AXl3Bdsa1EiNZ6K7nDh+c/IbYtJjyud6lZTdgAGoXV3JiYwkcWPJe7Mf5EzUGYITg7FQW9DPu1/hjSTp/sIJExuGzaU1U/FegNyTOH9vEDH3aiUKQK224NkGdJlwrHSJSUVJPXwIsrMxq1UT89q1jR2OQe4K2cS/NpB182aJj3e3cjcsSlp6IX+vXWhsKqGxaaiVCtr6OD1yrJVBiRO7N998k/Xr1+Pt7U3Pnj1Zs2YNmZniTV4RfFys6dNQrns2vzRz7exqyCvukEpdMf2tFm9hbWbN5djLrAss+UKMqmrDjQ28tvs10nLSaOPRhp97/4yrpWuR7QM3fom5IpurZn74P9G7fIJSqqCZPK/vxds38HP0Iykria9OfFU+16uklBoNjqPkLQxjlyxB0pXdB5bc3ro+tfsUvWgi4jwk3wUzS/DqUGbXLmtPN6lGw+q2pGTmMGd3xe+za9Jye+1OLIMM0635Z0rDsHlZNmsmx6TTEf3T3FKdY2TDkShQ8O+tf7kRf//vY+4wbItaDlibq8skXlNXqsTu7NmzHD9+HD8/P15//XU8PDx47bXXOH36dHnEKOTxahd5rsumc3cIi00r+QlKWaw4l7OFM681k6uGi4UU8lDbwnML+fjQx+RIOTzp/STzu8/HWlP0pOTEuGga3ZGf/4wn3izfOlJN5cROHbKPaQ3Ho1Qo2RqylQPhB8rvmpWQw5AhqOzsyA4NI3n79jI5Z0JGAjtuyj1xRS6agPtFib27gJm2TK5dHpRKBVP6yEWLVx8LIzg6xcgRmZB6vcG5vrwd3Knlxo6mUJJeT8q9/WFNLbEDcJkk99ol/fMPGddLvtuJt5033WvK9R+XX7r/Guy7fm+3icdkGBYeYY5d8+bN+fHHH7lz5w7Tpk1jyZIltGrViqZNm7Js2TIxSbucNKxuR6d6LuglWLC/FHPt/PuDQinXXYq/WaoYnqv/HPUd6pP0mO9skKPPYfrR6fx09icARjcczRcdvsBMZfbA4y5v/AZrRTrBSi+adH22fIN0qAW15V/iDW4e4yW/lwD4/OjnpGWX4oNBFaW0ssJh2MsAxCxcVCa/vzYFbSJLn4Wvoy8NnBoU3TDwXiJZ13TKnBSlXR1nutZ3IUcv8dW2a8YOx3QoldBeTkw4Mg9yTG8UK+PyFXTRMSgsLbFs1crY4RSg9ffHJiAAJImYOXNKdY7RjeT5sluCt3An5Q7ZOj1Hgh6PbcTyKnVil52dzR9//MHTTz/NO++8Q8uWLVmyZAmDBg1iypQpvPhiwdIOQtmY2EXe9/bPk+FEJWWU7GBrV6jdSf6+FIso4N5CiifkhRTrAtcVOlm1qkvLTuOtf9/iz+t/okDBlDZTeLPFm0VPjs89LiUR31C5Zlp889cqpup782Hyv2dWM7HxK1Szqsad1DvMOzuv/K9diTi++CJKS0syr10zDFmVliRJ/Bn4kJ0mAFJjIPyk/H0905xf91+T+/qhVMC2SxGcvBln7HBMR6NnwaYapETA+T+MHU0BKXv3AmDdvh1KjebBjY3E5fXXQKEgeecu0i9eKvHxDZ0b0sajDTlSDisureB0aDypWTqcrDQ0qGZbDhGbphL/VTl9+nS+4dcGDRpw8eJFDh48yMiRI/n444/ZtWsXf/31V3nEKwCtazvSspYDWTo9Sw6WYoXaI6yOzdXMtRn9ffoDMPPo47WQIi4jjrE7xrI3fC/mKnO+7/I9Q32HFuvY85vm4EAy4Qp3mgQML+dI7/F9ErT2kBSO5a1jhqR85ZWVXI69XDExVAIqe3vsn38egNhH7LU7FXmKkMQQLNQW9K3dt+iGgTsBCdwbgW21Ul+vItVzs+HZlp6AXLRYjM7co9bIu1GAXLBYrzduPP9hqvPr8jKvUwe7p58CIPrH0o0GjWk0BpCrN+y4Js+161DXGaXS9Fabl5cSJ3atWrUiMDCQ+fPnc/v2bb755ht8fX3ztalduzbP3/sFKZQ9hULBxHt1pVYdDSUhrYQlGnyfBKWZvIF1dOmHU95q8RY2ZjZcibti2AezqruVdIuXt7zM+Zjz2JnbsaTXErrXKt6+nlmZGXhfl1ds3WkwHrVZBX1qNtNC43tDvqdX0qlGJ/p49UEv6fn08Kfk6HMqJo5KwHHEcBRmZqSfOUP6yZOlPk/uoom+tfs+cL7l/WHYytFbl+vtnvWwMFNxOiyBrRcjjB2O6WgxArR2EBsI17YYOxqDnJgYMi5cAMCqUycjR/NgzhMngkpF6v4DpJVi3n4b9zY0cGpAhi6D7bfkucyP0zAslCKxCw4OZtu2bQwZMgQzs8LnEllZWbF8uWlOIK0qutR3wc/DlrQsHSsOh5bsYEtH8Okmf/8IvXZOFk73F1KcmU1cRtUelrkYc5GXtr5EWHIY1a2rs7LPSpq6Ni328Wc3L8CVOKJwpMmTr5RfoIVpJs8f4+o/kBrL+63fx0YjJ+Wrr5TvdlqViZmrK3aD5F1aYhYuKtU5EjIS2Bm6E3jIogldNtzYI39fr5xWRpcTV1stYzvJpXy+3HaVrBzT6p0yGnMbaCX3GHHoB7mUjQlI2S8vltL6+2PmWvRqfVOgqVkT+2fk92D09z+UuEdYoVAYeu0S1P+CMoOOj8E2YnmVOLGLiori2LFjBW4/duwYJx/hE65QMgqFglfvzbVbfjiE1MwS9rrkXR37CL98nq3/LL6OviRnJfPDqR9KfR5Ttz98P6O2jyIuIw4/Rz9W9V1Fbbvi14HS5eTgcVHeMie47gjMtZblFWrhPBqDRxPQZ8P533G2cObdlnL9vLln53I7peR1Dasqp9GjQakk9eBB0i+VfJ7PxqCNZOuz8XP0o4HzAxZNhB2VV1FaOkH15o8QsXGM7+SNs7U5obFprD5Wwg+XVVmbV0BlDuEn5JqhJsAwDNvFdIdh83J+dQIKMzPSTpwg7ejREh/frWY3nM1roFBlUN3zHK62prvavDyUOLGbOHEit27dKnD77du3mThxYpkEJRRP30YeeDlZkpCWzW/HS1gwun4fUGvlIYOIC6WOIe+OFH/d+IuzUWdLfS5TtT5wPW/seYP0nHTaVWvH8t7LcbYo2SfAsztW4CndIQFrGj09qZwifYjcXrszq0CSGFhnIC3dWpKek86MozPEXKl7NJ6e2PaTiwnHLlpcomMlSTJMSxhS/wG9dXB/GLZOT7nmYCVjZa7mrZ51AfhxdyCJ6dlGjshEWLsa6kdy6AejhgIgZWeTeugQYNrz6/Iy8/AwzHeN+qHkvXZKhRI3fR8Asq33kqUr2x1lTF2JE7vLly/TvHnBT5fNmjXj8mUxEbsiqZQKXuks99otPhBMZk4JFjBobe+XVyhlTbtcTV2bMqDOAIAqtSOFJEnMOzuPaYenoZN0PO3zND91/wkrs5JtIi3p9difkpfvX635AlY29uUQbTE0GiIn81GX4M5pFAoFn7T9BDOlGYduH2LbzW3GicsEOY2Vh3KSd+wgMzi42MedjDzJzaSbWKotH7xoAu7Xr6skq2EL81xLT+q4WhOfls2CfaXc6rAqavuaXFYqcAdElrzXtyylnTqNPiUFlaMj2kZF7FVsgpzHjUWh1ZJx7rxhRW9xSZJEUEg99Nl2pOvj2RS0qXyCNFElTuzMzc2JjCy4H97du3dRqx+Pqs6mZGDz6rjbaolMymT96RIOp+UOx15a/8hzQd5s/iY2Ghuuxl3lj+umt9S/pHL0OXx65FPmn5O3CBrbaCyft/8cM+WDa9QV5vzeP/HRhZAmmePXv5y2DysOC3vwk1eccXolALXtajOu8TgA/nf8fyRmJhopONOirVcP6+7dQZKIXVL4xuKFMSya8O774A8AcSEQcw0UqvvzXSshtUrJh73lxXPLDoZwJyHdyBGZCCcf8Hta/v6QcWt9GoZhO3WqmPJKZUTt4oLjy3Ldzegf5yCVYJXx1YhkopN1SAlyD+Xyi8urTIdDcZT4Ve7VqxeTJ08mMfH+H4CEhASmTJlCz549yzQ44eHM1SrDJOYF+4LI0ZVgEnPdXqCxhoQwuWDxI3CycOKNZnKBzjmn5xCbHvtI5zOmtOw03tjzBusD16NUKPn4iY95o/kbD61RVxTNkR8AOO8xGDsntzKMtBRyh2MvroMsuUDx6Iaj8bHzIS4jju9OfWfE4EyL87ixACRu2kT2nTsPbR+fEc+u0F3AQxZNwP29YWu2lRPuSqy7nyutazuSmaPnmx2iaLFBhzflfy/8Kf+ONRJD/bpKMr8uL8dRo1BaWZF55QrJO3YU+7jcbcRaOgVgZ25HWHIYO8N2lleYJqfEid0333zDrVu3qFWrFl27dqVr167Url2biIgIvv322/KIUXiIoa09cbA0IzQ2jS0lKT2gsYT694aLHnE4FuQ/Zn6OfiRnJ/P9qe8f+XzGEJsey6jtozhw+wBalZYfuvzAs/VLvzvE5aPb8Mu+RJakps7T75dhpKXk1RHsa0FmElyWN7w3U5kxrd00QJ5PeCLihDEjNBkWTZpg+cQTkJND7LKHr/LfeENeNOHv5I+/k/+DG1+/N7+uEg/D5lIoFHzUV95q7K8zt7l0R/T6AlCtmbzri6STd6MwgqywMLJCQkCtxqp9e6PE8CjUDg44jhgB3Ou1K+Y+zvsD5cSuaz1PXvSV5zsuvbD0sZlHXOLErnr16pw/f56vvvoKf39/WrRowezZs7lw4QKenp7lEaPwEJYaNSPbyys05/17o2Q/vHmLFT9iV7VKqTIUv90YtLHSLaQITQrlpS0vcSn2Evbm9iwJWELXml0f6Zw5e78B4IxzP5yreZVBlI9IqcyziGKl4eZmrs14tp6cwE4/Mp1MneltiWQMzuPlYeqEP/8kJ7boXuj/7jTxQJkpcPPeXr1VILEDaOJpz1NNqiFJMGvL1cfmD+hD5fbanV4BaRVfDiplrzwMa9m8OSobmwq/fllwHDEclZ0dWcHBJG3e/ND2aVk5nAiR9zDvWNeFob5DsVBbcDXuKofuHCrvcE1CqQbcraysGDduHHPnzuWbb75h2LBhRda0EyrG8LZeWGlUXI1IZs/VqOIf6NNNLqiZEgFhRx45jiYuTXimrlyDaOaxmZWm+O356PO8vOVlwlPCDTXqmrg0eaRz3jh3iMYZJ9BJCmr0m1xGkZaBpi/IE7tDD0Hs/Qnvk1pMwsXChZtJN1l8vmSrQasqyyeeQNuoEVJGBnG/rCyy3YmIE4QmhWJlZvXwRRMh+0CXJfecOtcr44iN5/2A+mhUSg7eiGHfvaGwx553V3BvDNlpcLzi31OVYbeJh1HZ2OA4Rt4DNvqnuUjZD159fSwkjiydnur2Fvi4WGGvtWdwvcGA3Gv3OCj1TMrLly+zbds2Nm3alO9LMA47SzNeeqIWAHNL0mun1tyfUF8Gw7EAk5pPwlZjKy+kuGb6Cyn23trL6O2jic+Mx9/Jn1V9V+Fl5/XI503a+SUAZ+y6U93b75HPV2bsqoPPvd0yzqwy3GyrsWVyGzkBXXpxKTfibxgjOpOiUCgMvXbxq1ejS04utF3uool+tfthafaQGoWGYdjeUMp5m6bI09GSYW3l30GztlxFpxe9digU93vtji80zGutCPrUVNKOHwcq5/y6vBxffBGVszPZt26RsP7B25Xmzq/rVM/ZMC96mP8w1Eo1JyNPVrqRpNIo1c4TTZo0oWHDhvTr148BAwYwYMAABg4cyMCBA8sjRqGYRneojUat5HRYAsdCStDtnzsce3mjXA3/ETlqHZnUXK7V9tOZn4hJj3nkc5aXP679waR/J5Ghy6BD9Q4sDyh5jbrChF0/S9Pk/QA49f7wkc9X5prfG449+yvo7veq9qjZgy6eXcjR5/DZkc/QS2JHAetu3dDU8UGfkkL8r78VuD82PZZdYfKiidyegSJJ0v2FE/V6lXWoRvdatzrYatVci0xm3alwY4djGvz6g4MXpMXm+yBV3lKPHkXKzsasRg003t4Vdt3yoLS0xHmc/AErZv589JlFTxUxJHZ5thFzt3LnKW+5A2Ppxarfa1fixG7SpEnUrl2bqKgoLC0tuXTpEvv376dly5bsLWGtGaFsudpqebZlDUDutSs2r05g6Sz/4gnZVyaxDKo7yKQXUkiSxJwzc5hxdAZ6Sc/AOgP5sduPD+9tKaaILV+iVEicsWxHbf9WZXLOMlWvj7zjQUoE3NhluFmhUPBRm4+wVFtyNvrsY7MH8IMolEqcx8orZONWrECfnr+kx6agTeToc2jo1BA/p4f0zEach+S7YGYJtTqUV8hGY2+p4fVuctHib3deIy2rckzFKFcqNbR7Xf7+yJx8H6TKU+78OusuXUq9ot+U2D/3LGp3d3IiIkj4/fdC29xOSCcoOhWVUkG7Ovk/oI9sOBIFCvbe2ktgfGAFRGw8JU7sjhw5wvTp03F2dkapVKJUKunQoQOzZs3ijTfeKI8YhRIY38kHlVLBgcAYLoQXc3WaSg0NBsjfP8LesflOqVQx9YmpgPyH73RkyTdzLi/Z+mw+PvQxi87Le4FOaDKBz9p9VqoadYWJCAukWbw83GbRzYh16x5ErYHGcmX3vIsoQP50+0Zz+b38/anviUorwZzNKsq2b1/MqldHFxdHwrr77xG9pC/+ThNwvyixd1cwq5rbHA1rV4saDhZEJmWy9ECIscMxDU1flD88J4TBpQcPJZYFSZKqxPy6vJTm5jhPmADI+zjr0woOa+f21jX1tMfOIv/v89p2telRqwcg17Wrykqc2Ol0Omzura5xdnbmzr36TrVq/Z+9+w5vqmwfOP49Gd17slpGKXuVvSlDQBwIuABlyxIV9x6vvv5EfVVQcYCCLAUHoCKiCCJ7711WW0oLdNI9kuf3x2kLlZauJCdtn8919WpMTs65G2l65xn3XZ9Tp2QNI60F+bhwd9s6AHy2qRyjdgXTsSfWQJ5ldkS28W/DiFD1vPaykSI9N53HNjzGz2d/Rq/oeaPbG0xvN92in2gv/PouRsXEMYe2NOvY32LntbiC6djT6yCtaPL2YNMHae3XmrTcNGbtnqVBcPZFMRrxzV/AnbDg68IF3LvjdhOVGoWr0ZXBDQaXfqLT+d09quE0bAFHg55nBzUF1Nqa8WlyhzVGZ7WHLKgFi628azj7xAnyrlxBcXbGpbMdzhhUkNfwYRiDgjAlJJC4dNlNjxckdr1Ci19OM7GV+ju89vzaat0fu9yJXatWrTh06BAAXbp04b333mPbtm28+eabNKri8/jVxbRwtc3YumNxnLmSVrYnBXUF9zpqU/IzGywWS8FGitNJp1lxqvjhc1uJz4xn/LrxbLu0DWeDMx/3+5gRTUZY9BqJV2Joe0WtD2fu+bRFz21xAc2hbkcw58GhomvH9Do9r3d7HYNiYH3kejZGbdQoSPvhOXw4ej8/8i7FkrLmN4DC0bo7G91Z+jR+evz1QuCh1TexA7irTR3a1PMkPcfEnL+q97RXmXWaCEZXuHzEou+xxSkYrXPt1g2do6NVr2VLitGI/wy1J33C118X2cyUZzKz7Yy6nrt3E/9in9/SryVda3fFJEwsOrbI+gFrpNyJ3SuvvII5v7XHm2++yfnz5+nVqxdr167l448/tniAUvk1CXTnthaBCEHZ+zfqdNBKLVNiqd2xAN5O3naxkeJ8ynkeWvsQJxJP4OPkw4JBC+hdr7fFr3Pq5/dxVnI4bWhCq553Wfz8Flcward/yU2jCE19mjK25VhAHXFNyynjh4RqSufoiO849fVImDeP+LQrbIhS/0CXWrsOIGI9INTyFx51rBip9nQ6hRdvV9cbfrs7irNXa/a/HQBcfKDDOPX2ttlWvVTh+rpqMg17I48778QhJARzSgqJ31xPzg5dTOFaVh6ezkba1vMq8fmTWqt9oFdGrKzSHZJupdyJ3aBBgxg+XE0AGjduzMmTJ4mPj+fKlSv061d1ex5WN9PzR+1WH4jhYlIZt9i3zE/sTq2FnHSLxTIidAQtfVuSlpvGh3tt37Lq4JWDPPz7w8SkxRDsHsyS25fQyq+Vxa+TmpJIyxh1VDK98+NVoy9jy+HqQv6ECIjeddPDU9tOJcg9iCsZV/jkwCcaBGhfvB58EJ2HBznnz7Pluw/IM+fRxq8NTX2alv7kwmnY6lGUuDTdQnzp3ywAk1nw7u8ntQ7HPnSbDjqDWqC6km0cS5KXmEjm4cMAuPWx/IdXrSl6Pf6PqZtREr/5hrwktRhxwTRsz8Z+6HUlL63pXKszrXxbkW3KZtmJm6dzq4Ny/eXJzc3FYDBw9OjRIvf7+PhUi1031UlYsDc9GvuSZxbM33yubE+q214tmpqbcb3WlgUUbKRQUPj13K/sjdtrsXOXZkPUBib9OYmU7BRa+7VmyZAlBHsEW+VaR3/+CA8yiNQF0bb/KKtcw+KcPKBlfpmiAzcX4HUyOPFq11cB+O7kdxy+etiW0dkdvZsb3qPV/7eu360DIUovcQJqGaGz+dPZoTUjsQN44fZm6BT48/hldpenBFN15VkPWue3KNw62yqXSN+yBYTAsVkzjLVqWeUaWnMfeBuOzZtjTk8n8Wu1fElBG7HeTW5drkpRlMJRu+Unl1fLmYhyJXZGo5Hg4GBMZezXJmlrenhjAJbviS7bAmZFuaHFmOWmYwFa+bUqXM/29q63yTVXvl5eaZafXM5Tm54i25RNn3p9+GrgV/g4+VjlWlkZaTQ5p04LXGk7HZ1eb5XrWEVBi7GjqyD75gK83ep04+6QuxEI3tjxhk3+39kznzFjEE4OBF3KoUu0E4MalCFRi9qp9ud18VM/QNUQoYHuPNBJ/SD1f2tPyFZjAD3UpSmc+BXiLV8EvHA3bBUvSnwrik6H/+P5o3ZLl5EYFcuh6GRAbSNWmr7BfWno2ZDU3NTC4uLVSbnnil5++WVeeuklEhPlpy971z3El7ZBXmTnmVmwtYxlBwoSu4j1kGXZZt5PhD2Bp6MnZ5LPsPzkcoue+0ZCCGbvm83bu97GLMyMCB3B7L6zLVajrjiHfv0UX1KIVfxpd/tEq13HKoK7gm9jyE0vsRTDMx2fwcvRi4ikiGq96LgsDN7eHO2urpEbs9e1bP+uCqZhQ28DXRVK+i3gydtCcXHQczA6md+OxGodjvYCmql1JBGw3bLr0kVuLmlbtgLVc33djdzCw3Fu2xaRlcXpDz/BLKBxgBt1vJxLfa5O0TGh1QQAFh9fXO16Y5c7sfv000/ZvHkzderUoWnTprRv377Il2Q/FEXh0fy1dkt2RJKSWYaRlsCW4NcUTNlwcq1F4/Fy8mJm+5kAfHbwM65mWL6fZK4pl5e3vlxYXfzRdo+quzt1Botfq/CaOdkEn/gKgKhmj2B0qGK70BQFwh5Sb+8vvh+qt5M3z3V6DoAvDn1B1LUoW0Vnd+Iz4/myRSx5OvA/dYWM/QdKf1JBt4lqvhu2OAHuTkzurVZMeG/dKbLz5IxPYZuxQ99BapzFTptx4ADm1FT03t44t2ljsfPaI0VR8J+pjn66rf8V/4ykIt0mSnNHwzsIdAkkPjOeX85Wr3ao5U7s7rnnHp555hlefPFFRo0axdChQ4t8SfZlQPNAmgS6kZqdx9KdkaU/4cbp2GOWKVZ8o+Ghwwvro324z7IbKdJy0pi+YTq/nvsVvaLnze5vMrXtVKuv/zy49itqc5V4vGh716NWvZbVtB0Fih4u7oarxdejvLPRnXSt3ZVsUzZv7nyzxk6rrT6zmivuJo508gXUHbK3lHgO4k+ri+ZDauYGs0d6NcLf3ZGoxAyW7qy5HwoKBXeFoC5gyoGdn1vstIVlTnr1RKlKy0EqyLVbN1y6dEFvymPkqb9KXV93I6PeyLiW4wC1YLE91Fm1lHIndq+//votvyT7otMphXXtFmw9T2ZOGT4tF5Q9ObsRMiw75a5TdLzc5WUUFNacW2OxjRRXMq4wbt04dsbuxNngzKf9P2VYqPV7F5tNJgIOfwbAmUZjcHJxs/o1rcI98Ppuzf2Liz1EURRe6/oajnpHdsXu4tdzv9owQPtgFmZ+Oq2uP/WcMA50OtI2bSLrVsXZC7pNBHcDZy+rx2iPXB0NPHVbEwA+2RhRttmD6q7HTPX73gUWW/ZS3bpNlEX2GHUjxMCoPbTXl6+aw/DQ4Xg5ehGdGs1fkX+V/oQqogrUY5Aq6642dajn7UxCeg4r9pTh07JfqFpry5wHJyw/RN3Sr2XhTkJLbKQ4l3yOh9Y+xKmkU/g4+bBw8EJ61rVNH85Dfy2lvvki13Ch5dAnbXJNqynYRHFoOeTlFHtIkEcQ09qqbX3e3/M+iVk1a63tzks7uZh2EXejO/16jMZjsJoMJ8ybX/KTIvJ3mNfAadgb3dehHqEBbiRn5JavK0511WQw+DdTN9XsrXyLq5yLMeScOQt6PW49q18f4pJscazLnsBm6IWZ1HnlG/10Mbowqrm6y/2rI19Vm1mIcid2Op0OvV5f4pdkfwx6HVP7qKN28zafIyfPXPqTrLQ7tsDjYY/j5ejFmeQzfHfiu9KfUIL9l/fz8O8PE5seS32P+iwdspSWvi0tGGnJhNmM2x61ttuxeg/i7mmdHbc2EzoQ3AIhI/76Yv9ijGk5hibeTUjOTuZ/e/5nwwC1V7CD7s6QO3E2OOP7yCMAXPv9d3Iii1nqkJ0GF9TF7DQpQ8uxasyg1/HikGYALNx2oez1NasrnQ665/dX3/l5pVs5pv2zCQDnsHboPT0rGVzVsfn0VRY3V3+3rv26huwz5fvQMKrZKJwNzpxKOsW2S9usEaLNlTuxW7VqFStXriz8WrFiBS+88AK1a9dmXmlrTSTN3NuhHv7ujlxKyeLng2XokVdQ2+z8Fosu7i1QZCPFoc8q1Gh+feR6HvnzEa7lXKONfxuW3L6EIPcgC0dasqNbfyY0L4JM4UCzoc/a7LpWozdA25Hq7QNLSzzMqDPyRrc3CusSbr+03UYBautqxlU2RW8CrneacGreHNc+vcFsJuGrr29+0rlN6joq7wbqSHgN17dpAF0b+ZCTZ+aDP09rHY72Wt8HHnUhLQ4OV67lYsE0rHt4uAUCqxqyck3sOp/AGa960DschODqx+UrpO7p6Fn4+/zVka+sEKXtlTux+/dmiXvvvZe3336b9957j19+qV47S6oTJ6OeST0bAvD5P2cxmUsZcvauD/U6AQKO/2yVmIaFDqO1X2vSc9P5YO8H5XrushPLeHrT0+SYc+gb1JevBn6Ft5O3VeIsiW6ruvnjUOA9ePtXkxZRBbtjz6yHa5dKPKy1f+vCKYy3drxFZl6mLaLT1Oozq8kTebTzb0eo9/UkzW/KFABSVq8m9/Llok8qnIYdpG5MquEUReHlIS0AWHUghqMxli2pVOUYHKDrdPX2to/BXIbZlGKYMzLI2Kl2jqlJ6+v2XkgiK9dMoIcjDZ95EhSF1D//JPPYsXKd5+EWD2PQGdh3eR8Hrxy0TrA2ZLE1dl27dmXDBus2NpYqZ3TX+ng4GTh3NZ0/jpVhFM7K07E6RcfLXdWNFGvPr2VP3J5Sn2MWZj7c+yGzds9CIHig6QN8FP4RzobSaxdZ0sk9f9Ey5zA5Qk+Du5636bWtyi9UXeQvzHDw21se+ljYYwS6BHIx7SJfHPrCRgFqwyzM/BSh/h78u9OES/v2OHfsgMjNJXHhN9cfEOL6xoka0kasLFrX82RoO/WDkCxaDHQYC06ealu/U79V6BTpO3chcnIw1qmDQ+PGFg7QfhV0m+gV6o9TkyZ43HknAPHlHLWr5VqLu0PuBuDrI8WMvFcxFknsMjMz+fjjj6lbt64lTidZiZujgXHdGwDw2aYzpb+htrgHUNQeosnWKVHQ0rcl9zdVW+y8vfPWGylyTDm8sOUFFh5TFxo/0f4JXu7yMnoNCr5m/a2uLTvkPZhaQdXsjbRgE8WBpbccQXA1uvJK11cAWHRsEacSb7EztIrbcWkHMWkxuDu4F9tpomDULun77wt7VxJ7SJ1iM7pCg5qzmL0snhnYFAe9ju1nE9h0yvL1LKsUR3fopK7VZOts9QNBOd3YbaImtfcs6A/bu4lav87/0emg15P2zz9kHChDfckbjGs5DgWFTRc3EZEUYfFYbanciZ23tzc+Pj6FX97e3ri7u7NgwQLef/99a8QoWdC4Hg1xNuo5GnONzRHxtz7Yo/b1P0gldCSwhMfCHsPb0ZuzKWf59kTxo0SpOalM+2sav5//HYNi4O2ebzOp9SRN3sTOH9tFu4wdmIVCrTuq0WhdgZb3gIM7JJ2HyFsvJg4PCue2+rdhEibe2P4GJnP1LD5bsGni7pC7cTI43fS4a8+eOLZojsjIIGlpfmPxgqLEjcLBUMWKVltZkI8L43o0AOCd30+QZ6rYFGS10WUK6B0hZm+pv3P/JoSokWVOLl/L4mRcKooCPRur9escGjTAc9g9AFydU76uHg09GzKg/gAAFhxdYNFYba3cid1HH31U5Ovjjz9mzZo1REZGcvfdd1sjRsmCfFwdGNVF7d049+8y7B4qqGl31PLFigt4OnryZAe1VMhnBz/jcnrRdUqX0y8zdt1YdsftxsXgwtz+cwuHzbWQ8Md7ABxw70NQaFvN4rAaB9fr/98PFN+J4kYvdn4Rd6M7RxOOsvyU9VrFaeVKxpXCTRP3ht5b7DGKouA3eTIAiUuXYkpLh9P56+vkNGyxHg1vjKezkdOX0/hx30Wtw9GWWwCEjVZvb51drqdmnz5NXlwcipMTLl26WD42O1UwWte6ric+rg6F9/tPn45iNJKxcyfpO3eW65wTW6vtIH8//zsXU6vuv8lyJ3bjxo1j7NixhV8PP/wwgwcPxtvbtgvXpYqb1KshRr3C7vOJ7L1QSh2y5kPVjgSxByHhrNViGtp4KG3825CRl1FkI8WZpDOMXjuaiKQI/Jz9+GbwN3Sv291qcZQm5twxwlLUtaReA6vhaF2B9mPU78d/hszkWx7q7+LPzA4zAZizfw6xadWrH+iqiFWYhImwgDAae5c87e5+2204NGiAOSWF5CVfQ8w+9YEaXr+uJJ4uRh7rp76eH64/TUZO9an8XyHdHwNFp25cijta5qelbcrvNtGlCzqnm0eTq6uCGad/txEz1qmD1/3q8p6rs+eUaw1nS9+WdKvdDZMwVeme2OVO7BYuXMgPP/xw0/0//PADixZV3ReiJqnt6cyI9vUA+GxTKcmaqy+E9FVvW3HUrqAjhU7R8fuF39kdu5s9cXsYs24MlzMu09CzIUuHLKW5b3OrxVAWF9fMQq8IDjl1IqSNdgmm1dXtAP7NIS+rTJtn7m1yL2EBYWTmZfJ/u/6v2iyIN5lNrIxQ/90XlEQoiaLXF9a1S1y8BLNJqIW+PWpbPc6q6uFu9QnyceZKajZfbTmvdTja8mkELfLbcm6bU+anFU7D9g23fEx2ymwWbI0our7uRr5TJqM4OZF58CDpmzeX69wFo3arzqwiPrOU5Up2qtyJ3TvvvIOf38392AICAvi///s/iwQlWd+UPiHoFNh48grHL1279cEtC6ZjrbM7tkAL3xbc30T9pPXS1peYsn4KqTmphAWEseT2JdR103ZzztVLFwhLWAuAQ99qULfuVhQF2hdsoih9Olan6Hi92+sYdAY2XdzEX1HVoz3P9kvbuZR+CQ8HD26rf1upx3vedSeGWrXIS0oj5bxLjS9KXBpHg57nBqlFi7/85yxXUytXpLfKK2gzdvSnMm1Yy0tKIvPgQQDceve2Xlx25uilFJIycnFzNBAW7HXT48aAALxHq+WYrswp36hd51qdae3XmmxTdolrvm+SHAVp9rMJqNyJXVRUFA0bNrzp/vr16xMVJZs7VxUN/VwZ0lodSfj8n1JG7ZrdAXoHuHoCLh+3alwzwmbg4+TD5YzL5Jpz6R/cn3m3zcPTUftK6md/noWDksdxYyuad6kB66baPAA6I1w6UKapoRCvECa1Vvs2vrPrHa7llPKBoQoobdPEvykODviOHwtAwgk3RMgAq8ZXHdzZpjZt63mSnmNi9l81vGhxnXbqZhthgh1zSz08fetWMJtxbNIEY51qUkuzDArW13UP8cWoLz6N8Z00CZ2LC9nHT5D65/oyn1tRFCa2Ukftlp9cTlpO2q2fkB4Pi++BBQMh6UKZr2NN5U7sAgICOHz48E33Hzp0CF9fX4sEJdnG9HB1fctvhy9xPv4WzZOdvaBx/miFlUftPB09eaXrK7gZ3Xio+UN80OeDMv1Btbbk+DjaxKlTcrndZ2objK24+kHT29XbZRi1A5jUehINPBpwNfMqc/aVfTrJHl1Ov8zmi+o0TmnTsDfy6lwPvaOJ3HQD1w5eLv0JNZyiKLw0RF1isXxPNGeulPKHtLorGLXbvxgybr0GumB9XU3aDQuw+XT++rpipmELGLy98Rmnfsi6+snHCFPZd+z3De5LQ8+GpOam8v3p70s+MCcdvr0fEs+CKU/d2WwHyp3YjRw5kscff5y///4bk8mEyWRi48aNPPHEEzz44IPWiFGykhZ1POjXLACzUKdBbqnVDdOxVl4/dVv929g2chvPd35ekxp1xTnxywe4KNmc1TeiTZ8RWodjOwWbKA6vKFMvS0e9I691ew2A709/z/7L+60ZnVWtOqNummgf0J5GXo3K/Dxd1N/4NFE/KCV89RWigt0EapIujXwZ0DwQk1kw6/eTWoejrUbhULst5GbA7pLbdIq8PNK2qn2I3cJrTmKXmpXL/ii1VuS/N078m8+4ceg8Pck5c5Zrv5W9+LNO0TGh1QQAlhxfQrapmPc+Uy78ME7dJOXsAw+vtJv1tOVO7N566y26dOlC//79cXZ2xtnZmYEDB9KvXz+5xq4Kmh4eAsBP+y8Sl5JV8oFNbweji1rb7FL5Cj9WhE6xWFOUSku7lkSLKLU2WXKHx1F09hOb1YX0U3tZZibByTVlekqnWp0YEaomv//Z8R9yTDnWjNAqTGZTYaeJ+5qWfbQOgNN/4B2ajs7ZkeyICNI2bbJ8gNXQC7c3Q69T+OvEZXadS9A6HO0oCvR4Qr2960t1VKgYmYcOYU5JQefpiXPbalh2qQTbzyaQZxY08HUh2NfllsfqPTzwnaAmaFc/nYvILbkA/r/d0fAOarnWIj4znp/P/KutphDw60y1VqXBGUZ9b1e9oMv9F8rBwYEVK1Zw6tQpli1bxsqVKzl79iwLFizAwcGh9BMUY+7cuTRo0AAnJye6dOnC7t27Szw2NzeXN998k5CQEJycnGjbti3r1q0r8fhZs2ahKAozZ86sUGzVXccGPnRu6EOuSTB/y7mSD3Rwvb4Q/Jj1dsfao6O/zMGTdKKVOrQb+LDW4diWTg/t1EXI7C/bdCzAkx2exNfJl3Mp56pksc9tl7YRlx6Hp6NnmTZNFEo8BwkR6J30eI98AID4L7+sNruEralxgBsPdgoC1FZj5tL6WVdnzYeCdwPITFQ7wBSjcBq2Z08Ug8GGwWlryy12wxbH56HR6H19yY2KInn16jJfx6g3Mq7lOAAWHl1InvmGcjwb/wsHl6qlwO77BoI6lfm8tlDhoYfQ0FDuu+8+7rzzTurXr1/hAFasWMFTTz3F66+/zv79+2nbti2DBg3iypUrxR7/yiuv8OWXX/LJJ59w/Phxpk6dyrBhwzhQTPuQPXv28OWXX9KmTZsKx1cTPNpXXWv37a4oEtNvMbpS2Dt2VYWbVVc12VkZhJz5BoC41lPR16A30ELt8gunnttU5tZyno6evND5BQDmHZ7H+ZSqVcrixk0TjuVZN1PQGza4Gz4THkFxdCTr0GEydpX8YVW6buaAJrg66Dl0MYU1R6pXPcRy0RvUunYA2z9Vp/3+5XobsXAbBqa9wvV1pUzDFtC5uuI3WS1DFP/Z55hzyj6DMKzxMLwcvbiYdpH1kfkbMHbPhy1qS0numg1N7W/ne7kTuxEjRvDuu+/edP97773HffeVc8oC+PDDD3nkkUcYP348LVq04IsvvsDFxYUFC4r/lL9kyRJeeuklhgwZQqNGjZg2bRpDhgzhgw8+KHJcWloao0ePZv78+bJ4cil6h/rRqq4Hmbkmvtl+oeQDGw8ARw+4dhEu1ow/VAd//Rx/kriML23vmKJ1ONrwaQgNewMCDpZx+z8wqMEgetbtSa45l//s+A9mUTU+DMSlxxVumri3SfGdJkp0On/2oMkgDH5+eI1QPwwlzPvSkiFWW/7ujkzpoy4Pef+Pk2TnVc8WdWXSbjS4+kNK1E0tHXMvXSL79GnQ6XDrVXP6EF+ITycqMQOjXqFbSNk3a3o9+CCGwEDyYmNJXnGLzRD/4mJ0YXRz9YPt10e+RhxdBWvzS131feX6GmQ7U+7EbvPmzQwZMuSm+2+//XY2l7MQYE5ODvv27WPAgOslAXQ6HQMGDGDHjh3FPic7Oxunf1XXdnZ2Zmv+ItICjz76KHfccUeRc5ckOzuba9euFfmqSRRFKdwh+82286Rll1AB3ugEze5Ub1t5d6w9yMvNod5x9Q/y+SYTcHDUfneuZsIKatotK/NoraIovNL1FZwNzuy7vI/VZ1ZbLz4LWhWxCrMw0yGwA408y75pguy0630+Q9VyOL4TJ4DBQPr2HWQeOWKFaKufSb0aEuDuSHRiJkt2RGodjnaMzmoPWVALFt8wnV8wWufcrh16Ly8NgtPG5vxp2A71vXF1LPvsic7REb9pUwF1aYQ5M7PMzx3ZbCQuBhdOJZ1i6++PAQI6ToTez5Qrdlsqd2KXlpZW7Fo6o9FY7oQoPj4ek8lEYGBgkfsDAwOJi4sr9jmDBg3iww8/JCIiArPZzPr161m5ciWxsdeH7ZcvX87+/ft55513yhTHO++8g6enZ+FXUFBQuX6O6mBQy1o08nflWlYey3be4s20YHfssVXq9u5q7OAf31BXXCYJD9rc/ZjW4Wir+V3g6KmOHpzfVOan1XWry6PtHgXgf3v/Z/eV3PPMedc3TZSjxAmgTlWbctS1UfkLqY116+J5p/phKGFeyTscpetcHAw8PbAJAJ9sPENKRtkXvFc7nSaBgxtcPgpnNhTeXXPLnKiJXa8yTsPeyGv4cIz16mGKjydp2bIyP8/T0ZP76qndl77ycFbfC4e8r25ysVPlTuxat27NihUrbrp/+fLltGjRwiJB3cqcOXMIDQ2lWbNmODg4MGPGDMaPH48uf6didHQ0TzzxBMuWLbtpZK8kL774IikpKYVf0dHR1vwR7JJepzAtfwrkq63nycotYQqkUTg4e0P6VYjcWvwx1YDZZMJ3/6cAnGwwGhc37Qska8roDG3yE51ybKIAGN18NM19mpOak8p7u9+zQnCWsy1mG5czLuPl6FW+TRNwwzTs4CJv+r6PTAJFIXX9X2SfOWPBaKuvezsE0TTQnZTMXOZuqsGvmbM3dBin3t42GwBzVhbpu3YBNavMSU6emR1n1d3Sfcq4ceJGioMDfo+qHzIT5n+FKa2M9RKTo3l4/88YhGC/kxMHes1QN5XZsXIndq+++ipvvfUWY8eOZdGiRSxatIgxY8bw3//+l1dffbVc5/Lz80Ov13P5ctEinpcvX6ZWrVrFPsff35/Vq1eTnp5OZGQkJ0+exM3NjUaN1CmTffv2ceXKFdq3b4/BYMBgMPDPP//w8ccfYzAYMBVTpNDR0REPD48iXzXR0HZ1qePpxNXUbH7cd7H4g/TG6/0Mq/F07OG/v6ehOZI04UyLofY75G5TBdOxJ9eUWjj1RgadgTe6v1HYB7hg/Zo9Ktg0MTRkKA76cuzyFwIi8hdXhw4s8pBjSAju+UtCEubPt0ic1Z1ep/DCELXV2DfbLhCdmKFxRBrqOh10BriwBS7uI2PXLkRWFoZatXBs0kTr6Gxmf1QS6TkmfF0daFG7Yn+jPe+6E4eGDTGlpJBYlt72GYmwdASBKZcYmmcE4OsTxe9StiflTuzuuusuVq9ezZkzZ5g+fTpPP/00MTExbNy4kcaNG5frXA4ODnTo0IENG64PMZvNZjZs2EC3bt1u+VwnJyfq1q1LXl4eP/30E0OHqslG//79OXLkCAcPHiz86tixI6NHj+bgwYPo9fadaWvJwaBjcm81Qf5y81nyTCWspSrYHXv8F8irejXKSiPMZpx3zgbgSJ378PS+uTdyjVSnHdRqrU43Hi77AmRQ+wA/3FxNDN/e+TYZufb3hzouPY4tMVsAGNGknEWoYw9BWhwYXaHBzYvZfSdPBiBlzW/kXIypdKw1QXgTf7qH+JJjMvO/P09pHY52POtCa7WHNts+ur4btk8fFDueDrS069Owfuh0Ffu5FYMB/8fVZTWJC7/BlJxc8sG5mfDdgxB/CjzqMu72z1FQ+OfiP5xOsu/WdxUqd3LHHXewbds20tPTOXfuHPfffz/PPPMMbStQJPGpp55i/vz5LFq0iBMnTjBt2jTS09MZP348AGPGjOHFF18sPH7Xrl2sXLmSc+fOsWXLFgYPHozZbOa5554DwN3dnVatWhX5cnV1xdfXl1atWlXkx61RHugUjK+rA9GJmaw5XEK5gfo9wC0QspLh3N82jc8Wju/4naZ5J8kSRkKHPqd1OPYlLH8X2IEl5e5AMr3ddOq41uFS+iXmHiy9D6atrYxYiVmY6VSrEw09b+6HfUun/1C/h/QFw83lUZxbt8K1e3cwmUhc8LUFoq3+bmw19vPBSxy+mKxtQFrKL1gsjq8hbaM6EFKTpmHh+saJstavK4n7oEE4Nm2KOS2NhK9LqLFpyoMfJ0D0LnDyhId+okHdroXLM+y9NmeF69ht3ryZsWPHUqdOHT744AP69evHzp07y32eBx54gP/973+89tprtGvXjoMHD7Ju3brCDRVRUVFFNkZkZWXxyiuv0KJFC4YNG0bdunXZunUrXjVoZ5A1OTvomdBT/aP22aYzxRcJ1emh5TD19tHqV6zYvFmtUXTI/y78atW8jTS31OY+tR/i5aPl7kDiYnThla6vALD0xFKOJRyzRoQVUqlNEwAR+Yndv6Zhb+Q7Rd3hmPzjT+RdvVr+a9RArep6MiysLqAWLa6xhZ4DmkGT28m5pic37gqKoyOuXbtqHZXNxKdlczRG3ZzZM7RyMyiKTof/E48DkLh0KXnx/9rQJQSsfRpOrQWDE4xcAQHqB4yJrScCsO78Oi6mlrBcyQ6UK7GLi4tj1qxZhcWJPTw8yM7OZvXq1cyaNYtOnSpWfXnGjBlERkaSnZ3Nrl276NKlS+FjmzZt4ptvvin87z59+nD8+HGysrKIj49n8eLF1KlT55bn37RpE7Nnz65QbDXRQ13r4+5o4PTlNP46UUIT84Lp2JO/qUPW1UTEgc20zt5PntARdOcLWodjf5y91V1hUGJF/FvpVa8Xtze8HbMw85/t/ylazV1DWy5u4UrGFbwdvekf3L98T067AjH5PXFvkdi5dO6Ec7t2iJwcEhcvrkS0NcvTA5vgYNCx81wiG08WX7i+Rug5k9RL6oZAlw7t0Dk7axyQ7WyNUJOv5rU9CHCvfNkpt759cWrTBpGZSfy/d6v/8y7s+wYUHYz4GupfXxbWwrcF3et0xyRMfHPsm0rHYS1lTuzuuusumjZtyuHDh5k9ezaXLl3ik08+sWZskkY8nY083E3tJjJ309niPyXX6wSewZCTen3ReDWQ+pe6a/OA123UadBU42jsVNhD6vcjP1YoqX+u03N4OHhwIvEEy06UveyANRVummhczk0TkP/vX6iN22/RBFxRlMK1dknffocpJaWi4dYo9bxdGN+jAQDv/H6y5LW/1V1wV9IS1GlIt7rVb23zrVyfhrXMemdFUQpH7ZK/W05uwazgvm9gU36ZtCH/g+Z33vTcia3UUbvVZ1bbbfmmMid2v//+OxMnTuQ///kPd9xxh9yEUM1N6NkQR4OOQ9HJhVvMi1AUaHmPerua7I6NPLGP9unq4vmA25/XOBo71rAPeAVDdoq6gaac/Jz9eKajutN47sG5mk9pxKbFsjVGLd1T7k4TcMM07KBSD3UL74NjkyaY09NJ+rbsXTxquunhjfF2MXLmSho/lLRjv5ozpaSQeUmt6edm3gpZNeODgRCCLfkjdn0qUL+uJK7du+PSsSMiN5f4L76Ek2thzZPqg72fg04Ti31ep1qdaOPXhmxTtt18MP23Mid2W7duJTU1lQ4dOtClSxc+/fRT4v89Ny1VG35ujoUNuUusI1UwHXv6D8hOtVFk1nNlndoq74BrT+o366BxNHZMp4N2+aN2B8pX067APY3voVOtTmTmZfLfXf/VdO3UTxE/IRB0qdWF+h7l7HudlwNn8zcQNSk9sVN0usJRu8TFSzBn2N/uYHvk6WzksX5q0ecP158mvaTuONVY2tatYDbj4KPDwZgCexdqHZJNnIhN5WpqNs5GPR0aWK49qKIo+M9UN6Uk//gjOQsngjCrZZ36vnTL501oPQGA5SeXk5pjf3/7ypzYde3alfnz5xMbG8uUKVNYvnw5derUKez+kJpqfz+cVDmP9G6EQaew7UwCB6OTbz6gdlvwCYG8TDi1zubxWdKlC6cIS1anlF37y52wpWo3ClDU2lqJ58r9dEVReK3razjoHNgWs43fz/9u+RjLIM+cx6oItQ9nhUbronZA9jVw8YM67cv0FI/BgzAGBWFKSiL5xx/Lf80a6qGu9anv68LV1Gzmbyn/v7mqrrDMSY/8Neg7P4e8bA0jso2CadhuIb44Giw7U+jSsSOuncPAZCL+kINaXPzO2aV2legb1JdGno1Iy03j+1PlK/1kC+XeFevq6sqECRPYunUrR44c4emnn2bWrFkEBARw9913WyNGSSP1vF0Y2k7dkfbZ38WM2inK9VG7Kj4dG71mFgbFzFHHMJq0r1llBCrEKwhC+qm3K7CJAqCBZwMmt1FHr97d8y4p2bafWtp8cTNXMq/g4+RT/k0TABF/qt9DB6ojmWWgGAz4TpoEQMKChYicmrVeqqIcDDqeG6QWLZ63+RxXUrM0jsh2hMlE+mZ1mYj7iEfAo65aN/HQco0js76C+nW9K7kbtljXLuFf9yAAKZEuZLd/DfSl96DVKTomtFJH7ZYcX0JWnn39W6xwuROApk2b8t5773Hx4kW+++47S8Uk2ZFp4Y1QFPjz+GVOXy5mVLYgsTvzF2Qm2TY4C4mPi6bt1V/V/+j9tLbBVCXt8ztRHPy2wn2DJ7SaQIhnCIlZiXyw9wMLBlc2N26aMOqN5T9BQf26JiXvhi2O57B7MPj7kxcXR8qvv5b/ujXUkNa1aBfkRUaOiY/WR2gdjs1kHj6MKTkZnYcHzh07qd0oALZ/DOYS2j9WAxk5eey9oP5d6VXJ+nU3yUyGpSNwdozBraEeBFz94qsyP31IoyHUcq1FQlYCv5wt/1pja6pUYldAr9dzzz338Msv9vXDSZXXOMCdwS3V9m6fbzp78wEBzSCgJZhz1dInVVDEL+/hpORyytCMlt3u0DqcqqPpEHD2gdRYOLuxQqcw6o280f0NAFadWcXu2N0WDPDWYtJi2BazDYB7QyswDZtwFhIi1HZPBaOXZaRzcMBngvqJP2HefEQxrQ6lmymKwst3qDXFVuyJIqK4D5vVUNqm/GnYnj1QDAboMFYtnJtwpsq+75bFrnOJ5JjM1PVyppGfq+VOnJsFy0fDlePgVgv/t+aq/ZzXrSPrxIkyncKoMzKu5ThALVhsL6WbwEKJnVS9TQ9XW8X9cuhS8T0bWw1Xv1fB6diUpHhax6ijNpldZ6KUcTpNQu2w0OYB9faBitdlaxfQjgeaqud5c+ebZJtss27op9P5myZqdyHYI7j8JyiYhg3upv6RLSfv++9D7+lJTmQkqX/+Wf7r11CdGvgwsEUgZgGzfj+pdTg2cWMbMQAc3aHTI+rtbbPL3QWmqvjn9PVuExZrn2Y2warJELkVHD3goR9x6tgHjyFDALj6cdnLuA0PHY63ozcxaTH8ecF+foflXzGpVK3redIr1A+TWfDl5mJG7QoSu3P/QFrVqqh//Of/4aZkcl5XnzZ979c6nKqnYDr21O+V+n//RPsn8Hf2J/JaJPMOzyv9CZWUa85l9ZnVQAU7TcAN07Cl74Ytjs7VFe+H1dcvft78mttVoQKev70Zep3ChpNXii/HVI3kxsWRffIkKAquvXpdf6DLVLUzQsw+uLBVuwCtqGDjRB8L1a9DCPj9eTj+M+gd4MFlav9rwG/Go6DTkfb332QePFim0zkbnBnVfBQAXx/92m5+h2ViJ5XJo33VUbvv9168edGyTyOoEwbCBCd+1iC6islMT6XZBbUOUULYo+hkbcbyC2yp7gY158Hhii/kdndw56UuaomBBUcWEJFk3fVTm6M3czXzKj5OPvQLKt80KqCW9yn4Y9pkcIXj8HloNIqLC9knTpC+ZUuFz1PThPi7MaqzOsr6f2tPFN/6sJpI+2czAM5t2mDw8bn+gJs/tBut3t422/aBWdnFpAzOXU1Hr1Po3thCid3WD2HPfECBYV9Cw96FDzk2bIjnPfcAcPXjj8t8ypHNRuJicCEiKYLjicctE2clycROKpMuDX1oH+xFTp6Zr7eev/mAwt2xVad37KFfPsaba8QogbQbPF7rcKquglG7/UsqNSXUP7g/fYP6kify+M+O/2AW1uswULBp4p7G91Rs08S5Teq6Uu+G4Nu4wnHovbzwfkCdho7/0vojldXJEwNCcXM0cCQmhV8PX9I6HKspnIYNL2a3fvfH1NZXZ/6CuCM2jsy6Np9W6+SGBXnh4VSB39F/O7AMNryp3r793eszTTfwmz4djEbSt+8gfVfZ1vt6OnryVo+3+OWeX2jp27LycVqATOykMlEUpXDUbumOSFIycose0HKY+j1yO6TE2Di68svJzqLhqa8BuNhiMgZjOdtISde1GgEGZ4g/BRf3VPg0iqLwUpeXcDG4cOjqIX449YMFg7zuYupFtl/aDlRw0wQUnYat5Nofn3HjUIxGMvftI2Pv3kqdqybxc3Nkap9GALz/xymy86rfBhRzdjbpO3YA4BYefvMBPg2hxT3q7W1lH2WqCgrKnPSyRLeJ03/CL4+pt3vMhC5Tij3MoV5dvO9T3xOuzplT5qnVgQ0G0sCzQeXjtBCZ2Ell1q9ZAM1quZOeY2LRjgtFH/Sspy4iR8Dx1RpEVz4H184jkASu4k3bO6dpHU7V5uR5vb3c/so1t6/lWosn2qvV4Gfvn83l9MuVDO5mKyNWIhB0q92NII+g8p/AbL6+caKC6+tuZAwMwHO4OnpwU0Ny6ZYm9mxELQ8nLiZlsnh7pNbhWFzG7j2IzEwMgYE4NmtW/EE91N8Xjv4ESdXjNcgzmdl2Vh2xq3R/2Iv74Iex6lKhtiNhwBu3PNx3ylQUR0cy9+8nfWvVXLsoEzupzBRFYXr+qN3CbefJyPnX9u4qUqzYlJdH7cOfA3C28TicnC24jb6mCsufjj22CrLTKnWqB5o+QBu/NqTlpjFr9ywLBHddrjmXVWcq0WkCIO4QpF0GoyvU72GRuHwnTgCdjvTNW8g6bh/rdKoCZwc9Tw1sAsAnGyNIzqhexZ4Lp2F79y55V2iddtAoXE1cdsy1WWzWdOhiMqlZeXi5GGlTz6viJ4o/A9/eB7kZENIf7v6k1BF2Y2AA3qPUDRFXZ5d91M6eyMROKpchrWpR39eFpIxcvtsdXfTBFkPV9R4x+yDpgibxlcXBP5cQJC6Rgiut7n5C63Cqh/rd1U00OWmVHrHV6/S81u01DIqBv6L+YkPUBsvECGyK3kR8Zjy+Tr70De5bsZOczh+tC+mrlnyxAIfg4MJyC/Hz5lvknDXFiPb1aFbLnWtZeXy6sYS+1lWQEIK0TZuAEtbX3ajHTPX7/sWQXvV3Cf+Tv76uR2M/9LoKLnVIvQxLh0FGgrq57/7FUMb1tL6PTEJxcSHr2DFS//qrYtfXkEzspHIx6HVM7RMCwPzN54qua3ELuL7LyE43UQizGc99ap2i40GjcPOwXFPpGk1RIOwh9fb+JZU+XVOfpoxrNQ6A/9v1f6TlVG4UsMCPp9XerMNCh2HUVXBBdkTlypyUxPcRtS5Z6h9/kH2+mA1KUrH0OoUXh6hFixfviCy+1mYVlHPuHLkXL6IYjbh27XrrgxuFq7278zJhd9Wfzi9YX9enouvrsq7BshGQHKV+4Bz1Azi6lfnpBh8ffMbklyL6+OMqV0BcJnZSuQ1vX5dAD0firmWx+sC/NkrY+e7YI/+spLHpLBnCkeZDn9E6nOql7Sh1xDZ6J1w9XenTTWkzhSD3IK5kXOHjA5VfGB6dGl24aWJE6IiKnSTtijoiDWp/WAtyatoEt759QQgSvip7ayNJ7SPas7EfOSYz7/1xSutwLKKg24RL587oXEtZLqIo10ftdn8JOenWDc6KkjNyOHwxGYBeFVlfl5cNKx5Sdwm7+sNDK9XSMOXkO2ECOg8PsiPOcG3t7+WPQ0MysZPKzdGg55Fe6m60zzedxXRjDalmd4LOCJePwFX7e4M1bP8IgMO1huPlV0vjaKoZj9rXk50DlR+1czI48Vq31wBYfnI5h64eqtT5fjqtrv3sXqc79dzrVewkEevV77Xbgrvl//34TZkMQMrPv5AbG2vx81dXiqLw4pBmKAr8eugSh6KTtQ6p0m7qNlGaFkPV8juZSRYZNdfK1jPxmAWEBrhR29O5fE82m2H1NDj/Dzi4wegf1Z3DFaD38MB3gloG6+qnnyDy7KdlWGlkYidVyMjOwXi5GLmQkMHaIzf8AXLxud43085G7U7s+oMWuUfJEQYa3f281uFUTwWbKA59B6bcWx9bBl1rd+XukLsRCN7Y/ga55oqdM9d0fdNEhTtNwA3TsBUvSnwrzu3a4dKlC+TlkbBwoVWuUV21rOPJsLC6ALy99kSVXPRewJSaSsb+/UAZ1tcV0OnVunYAOz61yO+fFracLtgNW4Fp2D9fUTfv6QzwwBJ1Y0kleD/0MHpvb3Ijo0j5ueoU35eJnVQhro4GxndXPwl9tuls0TfRG3fH2tGba86m/wFwwHcIAXUr9ilOKkWTQeAaAOlXr9d6q6RnOj6Dt6M3Z5LPsOjYogqd4+/ov0nMSsTP2Y8+QWX8Q/lveTlwZqN6O9Sy6+tu5DtZXWuX/P0P5CUmWu061dEzA5viaNCx+3wiG05c0TqcCkvftg3y8nBo1AiH4HL0MW43Sp1+TIm2uw/WZSGEKGwjVu7EbvsnsDN/V/A9n18fYKgEvZsrvpPVUfSrc+dizqkau65lYidV2Nju9XF10HMi9hqbTt3QJ7Tp7WoPw4QIu6mGfvbwdtpm7sYkFOrd+YLW4VRfeiO0fVC9bYHpWABvJ2+e7fQsAJ8f/JzIa+Wv1VXQaWJY40psmojaATmp6h/OOmEVO0cZuHbvjlOrVoisLBIXV64uYE1Tx8uZCT3VD23v/H6CPJP1updYU8H6ujJPwxYwOqs9ZAG2zbGrD9ZlceZKGrEpWTgadHRp6FP6Ewoc/l4drQMY+F9oY7m+394jH8Tg70/epViSf7BO0XRLk4mdVGFeLg6M7lofgLl/31BmwMnj+lorO6lpl/znuwAc8OhH3Ub20fal2iqYjo34E65ZZp3YnY3upFvtbuSYc3hrx1vlmmaLuhbFztidKCiMaFLBTRNwvShx6EDQWe+tU1EUfPPX2iUt+xZTmmV2BNcU08JD8HF14OzVdFbsjS79CXZGmM2kbVb7w5Y7sQPoNFFdX3blmNpqrAr5J383bOeGPjgZy9i7+8wGdV0dQLcZ16ejLUTn5ITvNDVZjv/iC8yZmRY9vzXIxE6qlEk9G+Kg17E3Mond52+YNiqYjj22UvNPjdERhwhLVT8B+wySa+uszr8JBHUBYVbX2lmAoii82u1VnPRO7IrbxS9nfynzc3+KyN80Ubc7dd3qVjyI0+vU7xbeDVsc9/79cQgJwZyaStJ3lnkNawoPJyOP91MLqX+0PoK07Kqz6B0g68gRTImJ6NzccOnQvvwncPaGDuPU21tnWzI0q9scoa6v61PWadhLB+D7MWDOg1b3wm1vWSUu73vvxVinDqar8SR9a/+/jzKxkyolwMOJezuqOwyLjNqFDlQ/NSZHXS8PoZHYte+iUwSHnLvSqFUXTWOpMQpG7Q4stVhiH+QexLR26ifz9/e+T2JW6evPck25rD6zGqjkpomEs5BwRl2UHVLBwsbloOh0+D4yCYDEbxZhzsqy+jWrk1Fd6tPA14X4tGzmbT6ndTjlUrAb1rVHDxRjBZcNdJ2uVieI3AoXq0b/4axcE7vOqcWVy9QfNvEcLLtPLYresI+6rs5KI+mKgwN+jz4KQML8+ZjS7LucjEzspEqb2jsEnaIOox+NSVHvdHCBpmolfS2nYy9fPEu7RHWkxbHfs5rFUeO0HKYm9olnIXK7xU77cIuHaerdlJTsFN7f836px2+I3kBiViL+zv70rte74hcumIat313tjWsDnnfcoY4SJCSQvLLqLYTXkoNBx/OD1d6q8zef4/K1qpMYV3h93Y08615fZ7b1IwtEZX17LiSSnWemlocTTQJLKSacdhWWDFc3adVqDQ8sBYODVePzHHo3Dg0aYEpOJmmJfa99lYmdVGnBvi7c3bYOAJ9tumHU7sZixWZtKnef/+VdHBQTxxza0KzTAE1iqJEc3dTkDiy2iQLAqDPyRvc3UFBYc24N22NunTRapNME3DANa73dsP+mGI34TJoIQOJXXyNyq2b5Cq0MblWL9sFeZOaa+Gh95Qtm20LulSuFvYLdeveq3Ml65LdLPPkbxEdUMjLrK+g20SvUr+S+uKD2ov72Pkg6D171YfRP6rpuK1MMBvwemwFAwoKFmFJSrH7NipKJnWQR08LVNS2/H43j7NX8xd4h/dTRjbQ4dUehjSVeiaHN5dUAmHs+afPr13jtx6jfj62GLMu9Cbbya8Xo5qMBeHPnm2TmFb+YOepaFLtid6mbJiraaQIgOxUubFNvW7iNWGm8hg9H7+tL7qVLpPz2m02vXdUpisLLd6itxr7fG83py6kaR1S69PxNE05t2mDwq0DXhRv5N82fNRHqDlk7t7ks9etMueqauksHwMVX7SrhHmijCMHj9ttxDA3FnJpKwgL7rTMpEzvJIprWcmdA80CEgC82nVXvNDhA87vU2xpMx5765X+4KNlE6BvTquc9Nr9+jVevE/g1VftXWvj//4ywGdRyrUVMWgyfH/q82GMKRut61O1BHbc6Fb/YuU1gzlV7Tvo2rvh5KkDn5ITPuLEAJMz/CmGumuU7tNKhvg+DW9bCLOCdtSe0DqdU17tNVGLZwI0K2owdXmGxHerWEJeSxanLqSgK9GxcQkIrBPw8A85uAKOL2v/Vz7a/j4pOh/8TjwOQuGQJeQkJNr1+WcnETrKY6X1DAFh1IIaY5PxRlILp2OM/27QSempKIi0vrgAgrfPjKFYsTyGVQFGgff4mCgu3OHI1uvJyl5cBWHxsMScTTxZ5PMeUY5lNE1B0GvZWU0RW4j1yJDp3d3LOniV1wwabX7+qe/72Zhh0Cn+fusr2M/Fah1Mic04OadvUpQVufcItc9LgLhDcDUw5sPMzy5zTCgqKErep54W3awlr5f56Aw4vB0UP9y+Geh1sF+AN3Pr3V+tMZmSQMG++JjGURv61kyymfbA33Rr5kmcWzC/YidagN7j4QUaC2r/PRo79/BEepBOpq0fbAQ/Z7LrSv7R5UN1Jemk/XD5m0VOHB4UzsP5ATMLEG9vfwHTDOs6NURtJyk4iwCWgcpsmzObr/WGbWL/MSXH0bm54jx4FQMKX86p0qywtNPRzZXQXtXvD//1+ArPZPl+/jD17EBkZ6P39cGrR3HInLlhrt3ehRZdEWFLB+rreoSWM1u38HLbNVm/f/QmE3mabwIqhKAr+T6ivadJ335F7+bJmsZREJnaSRT3aVx0aX74nivi0bNAboOU96oM2anGTlZFG43PqrqUrbaah05ex0KVkeW7+1/uqHlhq8dO/0PkF3I3uHEs4xncnr9eXKug0MTx0OAadoeIXiDsEaZfVHb71e1Q23ArzGTMGxcmJrKNHydhh+/WqVd3j/UNxdzRwNOYavxy6pHU4xSqchu3d27IzDKGDwL+Z2jVl7wLLnddCTGbB1jO3WF939CdY96J6u/9rEDbahtEVz7VnD5w7dEDk5BD/xRdah3MTmdhJFtWjsS9t63mSlWtm4bbz6p0F07En1kBettVjOLTmM/xIJg5/2g15xOrXk0pRsIni0HKL///3d/HnyY7qxpiPD3xMbFosF1IusDtuNzpFx/DGwyt3gYJ+t43CweBYuXNVgsHHB6/71Snl+C/naRZHVeXr5sjUcHWpyPt/nCIrV5td+rdyfX1dJcqcFEenuz5qt/NzyLWv0i9HY1JIzsjF3dFAuyCvog+e3wyrpgICOk+Gnk9pEeJNFEUhYKb6mib/8CM5Fy9qHFFRMrGTLEpRlMIdsot3RHItKxeCuoJ7HchOUdu/WFFuTjZBJ9R1D5HNJ2F00O6PsZQvpD+414bMRDi11uKnHxE6gvYB7cnMy+S/u/5buGmiZ92e1HarXbmTFyR2Nt4NWxzf8ePBaCRj1y4yDx7UOpwqZ2LPhtT2dCImOZNF2y9oHU4R2efPkxsZBUYjrt2tMDLc6l7wqKuOPh9ebvnzV0LBNGz3xr4Y9TekJHFHYPlodX1gi6EweJYma1xL4tKpE67du0NeHvFz7Wv9okzsJIsb2CKQxgFupGblsXRnpPqJsVX+yImVd8ce/P1r6ogrJOBJ27tmWPVaUhnpDdBOXSNm6U0UADpFx+vdXsegM7D54ma+PfktYIFNE2lX1LWBYJM2YqUx1q6N593qLvN4O120bc+cjHqeHtgUgE//PkNSeo7GEV1X2G2iU0f0bq6Wv4DBAbqpnRPY9rFmdUWLU7Bxosg0bFIkLL0Xsq9B/Z4wbB7o7G9JjX/+qF3Kzz+Tfe68xtFcJxM7yeJ0OoXp+dMeC7aeV6c9WuYndqfWQo512rGYTSb8D6mfnE43fBgnl1Kql0u2E5a/geXsRki2fGP2Rl6NeKS1Ou2ea84l0CWQnnV7Vu6kBd0marcD91qVO5eF+E6aBIpC2saNZJ2qGkV37cmwsLo0r+1BalYen2w8U/oTbMRq07A3aj8WnLzUbjAn11jvOuVwLSuX/VHJAPQuaCOWngBLR6j1TwNawoPLwOikXZC34NymDW79+oHZTPynn2gdTiGZ2ElWcVfbOtTzdiY+LYfv90ZD3fZqlfDcjOvTWxZ2aMN3NDBHcw0XWg61j7UYUj6fRtCgFyDg4LdWucSk1pNo4NEAsMCmCbCradgCjg0b4j5IjSdhvhy1Ky+9TuGlIWqrsSU7LxCZoH3PT1NaGhl71H6uVk3sHN2gc/6a462zLdbDuTK2n0nAZBY09HMlyMdF/dD/7f2QEAGeQfDQj+DspXWYt+T/+GMAXFv7O1mnTmkcjUomdpJVGPU6pvRuBMCX/5wj1yxuaDFm+elYYTbjulutrn6s7v14ePla/BpSJYXl17Q7uFQtI2JhDnoHPhvwGU92eJIJrSZU7mR5OXD2b/W2HSV2AH6T1T/O19auJScqSuNoqp5eof70CvUj1yR47w/t/xCnb9sOeXk41K+PQ4MG1r1Y5ylgcFKXGFzYYt1rlcGWiBvKnJjy4IfxELNXHVl86CfwqERhcRtxatYM74ceIvDll3Fo2FDrcACZ2ElWdF/HIPzcHIlJzuTng5euJ3YR6y1eT+no1l9pkneaTOFAk7uftei5JQtpfhc4ekByFFzYbJVLBLkHMaHVBJwMlZy6idqulodwDYDaYZYJzkKcWrTAtXcvMJtJ+Nr+yldUBS8NaY6iwG+HYzkQlaRpLIXTsOFWHK0r4OYP7fLLhWydbf3r3YIQ4vr6ulA/WPMERPyhJp6jvldbolURtV55GZ+HH0LnUEJxZRuTiZ1kNU5GPZN6qZ9gPt90BrN/C7XFlCkbTlp2d6Sy7UMADgUMxTewnkXPLVmIgwu0vle9bYVNFBZ1On99Xeht6uYfO+M3eTIAKStXknv5isbRVD3Na3swor36PvHO2pOaFX0WZjNp+f1hrToNe6Puj4GiU1tzxR2xzTWLcSEhg+jETIx6hV4x89U6l4oO7l2odsyQKsz+3rGkamV0l2A8nAycvZrOnycuW2U69uTeDbTKPkiu0NPgructdl7JCgqmY0/8CpnajpTcUoT9ra+7kUvHjmqB1NxcEr/5RutwqqSnBzbByahj94VE1h/XpntA1rHjmOLj0bm44NKxo20u6tMQWtyj3t42xzbXLEZBmZMX/LbhsO1/6p13fgTNhmgWU3UhEzvJqtydjIzt3gCAuX+fRbQcpj5w7m/ISLTINTI3qm8KB7wHUSs41CLnlKykThgEtlJHbQ//oHU0xUs4CwlnQGeERn21jqZEflPUUbukFSswJSdrG0wVVNvTmYk91RmFWetOkmuy/LrP0hSWOenRA8WW03g9Z6rfj65US4toYPPpqwzS7WZCylz1jvAXocM4TWKpbmRiJ1nd+B4NcTbqORKTwtZkb6jVBsx5cOKXSp/7/PE9hGVsxywUag2Ro3V2T1Guj9odWKxtLCUp2A1bvxs4eWgbyy249uqFY/PmiIwMEpcu0zqcKmlqnxB8XR04dzWd5XssX4anNDZdX3ej2m3VDy3CBDs+te21gZw8MznntvKxcS4KQk3o+sj3b0uRiZ1kdT6uDjzYOQiAuX+fseh0bMK6WQAcdO9FcJN2lT6fZANt7ge9g7q+59JBraO5WeE07GBt4yiFoiiFO2QTlyzBnK596Y6qxt3JyBMD1FH+OX+dJi07z2bXzrt6lawj6ho3t969bXbdQgWjdvuXQHq8TS99/OBOPlXew1HJRTQdAkM+sKuuElWdTOwkm3ikVyOMeoWd5xI54tVPvfP8FkiNq/A5Y86dICxFbVHmcZv8tFdluPhAszvV2wfsbBNFdipc2KbeDrXP9XU3ch84EIf69TGnpJD0vZ1Obdu5kZ2DaeTnSnxaDl/+c9Zm103brJYbcWrZEoO/fylHW0HDPmrx7bxM2G3D/sMpFwn5cwyeSgbnnVuh3LtA7U4jWYxM7CSbqOPlzPAwdRfanH3ZUK8TIOD4zxU+58XfZqFXBIedOtG4bSW7DEi21T5/OvbID5CbqW0sNzr7N5hz1YLKfo21jqZUil6Pb8Go3YIFmHPsp01WVWHU63husFq0eP6Wc5yMu2aT69qk28StKMr1Ubvd86zWEaiIzCRYOgL3nKtEmOtyLPxLMDpb/7o1jEzsJJuZ0qcRigJ/nbhCXPAd6p0VnI6NvxRJWLzaFsfQ52lLhSjZSsNwtbJ8VgqcsI/2RkCVmYa9keddd2GoVYu8q1dJWbVa63CqpEEtA+nWyJesXDMj5+3k+CXrJnciJ4f0berIsM3X192o+d3g3VBNuPZbec1rbiZ8NxKuniRW+DA253m6tJCb3axBJnaSzTTyd2NI69oAfHq5FaBA9C61YG05nfnlXRyUPE4YW9C8i/1PmUn/otNdL5RqL5sozOYb6tcN1DaWclAcHPCdMB6AhK+/RuTZbp1YdaEoCl883IG29TxJyshl1Fc7ORpj2SLqN8rYvx9zejp6X1+cWrWy2nVKpdOrde0AdswFU651rmM2wU+TIGoHOQZ3xuY8j1ftRvi7O1rnejWcTOwkm5oeHgLAt8dzyKrbTb3z2KpynSMl4TKtY9WRvpxuT6LYYQFZqQzCRgMKnN8Miee1jgZiD0L6FXBwg/o9tI6mXLzuvRe9tze5UVFcW2edXszVnaezkSWTutAuyIvkjFxGf7WLIxetk9ylbcqfhu3dW/v3r3ajwNUfUqLV8ieWJgT89jScXAN6R+bV+S+nRRC9m2iwrrCGkH8RJZtqWceT8Kb+mAX8Tnf1znK+mRz/+QNclSzO6hvSJvxeK0Qp2YRXMDQKV28ftINyHRH5o3UhfcFgH62Bykrn4oLPGHXdYsK8eZp1UqjqPJyMLJnYmfbBXqRk5jL6q50cik62+HU0X193I6MzdJmq3t42R03ELGnz+7BvIaBgHj6Pby6pa617N/Gz7HWkQjKxk2zu0b7qovRZF5ogFL06UpJQtt1o6anJNI9Sk4Dk9jO0/7QrVU7BJoqD36rTNVo6vU79XgV2wxbHe9QodK6uZJ8+TdqmTVqHU2W5OxlZPLELHet7cy0rj4e+3mXRfrI5kZHknD8PBgOuPbpb7LyV0mmiOlJ95Zjay9tS9i2Cv99Wbw95nxPefYlPy8bFQU/H+j6Wu45UhPyrKNlcpwY+dG7gw2WTG2fdO6l3lnHU7sgvH+NFGheV2rQbNM56QUq20exOcPaGazFwdqN2caRehksH1NtVaH3djfSenniPGglAwhdfylG7SnBzNPDNhM50buBDalYeD3+9m32RlknuCkbrXDp0QO/ubpFzVpqz9/WuD9tmW+acp36HNTPV272egc6PsPm0Wi+vWyNfHAwy/bAW+cpKmpjWV11rtyA5TL2jDLtjs7MyaBSxEIDYVlPQG2TtoyrP4AhtHlBvW3tX3q2cyR+lqBMG7oHaxVFJPmPGoDg4kHnoEBm792gdTpWmJned6NrIh7TsPMZ8vYu9FyrfBrFwfZ09TMPeqNujahu9yG0QXcl/O9G74YfxIMwQ9hD0ewW43h9Wrq+zLrtI7ObOnUuDBg1wcnKiS5cu7N69u8Rjc3NzefPNNwkJCcHJyYm2bduybt26Isd8/vnntGnTBg8PDzw8POjWrRu///67tX8MqRzCm/jTorYHa3Lak6cY4eoJuHz8ls85tOYLAkjkCj60vWOqjSKVrC7sIfX7qd9tXgG/UBWfhi1g8PfH6161s0vCPBsWna2mXBwMLBzXme4hvqTnmBizYDe7z1c8uTOnp5OxR02aNC1zUhyPOtc/ZFVm1O7qafj2frXwcehAuHM2KArp2XnsjVRfu16hcn2dNWme2K1YsYKnnnqK119/nf3799O2bVsGDRrElStXij3+lVde4csvv+STTz7h+PHjTJ06lWHDhnHgwIHCY+rVq8esWbPYt28fe/fupV+/fgwdOpRjx47Z6seSSqEoCo/2bcw1XNks2ql33mLULi83hzrHvgTgXJMJODjJopbVRq3WagV8cy4cXmH76+flwNlN6u0mVXMa9kY+EyaCXk/6tm1kHjmqdThVnrODnq/HdqJnYz8yckyMW7ibnecSKnSu9B07ELm5GIOCcGjY0MKRWkCPx9XvJ39TE7TyuhYLS4erdfHqdoD7vgG9EYCd5xLINQnqeTvT0M/VcjFLN9E8sfvwww955JFHGD9+PC1atOCLL77AxcWFBQsWFHv8kiVLeOmllxgyZAiNGjVi2rRpDBkyhA8++KDwmLvuuoshQ4YQGhpKkyZNePvtt3Fzc2Pnzp22+rGkMhjcqhaN/FxZldNFvePoTyXuyDr45yLqiTiScKfN3Y/bMErJJgo2UexfYvldeaWJ2g45qeAaALXDbHttK3CoVxfPO9UC4HLUzjKcHfR8NbYjvULV5G78wj1sP1v+0eXC3bDh4Sj22BvVvyk0HQII2D6nfM/NTIalI9SyKb6NYdQP4HA9gdsSob5evZv42+fPXo1omtjl5OSwb98+BgwYUHifTqdjwIAB7Nixo9jnZGdn4+TkVOQ+Z2dntm7dWuzxJpOJ5cuXk56eTrdu3SwXvFRpep3C1D4h/GVuTyaOkHT++gL2GwizGZ99nwJwsv5oXNw8bR2qZG2t7gWDkzolH7PPttc+nV/3LXSgWji5GvB9RG0zlvrXX2SftV3/0+rMyahn/piOhDf1JzPXxIRv9rDtTNmTOyEEaf9sBuxwfd2NesxUvx9aAdcule05uVmwfLS6q9YtEB76CVx9ixxSuL4uVK6vszZN38Xi4+MxmUwEBhZdrBwYGEhcXPHN4QcNGsSHH35IREQEZrOZ9evXs3LlSmJjY4scd+TIEdzc3HB0dGTq1KmsWrWKFi1aFHvO7Oxsrl27VuRLso17wuri5enFX6b8kZJjN++OPfT39zQyXyBdONFi6DM2jlCyCWcvaDFUvW3rTRQFiV01mIYt4Ni4Me63DQAhSJj/ldbhVBtORj1fPtyBfs0CyMo1M+GbPYUJS2myT5wg78oVFBcXXDp3snKklRDcBYK7qUsjdn5e+vFmM6yaApFbwcEdRv8I3g2KHBKdmMG5+HT0OoXujX2LP49kMVXu4+mcOXMIDQ2lWbNmODg4MGPGDMaPH4/uX5+0mzZtysGDB9m1axfTpk1j7NixHD9e/OL8d955B09Pz8KvoKAgW/woEuBg0DG5dyN+NamjqeLoSvWNIp8wm3HaMRuAw3XuxdNHftqrtsLyp2OPrrRNQ3KA+DOQeFbdDdior22uaSO+kycDkLJmDbkxMRpHU304GvR8/lB7BjQPIDvPzKTFe9l0qvg14TdKza8t6NqtGzoHOy+AXTBqt3ehOsVaEiFg3QtwfLX6O/TgMqjd5qbDNkeoyW/7YC88nIwWD1cqStPEzs/PD71ez+XLl4vcf/nyZWrVqlXsc/z9/Vm9ejXp6elERkZy8uRJ3NzcaNSoUZHjHBwcaNy4MR06dOCdd96hbdu2zJlT/JqBF198kZSUlMKv6Ohoy/yAUpk82CmYw06duCacUa7FwMXru6KP71xHs7wTZAsjoUOf1zBKyeoa9FQbkuekwrHVtrlmRP5oXf3u4ORhm2vaiHPr1rh27wZ5eSQsWKh1ONWKo0HPZ6M7MLBFIDl5ZiYv3sffJ2+d3F3vNtHbFiFWTuhA8G+u/i7uLX69O6Dunt2tbmpj2BfQqPgp5oJRzV5yGtYmNE3sHBwc6NChAxs2bCi8z2w2s2HDhlLXwzk5OVG3bl3y8vL46aefGDp06C2PN5vNZGdnF/uYo6NjYWmUgi/Jdpwd9DzUswnrzR0BEEd+LHzMtPl/ABz0uwO/WsGaxCfZiKJcL31yYIltrlk4DVu1y5yUxHfyFACSf/yRvHiNSslUUw4GHXNHt2dwy1rkmMxMWbKPDScuF3tsXmIiWYePAHa+vq6ATgc9nlBv7/xcXUP3bwe/hb/eUG8PegdaF9/eMddkZvsZdRexrF9nG5pPxT711FPMnz+fRYsWceLECaZNm0Z6ejrjx48HYMyYMbz44ouFx+/atYuVK1dy7tw5tmzZwuDBgzGbzTz33HOFx7z44ots3ryZCxcucOTIEV588UU2bdrE6NGjbf7zSWXzcLcGrNf1BCDn8Eow5RFxcAttsvaRJ3QE3fliKWeQqoV2o0DRQdQOdZrUmrKuQeR29XaTwda9lkZcunTGuW1bRHY2iYs0LABdTRn1Oj4ZFcYdrWuTYzIzdek+/jx28/rwtM2bQQgcmzfHGFhFCmC3vhc86kH6FTj0XdHHItbDzzPU290fh27TSzzNoehkUrPz8HIx0rqu3PhmC5ondg888AD/+9//eO2112jXrh0HDx5k3bp1hRsqoqKiimyMyMrK4pVXXqFFixYMGzaMunXrsnXrVry8vAqPuXLlCmPGjKFp06b079+fPXv28Mcff3DbbbfZ+seTysjT2UijzneSJNxwzE5AXNhK6vr3ADjo2Z86DZtpHKFkEx51oHH+Lnlrj9qd+1tdIO4TAr4h1r2WRhRFwXeKutYu6dtvMcmNYRZn1OuY82A77mxTm1yTYPqy/aw7WjS5u17mpAqM1hXQG9VuFADbP77ey/niPvh+DAiTWtB4wH9ueZqCadiejf3Q62SZE1tQhGwoeJNr167h6elJSkpKidOyQgjy8vIwmTRuXF6FGI1G9Hp9iY9fTc1mw/sjeVC3gTifTgQk7EWnCC48sIEGzTvaMFJJU8d/ge8fVssmPHkc9FZqHbf6UTi4FLpOh8HvWOcadkCYzZwfeg/ZERH4z5yJ39QpWodULeWZzDz9wyF+PngJg07hk5Fh3N66NiI3l9Pde2BOTaXB8u9wbtdO61DLLjsNPmoJWclw3yK1mPjXt0FGAoT0g5ErwHDrjSBD527jUHQy793bhvs7yo2JFVWWvKSAbLZZATk5OcTGxpKRkaF1KFWKoijUq1cPNze3Yh/3d3cks8lQOLOBWol7QIEDLj0Ik0ldzdJkMLj4QdpliPgTmg2x/DXMZvXcUG3X1xVQdDp8J0/m0rPPkrhoET5jx6Bzlp1bLM2g1/Hh/e3QKQqrDsQw47sDzBGCvlkXMaemovf2xql1a63DLB9HN+j8CGx+X/3KTlWTutrt4P7FpSZ1Sek5HL6YDMj6dbYkE7tyMpvNnD9/Hr1eT506dXBwcJBVtMtACMHVq1e5ePEioaGhJY7cDRg8nCufvEaAkgyA64Dnij1OqsYMDtD2QdjxqToda43ELvaAunbIwR2Cu1v+/HbG4/bBXP34Y3Kjo0n+4Ud8xjysdUjVkl6n8L/72qJTFH7af5Enlh9kSe4uvAG33r1QbjFjYbc6T4Htn8Dl/PZ03g1g9A/g6F7qU7eeiUcIaBLoRi1Pp1KPlyxDJnbllJOTg9lsJigoCBcXF63DqVL8/f25cOECubm5JSZ2QX7ubPbtT0DiTxx1bEer9uG2DVKyD+3HqInd6T8gNQ7ciy9/VGGn80frQsJLHXWoDhSDAd+JE4l74w2uzp6Nc9s2OLdtq3VY1ZJep/D+vW3Q6+D7vRdJ3bRJTeyqwm7Y4rj5q7vV93yljqQ/tBLcAsr0VNltQhuab56oqv5dEFkqXVlHNtuMnsWOehPxHS0r5tdY/k2hXmd1gfa/d+RZQkH9utDqPQ17I68Rw3Hp1hVzRgZRj0wm6+RJrUOqtnQ6hVnD2/BIY0eCU69gUnRscGtU+hPtVb9XodfTMO63Mm80EkIU6Q8r2Y7MTiS74+UbQLdJH1I7OFTrUCQtFda0W6pWuLeU1LjrPYlDq08bsdIoRiNBn36Kc1gY5mvXiJowkexz57UOq9rS6RSmOqq7Y4/7NOCp38/y/d4qWvze2Qv6vwYBZa9OEHEljbhrWTgadHRu6GO92KSbyMROkiT71Go4GF0h4QxE7bTceSPWq9/rhIF7FakpZiE6V1eCvvwCxxbNMSUmEjVhAjkXZbsxa0nfvBmAvM7dEQKe/+kwK/ZEaRyVbRRMw3Zp5IuTsQquLazCZGInFWrQoAGzZ8/WOgxJUjm6Q8th6m1L1rSrgdOwN9J7eBD81Vc4hISQFxdH1Pjx5F4uvdepVD7mjAwydu0CYPj0+xnXvUF+cneEb3dV/+Tun8L1dX4aR1LzyMROkiT71T5/9+axVWqniMrKy4azf6u3q3mZk1sx+PgQvGABxqAgcqOjiZowgbzERK3DqlbSd+5C5ORgrFsXx8aNef2uFkzo0RCAl1YdYcnOSI0jtJ6sXBO7z6v/nuT6OtuTiV0Nkp6ezpgxY3Bzc6N27dp88MEHhIeHM3PmTMLDw4mMjOTJJ59EURRZwkWyD0FdwDcUcjPg2MrKny9yO+SkgWuAWourBjMGBhC8cCGGWrXIOXuWqEmTZGcKC0rbtAlQd8MWvKe+emdzHumlJnevrj7K4h0XtAvQinafTyQ7z0wtDydCA4qvWypZj0zsLEAIQUZOns2/yts05Nlnn+Wff/7h559/5s8//2TTpk3s378fgJUrV1KvXj3efPNNYmNji7RxkyTNKMr1Ubv9FpiOLShKHDpQbXRewznUq0vwggXofX3JPn6C6MlTMKenax1WlSeEUPvDUrSNmKIovDSkOVP6qDtkX/v5GAu3Vb8NLIVlTpr4yUECDcg6dhaQmWuixWt/2Py6x98chItD2f4XpqWl8fXXX7N06VL69+8PwKJFi6hXrx4APj4+6PV63N3dqVXLwjXDJKky2o6EDW9CzF64cgICmlf8XKfXqd9r8DTsvzk2akjwgq+JHDOWzIMHiX50BkFffoHO0VHr0Kqs7FOnyIuLQ3FywqVz5yKPKYrCC4OboVcUPtt0lv/8ehyTWTCpVxUuh/IvmyMKEjs5DasF+ZG1hjh79iw5OTl06dKl8D4fHx+aNm2qYVSSVAZuAWqbMajcqF38GUg8BzojhPS1TGzVhFPTpgTPn4fOxYWMnTuJeWImIjdX67CqrLRN/wDg2rUrOqebOy4oisKzg5ryWL/GAPz3txPM23zWpjFaS2xKJqcvp6FToGdjuXFCC3LEzgKcjXqOv2n7EQBnuYVcqinCHoKTa+DwchjwRsW6RRTshq3fvUztkGoa5zZtqPfF50Q/Mpm0TZu49Pzz1Hn//arZBktjaf+oiZ1beHiJxyiKwlO3NUGnKMzZEMH/rT2JyQzTwstWANhebTmtFiVuU88LL5fq39XFHskROwtQFAUXB4PNv8qzdiEkJASj0ciu/O33AElJSZw+fbrwvx0cHDCZTBZ9bSTJIhrfBm611Abkp3+v2DlO5yd2BaN/0k1cO3em3qefgNHItbW/E/vaawizWeuwqpS8pCQyDx0CwK1P71seqygKT97WhCcHNAHg3XUnmfv3GavHaE3/RMgyJ1qTiV0N4ebmxsSJE3n22WfZuHEjR48eZdy4cUVaozVo0IDNmzcTExNDfHy8htFK0r/oDdBupHq7ItOxWdcgcpt6W66vuyW3Xr2o+7//gU5Hyk8rufzOrHJv1KrJ0rduBbMZx6ZNMdauXabnPDEglGcGqsnd+3+c4uMNEdYM0WpMZsG2M7KNmNZkYleDvP/++/Tq1Yu77rqLAQMG0LNnTzp06FD4+JtvvsmFCxcICQnB31/+Ukp2Jix/d+zZDZBSzm4J5/4Gcx74hJS512VN5jFoIHXe+T8AkpYs4ersORpHVHUUrK9z69OnlCOLmtEvlOcGq2ueP1x/mtl/nS7lGfbnSEwKyRm5uDsZaBfkpXU4NZZM7GoQNzc3lixZQnp6OnFxcTz77LNFHu/atSuHDh0iKytLfkKX7I9vCNTvAcIMB78t33NP55c5kdOwZeY5dCi1Xn8NgIQvvyR+3nyNI7J/Ii+PtC1bgKJlTspqenhjXhqi9mOd/VcEH/55qkq9FxeUOekR4odBL9MLrchXXpKkqqNg1O7AEijr2i+z+frGiSYDrRNXNeU9ciQBzz4DwNUPPyRx6TKNI7JvmQcPYr52Db2nJ85t21boHJN7h/DKHWpJn483nuF/VSi5u16/Ts74aEkmdpIkVR0thoKDOyRHwoUtZXtO7AFIv6o+L7i7deOrhnwnTsRv+nQALv/3vyT/ZIEOINVUwW5Y1169KrWbeFKvRrx2ZwsA5v59lnfX2X9ydy0rlwPRyQD0khsnNCXLndRwm/Lb3khSleDgAq1HwL5v4MBSaFSG6a6CadiQvhUrkyLh99gMzOnpJC5aROyrr6Jzccbj9tu1DsvuFK6vu0WZk7Ka0LMhep3C678c44t/zmIym3lpSHO77eSw/Uw8JrOgkZ8rQT4uWodTo8kRO0mSqpawMer3E79AZnLpx8tuE5WmKAoBLzyP1/33g9lMzLPPkfr331qHZVdyL10iOyICdDrcevawyDnHdm/AW/e0AmD+lvO8teaE3Y7cbY6Qu2HthUzsJEmqWuq2h4AWkJcFR3649bGpcRB7UL3d+Darh1adKYpCrddfw+POOyEvj5gnZpK+c6fWYdmNgmlY57Aw9F5eFjvvw13r83/DWgOwYNt5/vPrcbtL7oQQRfrDStqSiZ0kSVWLohTdRHErEevV73Xag3ugdeOqARS9njrv/B9u/fsjcnKInv4oGQcOaB2WXahomZOyGNUlmFnDW6Mo8M32C7z+yzG7Su7Ox6dzMSkTB72Oro18tQ6nxpOJnSRJVU+bB9Ser7GHIPZwycfJaViLU4xG6n70Ia49eiAyMoiePIWs48e1DktT5szMwtFLayR2AA92DubdEW1QFFi8I5JXVh/FbLaP5K5gtK5jA29cHOTSfa3JxE6SpKrH1Rea3aHeLmnULi8bzm1Sb4fKMieWpHNwoN6nn+DcoQPm1FSiJk4i+2z1aGJfEem7diGyszHUro1jk1CrXef+jkG8f29bFAWW7Yri5dVH7CK5k+vr7ItM7CRJqpra50/HHv4ecrNufjxyO+SkgVsg1G5n09BqAp2zM0FffI5Ty5aYkpKIGj+BnOhorcPSRMH6Orc+va2+a/XeDvX48P626BT4bnc0L67UNrnLzjOx42wCIMuc2AuZ2EmSVDU16gse9SArGU6uufnx0/lFiUNvA518q7MGvbs7QV/NxzE0lLwrV4gaN57cuDitw7IpIcT1xM4CZU7KYlhYPT56oB06BVbsjea5nw5j0ii52xeZRGauCT83R5rX8tAkBqko+W4nFWrQoAGzZ8/WOgxJKhudHtqNUm8XNx1b0G0iVK6vsyaDtzfBC77GWD+Y3JgYosZPIC8hQeuwbCY7IoK8S7Eojo64dulis+sObVeXOQ+Godcp/LjvIs/+cEiT5G7z6fxp2FA/dDr7rLFX08jETpKkqitstPr93CZIirx+f/wZSDynbrAI6atJaDWJwd+f+gsXYqhTm5zz54maOAlTSorWYdlEwWidS9cu6JydbXrtu9rW4ZORYRh0CisPxPD09wfJM5Wx1Z6FyDZi9kcmdjVIeHg4M2bMYMaMGXh6euLn58err76KEILw8HAiIyN58sknURTFbqubS1IR3g2gYf4uxIM39DEt2A3boAc4uts8rJrIWKcO9RcsQO/nR/bJk0RNnowpLV3rsKzu+vo66+yGLc2Q1rX5dFR7DDqF1Qcv8eT3h2yW3F1NzeZ47DUAesr1dXZDJnaWIATkpNv+qwJ1jBYtWoTBYGD37t3MmTOHDz/8kK+++oqVK1dSr1493nzzTWJjY4mNjbXCCyVJVtA+vxPFgWVgNqm35TSsJhwaNCB4wdfoPT3JOnSYi9OnY84qZmNLNWFKTiZzv1rHz12jxA5gcKtafDa6PUa9wq+HLvHEioPk2iC52xKhjta1rOOBn5uj1a8nlY0sOGMJuRnwf3Vsf92XLoGDa7meEhQUxEcffYSiKDRt2pQjR47w0Ucf8cgjj6DX63F3d6dWrVpWCliSrKDZneDkBdcuwrm/oV5ndUcsyPp1GnBq0oSgr74iatw4Mnbv5uLjjxP06acoDtWvT2/a1m1gNuMY2hhj3bqaxjKwZS0+H92B6cv289vhWMxmwccjwzDqrTd+I6dh7ZMcsathunbtWmSatVu3bkRERGAymTSMSpIqwegEbe5Xb+9fAmc3gjkPfBuDb4i2sdVQzq1bEfTlFyhOTqRv3kLMs88h8vK0DsvitJ6G/bcBLQL58uEOOOh1/H40jhnf7icnzzojd2azYOuZgo0TMrGzJ3LEzhKMLuromRbXlSRJbTG2ex6c/E0tTAxyGlZjLh07Uu/TT7k4bRqpf/xBrLMztf/vbZRqUnpGmEykb9kC2K7MSVn0bRbAvDEdmLxkH38cu8z0ZfuZOzoMR4Peotc5HnuN+LQcXB30dKjvbdFzS5VTPX7DtKYo6pSorb8qsMFh165dRf57586dhIaGotfrcXBwkCN3UtVUuw3UagPmXDj9u3qfnIbVnFvPHtT96EPQ60lZvZrL//2vXfU4rYzMQ4cxJSej8/TEuV07rcMpIrxpAF+N6YijQcdfJy4zbel+svMs+96+OX99XbcQXxwMMpWwJ/L/Rg0TFRXFU089xalTp/juu+/45JNPeOKJJwC1jt3mzZuJiYkhPj5e40glqZwKNlEAOLhDcDftYpEKuQ8YQJ1Zs0BRSPr2O65++GG1SO4Kp2F79EAx2N/kV+8m/nw9thNORh0bT15hypJ9ZOVaLrmT6+vsl0zsapgxY8aQmZlJ586defTRR3niiSeYPHkyAG+++SYXLlwgJCQEf3/5yypVMa3vBX3+zryQvmCofov1qyrPu+6k1htvAJAw/ysSvvxS24As4Hq3CftYX1ecnqF+LMhP7jaduspkCyV36dl57ItMAqCXXF9nd2RiV8MYjUY+//xzUlJSSExM5O233y7cTNG1a1cOHTpEVlZWtfhELdUwzt7XO1EUbKaQ7Ib3A/cT8MLzAFydPYfERYs0jqjicmNjyT55EhQF1169tA7nlro39uOb8Z1xNurZfPoqjyzeS2ZO5ZK7HWcTyDUJgnycaeAr13rbG5nYSZJUfdz+Hjy6G5rfpXUkUjF8x43D77EZAFx+ZxZJP/ygcUQVk/bPZgCc27bF4G3/Gwe6NvJl0YTOuDjo2RIRz8RFeyqV3BXUr+sd6i+L2dshmdhJklR9GBzAv6nWUUi34Dd9Oj4TJwAQ99rrpKz5TeOIyq8qTMP+W+eGPiye0BlXBz3bzyYw/pvdZORUrATN5oj8MidyfZ1dkoldDbJp0yZmz56tdRiSJNVgiqIQ8MwzeI18EITg0vPPk7pxo9ZhlZk5O5v0nTsB+ypzUhYdG/iweGJn3BwN7DyXyLiFe0jPLl9yF52Ywfn4dAw6he4hvlaKVKoMmdhJkiRJNqUoCrVefRXPoXeDyUTMEzNJ375d67DKJGP3bkRmJoZatXBsWvVGhzvU92HJxM64OxrYfT6RcQt3k1aO5O6f/N2w7YO9cXcyWitMqRJkYidJkiTZnKLTUfvtt3G/7TZEbi7Rj84gY98+rcMqVdqm/GnY3r2r7PqysGBvlk7qgoeTgT0Xkhi7YDepWbllem5BmZNeoX7WDFGqBJnYSZIkSZpQDAbqfvA/XHv1QmRmEj1lKplHj2kdVomEEFVyfV1x2gZ5sWxSVzydjeyLTGLMgt1cKyW5yzWZ2X42AZDr6+yZTOwkSZIkzSgODtT7eA4uHTtiTksjetIksiMitA6rWDnnzpF78SKKgwOuXbtqHU6lta7nybJJXfByMXIgKpmHv95NSmbJyd3B6GTSsvPwdjHSqq6nDSOVykMmdpIkSZKmdM7O1PviC5zatMGUnEzkhAnkREZqHdZN0jZtAsClc2d0LtWjflurup58O6kr3i5GDkUn8/DXu0jJKD65K5iG7Rnqj15XNaehawKZ2EmSJEma07u5EjzvSxybNsV0NZ7I8ePJjY3VOqwiCtfX9ana07D/1qKOB98+0hUfVwcOX0xh9Nc7Sc7Iuem4wjZicn2dXZOJnSRJkmQX9F5eBH/9FQ4NGpB3KZaocePJu3pV67AAMF27Rsb+/UDVX19XnOa1Pfjuka74ujpwNOYao+bvIin9enKXmJ7D4ZgUQK6vs3cysZMkSZLshsHPj+CFCzDWqUNOZCRREydhSk7WOizSt20DkwmHkBAcgoK0DscqmtZyZ/nkrvi5OXI89hqjvtpFYn5yt/VMPEJA00B3Aj2cNI5UuhWZ2EkVlpNz81C9JElSZRlr1yb4m4UY/P3JPn2aqEcmY0pL0zSm6joN+2+hgWpy5+/uyInYa4yav5P4tOzr07BN5DSsvZOJXQ0SHh7O448/znPPPYePjw+1atXijTfeKHw8KiqKoUOH4ubmhoeHB/fffz+XL18ufPyNN96gXbt2fPXVVzRs2BAnJ/mpTZIk63AIDiZ44QL0Xl5kHTlC9NSpmDMzNYlFmM2kbdkCVP/EDqBxgBvLJ3clwN2Rk3GpjJy3s7AwsZyGtX8ysbMAIQQZuRk2/xJClDvWRYsW4erqyq5du3jvvfd48803Wb9+PWazmaFDh5KYmMg///zD+vXrOXfuHA888ECR5585c4affvqJlStXcvDgQQu9gpIkSTdzbNyYoK+/QufmRubefVx87HHMGswUZB05gikxEZ27Oy7tw2x+fS2E+LuxYko3ank4EXEljaup2TgZdXRq4KN1aFIpDFoHADB37lzef/994uLiaNu2LZ988gmdO3cu9tjc3FzeeecdFi1aRExMDE2bNuXdd99l8ODBhce88847rFy5kpMnT+Ls7Ez37t159913aWql9i+ZeZl0+baLVc59K7tG7cLFWL4t923atOH1118HIDQ0lE8//ZQNGzYAcOTIEc6fP09Q/vqRxYsX07JlS/bs2UOnTp0Adfp18eLF+PvLT22SJFmfc8uWBM2bR9TEiaRv3cqlp5+m7kcfoRhs9+crNb/MiWuPHijGmtNGq6GfK8snd2Xk/J3EpmTRpaEvTka91mFJpdB8xG7FihU89dRTvP766+zfv5+2bdsyaNAgrly5Uuzxr7zyCl9++SWffPIJx48fZ+rUqQwbNowDBw4UHvPPP//w6KOPsnPnTtavX09ubi4DBw4kPT3dVj+W3WrTpk2R/65duzZXrlzhxIkTBAUFFSZ1AC1atMDLy4sTJ04U3le/fn2Z1EmSZFMu7cMI+mwuioMDqev/4tJLLyHMZptdv7DbRA2Yhv23Bn6ufD+lGw93rc9zg6teb9yaSPMRuw8//JBHHnmE8ePHA/DFF1/w22+/sWDBAl544YWbjl+yZAkvv/wyQ4YMAWDatGn89ddffPDBByxduhSAdevWFXnON998Q0BAAPv27aN3794W/xmcDc7sGrXL4ucty3XLy/ivT5uKomAuxxukq6trua8pSZJUWa7dulF39mwuPv441375FZ2LC7Vef93q/VpzL18h+/gJUBTcevey6rXsVZCPC2/d00rrMKQy0jSxy8nJYd++fbz44ouF9+l0OgYMGMCOHTuKfU52dvZNi/adnZ3ZunVriddJSVFr7/j4WGdtgKIo5Z4StTfNmzcnOjqa6OjowlG748ePk5ycTIsWLTSOTpIkCdz79aXOu7O49MyzJC9fgc7ZhYDnnrVqcpe2WR2tc2rTGoOvr9WuI0mWoulUbHx8PCaTicDAwCL3BwYGEhcXV+xzBg0axIcffkhERARms5n169ezcuVKYkuoUG42m5k5cyY9evSgVaviP3FkZ2dz7dq1Il81zYABA2jdujWjR49m//797N69mzFjxtCnTx86duyodXiSJEkAeN5xB7X/+xYAiQsXEj/3M6teryZPw0pVk+Zr7Mprzpw5hIaG0qxZMxwcHJgxYwbjx49Hpyv+R3n00Uc5evQoy5cvL/Gc77zzDp6enoVfQdW0+OStKIrCzz//jLe3N71792bAgAE0atSIFStWaB2aJElSEV4jRhD40ksAxH/6KQkLv7HKdcw5OaRvV2ePZGInVRWKqEjNDAvJycnBxcWFH3/8kXvuuafw/rFjx5KcnMzPP/9c4nOzsrJISEigTp06vPDCC6xZs4Zjx44VOWbGjBn8/PPPbN68mYYNG5Z4ruzsbLKzswv/+9q1awQFBZGSkoKHh8dN1z1//rys41YB8rWTJMmS4r/4gquz5wBQ6z//wfuB+y16/rRt24ieOAmDvz+NN/9j9fV8klSSa9eu4enpWWxe8m+ajtg5ODjQoUOHwnIboE6dbtiwgW7dut3yuU5OTtStW5e8vDx++uknhg4dWviYEIIZM2awatUqNm7ceMukDsDR0REPD48iX5IkSZJ9850yBd9HHgEg7o03SPnlF4uev6DbhGuf3jKpk6oMzXfFPvXUU4wdO5aOHTvSuXNnZs+eTXp6euEu2TFjxlC3bl3eeecdAHbt2kVMTAzt2rUjJiaGN954A7PZzHPPPVd4zkcffZRvv/2Wn3/+GXd398L1ep6enjg7l38nqSRJkmR/FEXB/6knMWdkkLRsGZdefAnF2RmP226r9LmFEHJ9nVQlaZ7YPfDAA1y9epXXXnuNuLg42rVrx7p16wo3VERFRRVZP5eVlcUrr7zCuXPncHNzY8iQISxZsgQvL6/CYz7//HNAbaF1o4ULFzJu3Dhr/0iSJEmSjSiKQuDLL2HOyCBl1Spinnoa3Wef4darZ6XOm3P+ArlRUShGI67dulsoWkmyPk3X2NmrW81ly3ViFSdfO0mSrEWYTMQ8/Qyp69ahODkRPH8eLvkdcyoiYeE3XHn3XVy7dyd4wdcWjFSSyq/KrLGTJEmSJEtQ9Hrqvvcubn36ILKyiJ46jcwjRyp8vsJp2HA5DStVLTKxkyRJkqoFxcGBunNm49KlC+b0dKImPULWqdPlPo8pLY2MvXsBub5OqnpkYidJkiRVGzonJ4I+m4tz27aYU1KImjiR7PPny3WO9G3bIS8PhwYNcKhf30qRSpJ1yMROkiRJqlZ0rq4EzfsSx+bNMcXHEzVhIrkxMWV+ftqmTYAcrZOqJpnYSZIkSdWO3tOT4K/m49CoEXmxsUSOn0DulSulPk+YzaRt3gzI9XVS1SQTO0mSJKlaMvj6ErxwAcZ69ciNiiJ64kTykpJu+ZysY8cwJSSgc3XFpUMHG0UqSZYjEztJkiSp2jIGBhL8zUIMgYFkR5whetIjmFJTSzy+sNtEjx4oDg62ClOSLEYmdpIkSVK15lCvHsELF6D38SHr2DGip0zFnJFR7LGy24RU1cnErgYJDw/nscceY+bMmXh7exMYGMj8+fMLW7i5u7vTuHFjfv/9dwBMJhMTJ06kYcOGODs707RpU+bMmVPknJs2baJz5864urri5eVFjx49iIyM1OLHkyRJKpFjo0YEf/0VOg8PMvfv5+KMxzBnZxc5Ju/qVbKOHgXArXcvLcKUpEqTiZ0FCCEwZ2TY/KsiTUMWLVqEn58fu3fv5rHHHmPatGncd999dO/enf379zNw4EAefvhhMjIyMJvN1KtXjx9++IHjx4/z2muv8dJLL/H9998DkJeXxz333EOfPn04fPgwO3bsYPLkybJZtiRJdsmpeXOC532J4uJC+vbtxDz5FCI3t/DxtM1b1ONatcLg769VmJJUKbKlWDHK21LMnJHBqfa2X2TbdP8+dC4uZT4+PDwck8nEli3qm5fJZMLT05Phw4ezePFiAOLi4qhduzY7duyga9euN51jxowZxMXF8eOPP5KYmIivry+bNm2iTxmmLWRLMUmS7EH6zl1ET5mCyM7G4447qPPeuyh6PRcfe5zU9evxe/RR/B+boXWYklRIthSTStSmTZvC23q9Hl9fX1q3bl14X2BgIABX8ssCzJ07lw4dOuDv74+bmxvz5s0jKioKAB8fH8aNG8egQYO46667mDNnDrGxsTb8aSRJksrPtWsX6s6ZDQYD1377jbg33sCck0P69u2ALHMiVW0GrQOoDhRnZ5ru36fJdcvLaDQWPYeiFLmvYBrVbDazfPlynnnmGT744AO6deuGu7s777//Prt27So8fuHChTz++OOsW7eOFStW8Morr7B+/fpiR/skSZLshXt4OHX/9z4xTz1N8g8/khMVjTk9Hb2fH04tW2odniRVmEzsLEBRFJRyTIlWFdu2baN79+5Mnz698L6zZ8/edFxYWBhhYWG8+OKLdOvWjW+//VYmdpIk2T2PwYMxZ2YR++KLZOR/YHXr3RtFJyezpKpL/uuVShQaGsrevXv5448/OH36NK+++ip79uwpfPz8+fO8+OKL7Nixg8jISP78808iIiJo3ry5hlFLkiSVndewewh89ZXC/5ZlTqSqTo7YSSWaMmUKBw4c4IEHHkBRFEaOHMn06dMLy6G4uLhw8uRJFi1aREJCArVr1+bRRx9lypQpGkcuSZJUdj6jR6NzdiHr6FHc+/XVOhxJqhS5K7YY5d0VK5WNfO0kSZIkqfzkrlhJkiRJkqQaSCZ2kiRJkiRJ1YRM7CRJkiRJkqoJmdhJkiRJkiRVEzKxkyRJkiRJqiZkYldBZrNZ6xCqHLkBW5IkSZKsS9axKycHBwd0Oh2XLl3C398fBweHwjZcUsmEEFy9evWmFmaSJEmSJFmOTOzKSafT0bBhQ2JjY7l06ZLW4VQpiqJQr1499Hq91qFIkiRJUrUkE7sKcHBwIDg4mLy8PEwmIe/pYwAAGexJREFUk9bhVBlGo1EmdZIkSZJkRTKxq6CCKUU5rShJkiRJkr2QmyckSZIkSZKqCZnYSZIkSZIkVRMysZMkSZIkSaom5Bq7YhTUW7t27ZrGkUiSJEmSVNMV5CNlqQcrE7tipKamAhAUFKRxJJIkSZIkSarU1FQ8PT1veYwiZDuAm5jNZi5duoS7u7vVig9fu3aNoKAgoqOj8fDwsMo1qjL5+pRMvjYlk6/NrcnXp2Tytbk1+fqUzBavjRCC1NRU6tSpg05361V0csSuGDqdjnr16tnkWh4eHvKX5Bbk61My+dqUTL42tyZfn5LJ1+bW5OtTMmu/NqWN1BWQmyckSZIkSZKqCZnYSZIkSZIkVRMysdOIo6Mjr7/+Oo6OjlqHYpfk61My+dqUTL42tyZfn5LJ1+bW5OtTMnt7beTmCUmSJEmSpGpCjthJkiRJkiRVEzKxkyRJkiRJqiZkYidJkiRJklRNyMROkiRJkiSpmpCJnWSX5J4eSZIkSSo/mdhJduWFF15g69atVmvlVh2YTKZib0uSJEmSTOzsSE0fpZo1axYff/xxmdum1BRmsxlQ+xGmp6ej1+v5888/ycjIQK/XaxydJFV9Nf29V6peZGKnkYI/1levXuXixYsANXqUKjMzkz///JOnn36a1q1bs3PnTs6cOaN1WHZBp9ORlJTEwIED+fPPP1m2bBmDBw/mr7/+0jo0qYqSI71FKYrCb7/9xieffKJ1KFXKuXPnOHHiBElJSVqHYjdu/JCg1QcGmdjZ0DfffENkZCSg/rFeuXIl3bt3p1u3brRs2ZL333+fmJgYjaPUhtFopEmTJuzdu5c333yTwYMHExcXp3VYmlu6dClffPEF3t7eNGrUiCeeeIKxY8cyb9487r777sIPCFJRBW+okZGRHDx4kJycnJseq4lyc3Mxm82FI73Lli3jvffe46OPPuLUqVM16rURQhT+/uzZs4cxY8bg7e1NXl6expFVDT/99BN9+/ale/fuPPzwwyxatEjrkDRV8LuTnp4OqL9riqJo8x4tJJu4du2aCAwMFO3btxeXLl0SBw4cEN7e3uLtt98Wf/75p5g+fbro1KmTeOSRR0RMTIzW4Wpi//79ok2bNkKv14vnnnuu8H6z2axhVNpJS0sTAwYMEJ06dRJr164VmzZtEp6eniIwMFD8+OOPIi0tTQhRc1+f0vz4448iKChIBAQEiHbt2onvvvuuRr9mDzzwgBg5cqTIysoSQgjx/PPPC1dXV9GvXz/h5eUlOnbsKN59912Rl5encaTW9dtvv4lDhw4V/vfp06fFrFmzxAsvvCCEEMJkMmkVWpURExMj2rZtK7766iuxZs0acf/994vu3buL2bNnax2aJgreT9atWyfuuusu0a9fP3HfffeJuLi4Io/bikzsbCgqKkq0atVK9OjRQ3z//ffi6aefLvL4J598Itq3by8+/vhjIUTN+eNT8Eb6yy+/CEVRRMuWLcV9990nNm/eXHhMTXkt/u3SpUvi/vvvF/379xdPPPGE+OOPP8SECRNE06ZNxeLFi0V6eroQoujrU93/MN9Kwetw4sQJ0aJFC/HRRx+JXbt2iaFDh4p27dqJuXPn1tjkbuXKlcLFxUVMmzZNnD59WnTt2lXs3LlTCCFERkaGmD59uujZs6f45JNPNI7UeuLi4kTDhg3F+PHjxeHDh0VWVpaoW7eucHR0FJMnTy48rqb92yiv+Ph48eCDDxa+/0RGRorJkyeLrl271qjk7sZ/J6tXrxZubm7ixRdfFJ9++qno3bu3aNy4sYiIiLjpWGuTiZ2NRUdHi+bNmwtFUcSQIUNu+iM8YcIE0a5dO42i086ePXuEj4+P+PTTT8Xq1atFeHi4uOeee8SWLVsKj6lJb7Zms1nk5OQIIYQ4evSoGDRokAgPDxdr1qwRQgjx8MMPi6ZNm4ply5YVvrl+8cUXIiMjQ7OY7cW+ffvEBx98IB5//PEi948bN67GJ3e///67cHJyEnfccYcYNGiQSEpKKnwsISFBjBo1SvTu3Vu7AG1g3759olOnTmLSpEkiMTFR7NixQwQHB4v27duL3bt3ax2eXVu7dq0YMWKEePjhh0X//v2LPHbhwgUxefJk0bNnT/HOO+9oFKFtxMbGFvnvkydPirCwMDF37lwhhDqIExwcLLy9vUVgYKA4deqUEMJ27zcysdNAdHS06Natm6hbt644fPhwkcdWrFghmjVrJuLj4zWKzvYiIiLEK6+8Il588cXC+9asWVNscldTFLwBrFixQtx///2iW7duwsXFRTRo0ECsXLlSCCHEmDFjRMuWLcUrr7winn76aaEoijh+/LiWYWvOZDKJvn37CkVRRO/evW+aVhs3bpzo2LGj+N///leYENc069atE76+vsLT01OcOHFCCHF91PzYsWNCURSxdetWLUO0uv3794t27dqJCRMmiKtXr4qdO3eKevXqibFjxxZ5T65pif+tbNq0Seh0OjFy5EgRFhYmjEajeOWVV4ocExkZKUaOHCluu+02kZiYqFGk1jV37lwxZMgQsWfPnsL7du/eLZ566imRl5cnoqOjRWhoqJg0aZI4fvy4aNKkiWjWrFnh75otyMTOygreGE6ePCn27NlTOL0YHR0tWrduLdq3by8OHDggMjMzhRBCTJ06VYSFhYnU1FTNYrallJQU0bFjR+Hv7y+efPLJIo8VJHf33nuv2Lhxo0YRamfnzp3CxcVFfP311+LkyZMiIiJChIeHi06dOolVq1YJIYR44oknRHh4uGjfvr04ePCgtgHbiYyMDDFixAhRr1498e2334rs7Owij48YMUL07t272v7huVFJ68XWr18vXF1dxdixY4uM2h0+fFiEhISI/fv32yhC7dyY3CUmJoqtW7eKoKAgMW7cOHHkyBGtw7Mrp06dEqtWrSpcJnTx4kXx2muviRYtWojXX3+9yLHR0dE3jWhVJxs3bhRBQUFi1KhRRZK7glG5cePGiXvvvbfwfeeee+4RiqKIxo0b3/ReZC0ysbOigqRu1apVokGDBqJ58+bC2dlZjBs3Tly6dElERUWJNm3aCH9/fxEeHi6mTp0qAgICxIEDB7QN3Mb2798vQkNDRbt27YosahZCXegcFhYmRo8eXeOmGb/88kvRokWLIj/3xYsXRc+ePUX9+vXFzz//LIQQIj09XSQnJ2sVpqYKfscuX74s0tPTxbVr14QQanI3YMAA0bFjR/HTTz8VTmsXqAkblG5M6v755x+xcuVKERcXV/ha/Pbbb8LJyUncd9994ocffhDbt28Xd9xxhwgLC6sx6zSLS+4aNWokRowYIY4dO6Z1eHYhKipK+Pj4CHd3d/HZZ58V3h8TEyNef/110axZM/Hmm29qGKHtFPxe7Ny5U4SEhIiHHnqocJ2qEOqGt+7duxcmwEKogzVr1qwRly5dslmcMrGzsj/++EN4eXmJL7/8UmRnZ4u1a9cKRVHEAw88IKKiokRUVJTo37+/UBRFrFu3TkRFRWkdsiYOHTok2rRpIyZNmiSOHj1a5LE//vhDXLhwQaPItLN48WLRtGlTceXKFSGEKPyDfPjwYeHm5iZatmwpFi9erGWIdmHVqlWiQ4cOomnTpuKxxx4rnEZMT08X/fv3Fx06dBCrVq26KbmrKZ555hnh7+8vfH19RXBwsPjss88Kl3r89ttvwtPTUyiKIqZOnSpGjRpV+DrVxOQuKSlJ/P3336JVq1Y1IvkvTcGo9kcffSRq164txo0bV+TxS5cuiTfffFMEBgaKWbNmaRGiTRX8TqSkpIh3331XeHl5iZEjRxYZjLn99ttF8+bNxcaNG8Vjjz0mgoKCRGRkpE3jlImdFaWkpIjJkyeL//znP0IIIc6dOydCQkLEvffeKzw9PcXdd98tzp07Jy5cuCC6detm8//59mb//v2iffv2YtKkSfLTslDXHjo5OYlXX321yP179+4Vffr0ESNHjqzx/2aOHDkivLy8xHvvvSeef/55MXDgQNGrVy+xfv16IYSa3A0aNEiEhISIX3/9VeNobePGdWEbN24UnTt3Fv/884+4cuWKmDp1qmjZsqV49913C5O7DRs2CEVRiuxmzM3NtXncWtq/f7/o2LGjuP/++0VycnKNmx0ozuHDh0X37t1FdHS0SE5OFp9++qlwc3MTzzzzTJHjLl68KGbNmiXOnDmjUaS2UTAC/sMPPwhfX18xbdo00bdvX2EwGMTw4cPF3r17hRBCHDhwQHTv3l0EBQWJFi1aaLKsQSZ2VpSdnS2+//57cebMGZGQkCDCwsLExIkThRBCfPvtt0JRFHH77beL6OjoGvdGWpL9+/eLzp07iwcffNCmi03t1ZIlS4TRaBQvvfSSOH/+vEhKShKvvvqqGDt2rEhJSdE6PE0dOXJEvP322+K1114rvG/Dhg1i2LBhonv37oXJXVpamhg6dKg4d+6cVqFqYtGiRWLmzJk3/SGeOXOmaNGihXjvvfcKk7tt27bV+Peg3bt3i969e9t0ysyerV+/XtStW1f8/fffQgi1xMncuXOFr6/vTf+mquvo7r9rHp4/f14EBwcXKQm0ceNGERAQIO65557C2Saz2SxOnDghEhISbB6zEDKxs7qCTRFLliwR3bp1E9HR0UIIIb777jsRHh4u6tevX+NHXf5t9+7dok+fPvINVqhvEN9++61wc3MTDRs2FCEhIcLHx0fs27dP69A0UTAade7cOXHHHXcIPz8/MXPmzCLHFCR3vXv3Fr/99psWYWri3zs4CxZtDxw48KZp6JkzZ4o2bdqIV199tcj6zJqe3BW8X0uqhx56SLRu3bqwqHViYqKYO3euCAwMFNOmTdM4Ouu6seZhQbWBixcvivr164u1a9cKIa6P4m3YsEHodDrx8MMPi23btmkWcwHZUszKnJycADh//jypqam4uroCcOjQIUaMGEFERATBwcFahmh3OnXqxLp166hdu7bWoWhOURRGjhzJkSNHmD17Nm+//Tb79u2jffv2WoemiYKenn/88QcPPvggjRo1Yu3atRw5cqTwmH79+vH4449jMBj4+OOPycjIqPatsoQQhb2mv/32W5YsWcKqVauYNm0aR44cYenSpWRkZBQe/9FHH9GhQwfOnTuHh4dH4f0Gg8HmsduTgvdrSfX444/j4uLCL7/8AoC3tzejR4/m2Wef5Y8//uDKlSvV9ncrMDCQH3/8kaNHj/Lhhx9y7NgxXF1dycrKKmz9mZeXh9lspl+/fnTo0IGlS5eyePFisrKytA1e48Syxti/f79wdHQUPXr0EP379xceHh437QCVJKmoG6dCCkakhg8fXrjr7McffxR9+vQRw4YNu+n3afPmzYUj5NXZjbtfjx49KsLCwkTbtm3FL7/8IoRQ6x02a9ZMLF68+Ka1YwXPlfXapB07doiWLVuKtWvXFs4ipaWlicGDB4u77rqryLEpKSk1olyQENfXfk+cOFHExMSIDz74QDg4ONxUX3Xq1Kniiy++sIu1hooQ1TTdtkM7duzgs88+w9PTk2nTptGyZUutQ5Iku3X58mW6detGeHg4zzzzDC1atACgd+/e3H333TzzzDMArFixgnnz5uHu7s5bb71F69attQxbM88++yznz58nNjaWkydP4uXlxfvvv8/w4cMZM2YMe/fu5eWXX2bYsGG4uLgUPs9sNqPTycmbmuzgwYNcunSJBQsWcObMGRwdHZk2bRrjxo3jzJkz9O7dmw8++ICRI0dqHaomDhw4wIQJE+jYsSMPPvggP//8M59//jkffPABAQEB7N27l2XLlnH06FF8fX21DleO2NmayWSSn44lqYxubP9UUDR24MCBYunSpUWOW7ZsmejXr5/o27dvjSwuu3DhQuHl5SX27dsnEhMTRWxsrBg4cKDo2LGjWL16tRBCiLFjxwpvb2+xbt06jaOV7MnKlStFUFBQYfWGv//+W7z22mvCzc1NDBo0SDz55JNi1KhR4rHHHitca1cTFeycnjJlivj777/Fxx9/LOrXry+aNGkiWrZsaVfrnmViJ0mSXSuYCpkwYYI4cuSIeOCBB8SGDRtuOm7u3Lli9OjRNWL69d9efvll0bNnT2EymQqnVy9evCi6dOkiGjRoUJjcvfXWWzW2np90szVr1ghnZ2cxf/78m2qoHj58WLzxxhuibdu2QlEUERwcXFgAvKbat2+f6NChg5g0aZKIjY0VGRkZIiEhQbPdryWRU7GSJNm9AwcOMHnyZFq2bMlPP/1EQEAAjRo1QlEUcnJyMBqNhIaG8tprr1GrVi2tw7UZkb9p4q233uKXX35hy5YtODk5kZubi9Fo5O+//+bOO++kQ4cOPP/889xxxx0AmEwm9Hq9xtFLWsrKymLMmDGEhoby9ttvk5GRQWxsLMuXL6dZs2aEh4fj6+tLWloac+bMYfjw4TRv3lzrsDV34MABpkyZQqNGjXjttdcKl4jYE5nYSZJUJezfv59x48ah0+lo2bIlgwYNIjk5mcTERIxGI8OGDbPLN1lbOHLkCGFhYbz66qu8/vrrhff/8ccfzJ8/n6SkJHQ6HWvWrMHR0VHDSCV7kZmZSe/evenWrRtvvPEGr7/+OkeOHOHs2bPk5OQwY8YMXnrpJfkBoBh79uzh2Wef5bvvvrPL6g0ysZMkqco4ePAgkydPpm3btrz88ss0aNBA65DsxjfffMPkyZOZOXMmDzzwAN7e3jz++ON0796dYcOG0bJlS/78808GDBigdaiSnVi8eDFTp07FaDTSv39/7rnnHsaMGcOTTz7JoUOH+Ouvv+TGmhJkZWXZbXkcmdhJklSl3DgV8vrrr8vpoRv89NNPTJ8+HQcHB4QQBAQEsH37di5fvsxtt93Gjz/+SJs2bbQOU7Ijx48fJyYmhttuu61wh/SMGTNITU1l3rx5coS3CqrZ1SglSapywsLCmDt3Ls8++yxeXl5ah2NXRowYQdeuXYmOjiY3N5cePXqg0+n44osv0Ov1BAQEaB2iZGdatGhRuITh9OnTLFmyhKVLl7J161aZ1FVRcsROkqQqyZ6nQuzFsWPHePfdd1m7di1//fUX7dq10zokyU7t27ePDz74gIMHD/Ldd9/Rtm1brUOSKkiO2EmSVCXJpO7W8vLyyMnJISAggH/++UcWRJduqUWLFkybNo0GDRoQFBSkdThSJcgRO0mSpGqsoPSJJEk1g0zsJEmSJEmSqgm5j1mSJEmSJKmakImdJEmSJElSNSETO0mSJEmSpGpCJnaSJEmSJEnVhEzsJEmSJEmSqgmZ2EmSJEmSJFUTMrGTJOn/27efkKjWOIzj38GrdTSkzCSEOYp/koQMZ6GVuQiEMcSN4koFs5GsZGhjtZJWFokUUlhIOUpILUYFQRBdKIwkitIfUNIkzb20yLQmmxZXhubOLLpcvV7PfT5wFu/7znnf33tWD+85IztsdHQUm83Gp0+ffvue1NRU7t+/v2M1iYg1KdiJyP9eTU0NNpuN+vr6sLGrV69is9moqan59wsTEfmbFOxERAC73c7z589ZX18P9m1sbNDT04NpmrtYmYjI71OwExEBHA4Hdrud3t7eYF9vby+maZKbmxvs+/r1K263m6SkJPbv38/Zs2eZmpoKmWtwcJBjx45hGAbnzp1jaWkpbD2fz0dhYSGGYWC323G73aytrUWsLRAIcOvWLUzTZN++fSQnJ+N2u7dn4yJiKQp2IiJbamtr6ezsDLafPn3KhQsXQn5z/fp1vF4vXV1dzMzMkJGRgdPpZHV1FYCVlRXKysooLS3l1atXuFwubt68GTLH4uIixcXFlJeX8+bNG168eIHP56OhoSFiXV6vl3v37vH48WMWFhbo7+/nxIkT27x7EbECBTsRkS1VVVX4fD6Wl5dZXl5mfHycqqqq4Pja2hrt7e20tLRw/vx5srOz6ejowDAMnjx5AkB7ezvp6em0traSlZVFZWVl2Pd5t2/fprKykmvXrpGZmcmZM2doa2uju7ubjY2NsLo+fvzI0aNHKSoqwjRN8vLyqKur29FnISJ7k4KdiMiWI0eOUFJSgsfjobOzk5KSEhITE4Pji4uL+P1+CgoKgn3R0dHk5eUxNzcHwNzcHPn5+SHznj59OqT9+vVrPB4PBw4cCF5Op5MfP37w4cOHsLoqKipYX18nLS2Nuro6+vr6+P79+3ZuXUQs4o/dLkBE5L+ktrY2+Er04cOHO7LG58+fuXTpUsTv5CL9UcNut/Pu3TtGRkYYHh7mypUrtLS0MDY2RnR09I7UKCJ7k07sRER+UVxczLdv3/D7/TidzpCx9PR0YmJiGB8fD/b5/X6mpqbIzs4G4Pjx40xOTobcNzExEdJ2OBzMzs6SkZERdsXExESsyzAMSktLaWtrY3R0lJcvX/L27dvt2LKIWIhO7EREfhEVFRV8rRoVFRUyFhcXx+XLl2lsbCQhIQHTNLl79y5fvnzh4sWLANTX19Pa2kpjYyMul4vp6Wk8Hk/IPDdu3ODUqVM0NDTgcrmIi4tjdnaW4eFhHjx4EFaTx+Nhc3OT/Px8YmNjefbsGYZhkJKSsjMPQUT2LJ3YiYj8RXx8PPHx8RHH7ty5Q3l5OdXV1TgcDt6/f8/Q0BCHDh0C/nyV6vV66e/v5+TJkzx69Ijm5uaQOXJychgbG2N+fp7CwkJyc3NpamoiOTk54poHDx6ko6ODgoICcnJyGBkZYWBggMOHD2/vxkVkz7MFAoHAbhchIiIiIv+cTuxERERELELBTkRERMQiFOxERERELELBTkRERMQiFOxERERELELBTkRERMQiFOxERERELELBTkRERMQiFOxERERELELBTkRERMQiFOxERERELELBTkRERMQifgKgocdSlu3PewAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "transformers = ['qt', 'pt','nor','mas']\n",
    "models = ['ab', 'rf', 'dt', 'knn', 'gnb', 'lr', 'svm', 'lda']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Collecting accuracies for each transformer\n",
    "accuracies = {}\n",
    "for transformer in transformers:\n",
    "    accuracies[transformer] = [globals()[f\"accuracy_{transformer}_{model}\"] for model in models]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for transformer in transformers:\n",
    "    ax.plot(models, accuracies[transformer], label=transformer)\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy of Models for Different Transformers')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
