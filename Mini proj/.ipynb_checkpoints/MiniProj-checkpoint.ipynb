{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b6bf1a-4cbd-401a-ba0c-09aabb06b98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy: 0.981042654028436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12,13,14,15,16]]\n",
    "\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding\n",
    "enc = OneHotEncoder()\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "\n",
    "transformed_df = pd.DataFrame(category_transformed.toarray(), columns=enc.get_feature_names_out(category_features.columns))\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Quantile Transformer\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=10, random_state=42)\n",
    "X_train_transformed = quantile_transformer.fit_transform(X_train)\n",
    "X_test_transformed = quantile_transformer.transform(X_test)\n",
    "\n",
    "# Initialize base decision tree classifier with regularization parameters\n",
    "base_estimator = DecisionTreeClassifier(max_depth=3, min_samples_split=2)\n",
    "\n",
    "# Initialize AdaBoost Classifier with the base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=base_estimator)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "ada_boost.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = ada_boost.predict(X_test_transformed)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n",
    "\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ce37a6a-486c-42c1-868c-6d8d0f90aa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy: 0.985781990521327\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2))\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Testing Set Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2f5229-048b-4ee8-8e49-83bcb5a716c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95294118 1.         0.97647059 0.98809524 1.         0.98809524\n",
      " 0.97619048 0.96428571 0.98809524 0.96428571]\n",
      "Mean CV accuracy: 0.9798459383753502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy with cross-validation: 0.990521327014218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Accuracy without cross-validation: 0.990521327014218\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2),n_estimators=64,learning_rate=0.5,algorithm='SAMME.R',random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_cv = pipeline_cv.predict(X_test)\n",
    "test_accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_cv)\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for testing without cross-validation\n",
    "pipeline_test = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set without cross-validation\n",
    "pipeline_test.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_test.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61fa0ab9-a4ad-411c-92f8-b67b2d26ebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95294118 0.98823529 0.98823529 0.98809524 0.98809524 0.97619048\n",
      " 0.98809524 0.97619048 0.97619048 0.98809524]\n",
      "Mean CV accuracy: 0.9810364145658262\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean CV accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(cv_scores))\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Test the model on the separate testing set\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m test_accuracy_test \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_test)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Set Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\compose\\_column_transformer.py:797\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform X separately by each transformer, concatenate results.\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \n\u001b[0;32m    783\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;124;03m        sparse matrices.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    798\u001b[0m     X \u001b[38;5;241m=\u001b[39m _check_X(X)\n\u001b[0;32m    800\u001b[0m     fit_dataframe_and_transform_dataframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    801\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2))\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=100, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy:\", test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd58aadb-7692-4e6b-9a95-055b950aeec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95294118 0.96470588 0.94117647 0.94047619 0.9047619  0.95238095\n",
      " 0.94047619 0.91666667 0.91666667 0.96428571]\n",
      "Mean CV accuracy: 0.939453781512605\n",
      "Testing Set Accuracy with cross-validation: 0.990521327014218\n",
      "Testing Set Accuracy without cross-validation: 0.990521327014218\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_cv = pipeline_cv.predict(X_test)\n",
    "test_accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_cv)\n",
    "\n",
    "# Create pipeline with preprocessing and Random Forest classifier for testing without cross-validation\n",
    "pipeline_test = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set without cross-validation\n",
    "pipeline_test.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_test.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29c4d9b3-6734-4a3c-8399-efa4e1011bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.91764706 0.91764706 0.95294118 0.89285714 0.89285714 0.89285714\n",
      " 0.9047619  0.9047619  0.89285714 0.94047619]\n",
      "Mean CV accuracy: 0.9109663865546217\n",
      "Testing Set Accuracy with cross-validation: 0.95260663507109\n",
      "Testing Set Accuracy without cross-validation: 0.95260663507109\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='log_loss',splitter='best',random_state=30)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_cv = pipeline_cv.predict(X_test)\n",
    "test_accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_cv)\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for testing without cross-validation\n",
    "pipeline_test = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set without cross-validation\n",
    "pipeline_test.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_test.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c379260-29db-4c12-a389-6dfc6660f9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__splitter': 'random'}\n",
      "Testing Set Accuracy with best parameters: 0.966824644549763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1680 fits failed out of a total of 3840.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "720 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1.5 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "960 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_leaf' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0). Got 1.5 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.89081232 0.88485994 0.88728291 0.89205882\n",
      " 0.88016807 0.88253501        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.89086835 0.8932493  0.89443978 0.89558824 0.88254902 0.88491597\n",
      "        nan        nan 0.88964986 0.8885014  0.88964986 0.8885014\n",
      " 0.88845938 0.89201681        nan        nan 0.88962185 0.88485994\n",
      " 0.88728291 0.89205882 0.88016807 0.88253501        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.89086835 0.8932493  0.89443978 0.89558824\n",
      " 0.88254902 0.88491597        nan        nan 0.88964986 0.8885014\n",
      " 0.88964986 0.8885014  0.88845938 0.89201681        nan        nan\n",
      " 0.89081232 0.88485994 0.88728291 0.89205882 0.88016807 0.88253501\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.89086835 0.8932493\n",
      " 0.89443978 0.89558824 0.88254902 0.88491597        nan        nan\n",
      " 0.88964986 0.8885014  0.88964986 0.8885014  0.88845938 0.89201681\n",
      "        nan        nan 0.89081232 0.88485994 0.88728291 0.89205882\n",
      " 0.88016807 0.88253501        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.89086835 0.8932493  0.89443978 0.89558824 0.88254902 0.88491597\n",
      "        nan        nan 0.88964986 0.8885014  0.88964986 0.8885014\n",
      " 0.88845938 0.89201681        nan        nan 0.9014986  0.91219888\n",
      " 0.90393557 0.90273109 0.89553221 0.89554622        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.90033613 0.90390756 0.89920168 0.90390756\n",
      " 0.89435574 0.89436975        nan        nan 0.89322129 0.89915966\n",
      " 0.89322129 0.89915966 0.89316527 0.89553221        nan        nan\n",
      " 0.90030812 0.90981793 0.90393557 0.90273109 0.89553221 0.89554622\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.90033613 0.90390756\n",
      " 0.89920168 0.90390756 0.89435574 0.89436975        nan        nan\n",
      " 0.89322129 0.89915966 0.89322129 0.89915966 0.89316527 0.89553221\n",
      "        nan        nan 0.9014986  0.91219888 0.90393557 0.90273109\n",
      " 0.89553221 0.89554622        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90033613 0.90390756 0.89920168 0.90390756 0.89435574 0.89436975\n",
      "        nan        nan 0.89322129 0.89915966 0.89322129 0.89915966\n",
      " 0.89316527 0.89553221        nan        nan 0.9014986  0.91219888\n",
      " 0.90393557 0.90273109 0.89553221 0.89554622        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.90033613 0.90390756 0.89920168 0.90390756\n",
      " 0.89435574 0.89436975        nan        nan 0.89322129 0.89915966\n",
      " 0.89322129 0.89915966 0.89316527 0.89553221        nan        nan\n",
      " 0.9014986  0.91219888 0.90393557 0.90273109 0.89553221 0.89554622\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.90033613 0.90390756\n",
      " 0.89920168 0.90390756 0.89435574 0.89436975        nan        nan\n",
      " 0.89322129 0.89915966 0.89322129 0.89915966 0.89316527 0.89553221\n",
      "        nan        nan 0.90030812 0.90981793 0.90393557 0.90273109\n",
      " 0.89553221 0.89554622        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90033613 0.90390756 0.89920168 0.90390756 0.89435574 0.89436975\n",
      "        nan        nan 0.89322129 0.89915966 0.89322129 0.89915966\n",
      " 0.89316527 0.89553221        nan        nan 0.9014986  0.91219888\n",
      " 0.90393557 0.90273109 0.89553221 0.89554622        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.90033613 0.90390756 0.89920168 0.90390756\n",
      " 0.89435574 0.89436975        nan        nan 0.89322129 0.89915966\n",
      " 0.89322129 0.89915966 0.89316527 0.89553221        nan        nan\n",
      " 0.9014986  0.91219888 0.90393557 0.90273109 0.89553221 0.89554622\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.90033613 0.90390756\n",
      " 0.89920168 0.90390756 0.89435574 0.89436975        nan        nan\n",
      " 0.89322129 0.89915966 0.89322129 0.89915966 0.89316527 0.89553221]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=100, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=35)\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid to search\n",
    "param_grid = {\n",
    "    'classifier__criterion': ['gini', 'entropy','log_loss'],\n",
    "    'classifier__splitter': ['best', 'random'],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [1.5,2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1,1.5, 2, 4],\n",
    "}\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=69)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(pipeline_cv, param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Perform Grid Search to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Test the best model on the testing set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "test_accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(\"Testing Set Accuracy with best parameters:\", test_accuracy_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e50e0c09-555d-4047-8eff-ca01eb10abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.87058824 0.92941176 0.95294118 0.92857143 0.95238095 0.91666667\n",
      " 0.89285714 0.9047619  0.9047619  0.86904762]\n",
      "Mean CV accuracy: 0.9121988795518208\n",
      "Testing Set Accuracy with cross-validation: 0.966824644549763\n",
      "Testing Set Accuracy without cross-validation: 0.966824644549763\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy',splitter='random',max_depth=None, min_samples_split=2,random_state=35)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=100, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=69)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_cv = pipeline_cv.predict(X_test)\n",
    "test_accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_cv)\n",
    "\n",
    "# Create pipeline with preprocessing and Decision Tree classifier for testing without cross-validation\n",
    "pipeline_test = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', decision_tree)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set without cross-validation\n",
    "pipeline_test.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_test.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ba591619-91be-44fc-b013-4542a7381d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.95294118 0.90588235 0.94117647 0.91666667 0.94047619 0.92857143\n",
      " 0.92857143 0.92857143 0.95238095 0.92857143]\n",
      "Mean CV accuracy: 0.9323809523809524\n",
      "Testing Set Accuracy with cross-validation: 0.9715639810426541\n",
      "Testing Set Accuracy without cross-validation: 0.9715639810426541\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define KNN classifier\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=11, weights='distance',algorithm='auto', p=2, n_jobs=3)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=100,subsample=500,random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=69)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_cv = pipeline_cv.predict(X_test)\n",
    "test_accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_cv)\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for testing without cross-validation\n",
    "pipeline_test = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set without cross-validation\n",
    "pipeline_test.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_test.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e971aa38-eb1c-4c80-af8a-ae84f34bc950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shanm\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACfLUlEQVR4nOzdd3iT5f4G8DtJ06a7dJdSaGkLWMosUDYOtqLgYMkqispQkKP8QFFAj3LUoyLI9jBkCUdxcJQigiAKlI0i0EELhW5auleavL8/2oSGrqSkfTPuz3V5HfrmzZs7adqTb5/n+T4SQRAEEBERERER0X2Rih2AiIiIiIjIErC4IiIiIiIiMgIWV0REREREREbA4oqIiIiIiMgIWFwREREREREZAYsrIiIiIiIiI2BxRUREREREZAQsroiIiIiIiIyAxRUREREREZERsLgiokaRSCRYunSp9uulS5dCIpHg9u3b4oWyUtu2bUOHDh0gl8vh5uYmdpwmoXl/UfMwt5/n06dPo2/fvnB0dIREIsGFCxeaPcP9vEcNeb0lEgnmzJnTqMchoqbH4oqItLZs2QKJRFLnfydPnhQ74n1RqVTYvHkzHnzwQbi7u8POzg6BgYGIiorCmTNnxI7XKFevXsW0adMQHByMjRs3YsOGDc3yuH/88QfGjBkDHx8f7ev44osvIjk5udHXLC4uxtKlS3HkyBHjBTVh06ZNg0QiQefOnSEIQo3b+SFaP0qlEs888wxycnLw6aefYtu2bWjTpk2t5x45ckT7++zs2bM1bp82bRqcnJyaOjIRWTAbsQMQkel55513EBQUVON4SEiICGmMo6SkBE8++SSio6MxcOBAvPHGG3B3d8f169exZ88ebN26FcnJyWjVqpXYUQ1y5MgRqNVqfPbZZ832/Vm1ahXmzp2Ltm3b4uWXX4afnx+uXLmCL774Art378ZPP/2Evn37Gnzd4uJiLFu2DADw4IMP6ty2ePFiLFy40BjxTc5ff/2FvXv34qmnnhI7ilm6du0abty4gY0bN+L555/X+35Lly7Fvn37jJbDkt+jRKQ/FldEVMOIESPQo0cPsWMY1euvv47o6Gh8+umnmDdvns5tS5YswaeffmqUx1Gr1SgvL4dCoTDK9RqSmZkJAEadDlhcXAwHB4dab/vjjz8wb9489O/fH9HR0TrnzZw5E/369cPTTz+Nv//+Gy1atDBaJhsbG9jYWN7/Zdnb2yMgIADvvPMOnnzySaub+ljfe01fjfkZ6Nq1K/73v//h3Llz6N69+309voYlvUeLiorg6Ogodgwis8RpgURkVLdv38bYsWPh4uICDw8PzJ07F6WlpTrnVFRU4N1330VwcLB2Stkbb7yBsrIy7Tnz58+Hh4eHznSpl19+GRKJBCtXrtQey8jIgEQiwdq1a+vMdOvWLaxfvx5DhgypUVgBgEwmw2uvvaYdtZo2bRoCAwNrnFfbmgrN1K0dO3agY8eOsLOzw759++Du7o6oqKga18jPz4dCocBrr72mPVZWVoYlS5YgJCQEdnZ2CAgIwIIFC3Rej9oEBgZiyZIlAAAvL68a6+DWrFmjzdSyZUvMnj0bubm5Otd48MEHER4ejrNnz2LgwIFwcHDAG2+8Uedjvvvuu5BIJNi6dWuND8XBwcH48MMPkZaWhvXr12uPa6ZaJSYmYtiwYXB0dETLli3xzjvvaL+/169fh5eXFwBg2bJl2qlbmudT32v/3//+F2FhYbC3t0efPn3w119/AQDWr1+PkJAQKBQKPPjgg7h+/XqN12/atGk1nuODDz6oM3KmmUq2Z88eLFu2DP7+/nB2dsbTTz+NvLw8lJWVYd68efD29oaTkxOioqIa/N5pSKVSLF68GH/++Se+/fbbes/VTNu993lo8lWfTqn5vv75558YNGgQHBwcEBISgq+//hoAcPToUURGRsLe3h7t27fHL7/8Uutj6vPzDADbt29HREQE7O3t4e7ujvHjx+PmzZs65xj6XgOAw4cPY8CAAXB0dISbmxueeOIJXLlyRXv7tGnTMGjQIADAM888A4lEUmPUszYvv/wyWrRoofPzUp/9+/drczg7O+PRRx/F33//rXNObe/RkpISvPLKK/D09ISzszMef/xxpKSk1PhZ1cjNzcW0adPg5uYGV1dXREVFobi4uNZMO3bsQPv27aFQKBAREYHffvutxjnnz5/HiBEj4OLiAicnJzzyyCM1pndr3ldHjx7FrFmz4O3trf1dWFBQgHnz5iEwMBB2dnbw9vbGkCFDcO7cOb1eNyJrxOKKiGrIy8vD7du3df7Lzs7W675jx45FaWkpli9fjpEjR2LlypV44YUXdM55/vnn8fbbb6N79+749NNPMWjQICxfvhzjx4/XnjNgwADk5OTofIA5duwYpFIpjh07pnMMAAYOHFhnpv3796OiogKTJ0/W6zkY6vDhw3j11Vcxbtw4fPbZZwgNDcWYMWPw3Xffoby8XOfc7777DmVlZdrnqlar8fjjj+Pf//43Ro0ahVWrVmH06NH49NNPMW7cuHofd8WKFRgzZgwAYO3atdi2bRuefPJJAJUf9GbPno2WLVvi448/xlNPPYX169dj6NChUCqVOtfJzs7GiBEj0LVrV6xYsQIPPfRQrY9XXFyMQ4cOYcCAAbVOGwWAcePGwc7ODv/73/90jqtUKgwfPhw+Pj748MMPERERgSVLlugUh5oCecyYMdi2bZvO86nLsWPH8I9//ANTp07F0qVLceXKFTz22GNYvXo1Vq5ciVmzZuH111/HiRMnMH369Hqv1ZDly5fjwIEDWLhwIaZPn469e/fipZdewvTp0xEXF4elS5fiySefxJYtW/DBBx/ofd2JEyciNDRUp9g0hjt37uCxxx5DZGQkPvzwQ9jZ2WH8+PHYvXs3xo8fj5EjR+Jf//oXioqK8PTTT6OgoKDGNfT5eX7vvfcwZcoUhIaG4pNPPsG8efNw6NAhDBw4sEYxr+97DQB++eUXDBs2DJmZmVi6dCnmz5+P48ePo1+/ftoC88UXX9QWaK+88gq2bduGN998s8HXxsXFBa+++ir27dvXYKGwbds2PProo3BycsIHH3yAt956C5cvX0b//v1rFLr3mjZtGlatWoWRI0figw8+gL29PR599NE6zx87diwKCgqwfPlyjB07Flu2bNFOla3u6NGjmDdvHiZNmoR33nkH2dnZGD58OC5duqQ95++//8aAAQNw8eJFLFiwAG+99RaSkpLw4IMPIiYmpsY1Z82ahcuXL+Ptt9/WTm986aWXsHbtWjz11FNYs2YNXnvtNdjb2+sUuER0D4GIqMrmzZsFALX+Z2dnp3MuAGHJkiXar5csWSIAEB5//HGd82bNmiUAEC5evCgIgiBcuHBBACA8//zzOue99tprAgDh8OHDgiAIQmZmpgBAWLNmjSAIgpCbmytIpVLhmWeeEXx8fLT3e+WVVwR3d3dBrVbX+bxeffVVAYBw/vx5vV6HqVOnCm3atKlxXPMcqwMgSKVS4e+//9Y5fuDAAQGAsG/fPp3jI0eOFNq2bav9etu2bYJUKhWOHTumc966desEAMIff/xRb1ZNpqysLO2xzMxMwdbWVhg6dKigUqm0xz///HMBgLBp0ybtsUGDBgkAhHXr1tX7OIJw93s3d+7ces/r3Lmz4O7urv166tSpAgDh5Zdf1h5Tq9XCo48+Ktja2mqzZ2Vl1Xhf3fs8q9O8L5OSkrTH1q9fLwAQfH19hfz8fO3xRYsWCQB0zm3Tpo0wderUGo81aNAgYdCgQdqvf/31VwGAEB4eLpSXl2uPT5gwQZBIJMKIESN07t+nT59a3z/3mjp1quDo6CgIgiBs3bpVACDs3btX5/nNnj1b+7Xm57P6c6ie79dff9V5DgCEnTt3ao9dvXpV+349efKk9rjmvbp582btMX1/nq9fvy7IZDLhvffe0znvr7/+EmxsbHSOG/JeEwRB6Nq1q+Dt7S1kZ2drj128eFGQSqXClClTajz///73vw1es/q5ubm5QosWLXSeY/XviSAIQkFBgeDm5ibMmDFD5zrp6emCq6urzvF736Nnz54VAAjz5s3Tue+0adPq/P05ffp0nXPHjBkjeHh46BzT/E4+c+aM9tiNGzcEhUIhjBkzRnts9OjRgq2trXDt2jXtsdTUVMHZ2VkYOHCg9pjmfdW/f3+hoqJC57FcXV113oNE1DCOXBFRDatXr8bBgwd1/tu/f79e9509e7bO1y+//DIA4KefftL53/nz5+uc949//AMA8OOPPwKoHMno0KGDdqrLH3/8AZlMhtdffx0ZGRmIj48HUDly0b9//3rXquTn5wMAnJ2d9XoOhho0aBDCwsJ0jj388MPw9PTE7t27tcfu3LmDgwcP6oxI/fe//8UDDzyADh066IwUPvzwwwCAX3/91eA8v/zyC8rLyzFv3jxIpXd/zc+YMQMuLi7a11jDzs6u1imM99KMbDT0Ojo7O2tf8+qqd77TTOkrLy+vc0qaPh555BGdKZyRkZEAgKeeekonp+Z4YmJiox9rypQpkMvlOtcUBKHGiFhkZCRu3ryJiooKva/97LPPGn30ysnJSWc0uH379nBzc8MDDzygfT00eYHaX5uGfp737t0LtVqNsWPH6rx/fX19ERoaWuP9q+97LS0tDRcuXMC0adPg7u6uPd65c2cMGTJE+/j3w9XVFfPmzcMPP/yA8+fP13rOwYMHkZubiwkTJug8P5lMhsjIyHp/PqOjowFUjghVp3kNa/PSSy/pfD1gwABkZ2fX+Hnq06cPIiIitF+3bt0aTzzxBA4cOACVSgWVSoWff/4Zo0ePRtu2bbXn+fn5YeLEifj9999rXHPGjBmQyWQ6x9zc3BATE4PU1NQ6MxORLstYeUlERtWrV69GN7QIDQ3V+To4OBhSqVQ7febGjRuQSqU1Otv5+vrCzc0NN27c0B4bMGCA9kPUsWPH0KNHD/To0QPu7u44duwYfHx8cPHiRUycOLHeTC4uLgBQ67QnY6htipyNjQ2eeuop7Ny5E2VlZbCzs8PevXuhVCp1iqv4+HhcuXJFu97oXprF+obQvIbt27fXOW5ra4u2bdvqvMYA4O/vD1tb2wavqylWGnodCwoKahRgUqlU50MeALRr1w4AGpxaVZ/WrVvrfO3q6goACAgIqPX4nTt3muWx1Go18vLy4OHhode1ZTIZFi9ejKlTp+K7777TTve8H61atarxRwdXV1eDXpuGfp7j4+MhCEKN8zSqF6OA/u+1ut7DAPDAAw/gwIEDRmm6MHfuXHz66adYunQpvv/++xq3a/6Io/ljx700v1tqo/ldd+/vh/q6et77HtM0hblz547OY9X2erdr1w7FxcXIysoCUDmNt67XT61W4+bNm+jYsaP2eG2/xz788ENMnToVAQEBiIiIwMiRIzFlypQaP8tEdBeLKyJqUnWNKOnTFa1///7YuHEjEhMTcezYMQwYMAASiQT9+/fHsWPH0LJlS6jVagwYMKDe63To0AFAZcvrrl27NjqzSqWq9bi9vX2tx8ePH4/169dj//79GD16NPbs2YMOHTqgS5cu2nPUajU6deqETz75pNZr3PtBuCnUlf9eISEhsLGxwZ9//lnnOWVlZYiNjW22bpP3/qW9oePVR4Xq+z7Xdv/7eSx9PPvss3j33XfxzjvvYPTo0TVuN/R92RR5782gVqshkUiwf//+Wq97755R+r7Xmotm9Grp0qW1jl6p1WoAleuufH19a9xu7O6AxnovNUZt35uxY8diwIAB+Pbbb/Hzzz/jo48+wgcffIC9e/dixIgRTZ6JyByxuCIio4qPj9f5C2hCQgLUarV26labNm2gVqsRHx+PBx54QHteRkYGcnNzdTb/1BRNBw8exOnTp7WLrAcOHIi1a9eiZcuWcHR01JkeU5sRI0ZAJpNh+/btejW1aNGiRY2F+ABqjPg0ZODAgfDz88Pu3bvRv39/HD58uMZi++DgYFy8eBGPPPKI0dpwa17D2NhYnb8wl5eXIykpCYMHD27UdR0dHfHQQw/h8OHDuHHjRq0bte7ZswdlZWV47LHHdI6r1WokJiZqR6sAIC4uDgC0743mbkNe3/dZjL/Ma0avpk2bVusoimYU497Mhr4vDdHQz3NwcDAEQUBQUJDO9/Z+VX8P3+vq1avw9PQ0WqvwefPmYcWKFVi2bFmNdu7BwcEAAG9vb4N/bjS/65KSknRGmhISEu47s2ZErbq4uDg4ODhoR8EdHBzqfP2kUqnef7jx8/PDrFmzMGvWLGRmZqJ79+547733WFwR1YFrrojIqFavXq3z9apVqwBA+3/EI0eOBFDZ6a46zchN9U5aQUFB8Pf3x6effgqlUol+/foBqCy6rl27hq+//hq9e/du8K/HAQEBmDFjBn7++WdtnurUajU+/vhj3Lp1C0DlB6q8vDydEZq0tLQGW2XfSyqV4umnn8a+ffuwbds2VFRU1OgAOHbsWKSkpGDjxo017l9SUoKioiKDHhMABg8eDFtbW6xcuVLnL97/+c9/kJeXV2+3soYsXrwYgiBg2rRpKCkp0bktKSkJCxYsgJ+fH1588cUa9/3888+1/xYEAZ9//jnkcjkeeeQRANC2dq+t4GkKwcHBOHnypE5Hx//97381Wog3p0mTJiEkJKTWDnGaD/rVW26rVCps2LChyfI09PP85JNPQiaTYdmyZTVGVwRB0LvL6L38/PzQtWtXbN26Vef9cOnSJfz888/a3yPGoBm9+v7773HhwgWd24YNGwYXFxe8//77NbpsAtBOwavNsGHDAFRuiVBdbb+DDHXixAmdLoc3b97E999/j6FDh0Imk0Emk2Ho0KH4/vvvdabdZmRkYOfOnejfv3+9UxqByvdWXl6ezjFvb2+0bNlS760GiKwRR66IqIb9+/fj6tWrNY737du3wb/oJyUl4fHHH8fw4cNx4sQJbN++HRMnTtROhevSpQumTp2KDRs2IDc3F4MGDcKpU6ewdetWjB49ukZr5gEDBuCrr75Cp06dtH+57969OxwdHREXF9fgeiuNjz/+GNeuXcMrr7yCvXv34rHHHkOLFi2QnJyM//73v7h69ap28f/48ePxf//3fxgzZgxeeeUVFBcXY+3atWjXrp3B+7uMGzcOq1atwpIlS9CpUyed0ToAmDx5Mvbs2YOXXnoJv/76K/r16weVSoWrV69iz549OHDggMFT7Ly8vLBo0SIsW7YMw4cPx+OPP47Y2FisWbMGPXv2xKRJkwy6XnUDBw7Ev//9b8yfPx+dO3fGtGnT4Ofnh6tXr2Ljxo1Qq9X46aefamwgrFAoEB0djalTpyIyMhL79+/Hjz/+iDfeeEP7l3Z7e3uEhYVh9+7daNeuHdzd3REeHo7w8PBG563P888/j6+//hrDhw/H2LFjce3aNWzfvl1bxIhBJpPhzTffrLXpQ8eOHdG7d28sWrQIOTk5cHd3x1dffWVQ4wxDNfTzHBwcjH/+859YtGgRrl+/jtGjR8PZ2RlJSUn49ttv8cILL+js6WaIjz76CCNGjECfPn3w3HPPoaSkBKtWrYKrq6ve+1PpS7P26uLFizojYi4uLli7di0mT56M7t27Y/z48fDy8kJycjJ+/PFH9OvXT+ePBtVFRETgqaeewooVK5CdnY3evXvj6NGj2hHb+xmpDQ8Px7Bhw/DKK6/Azs5OW8BVL8r/+c9/4uDBg+jfvz9mzZoFGxsbrF+/HmVlZfjwww8bfIyCggK0atUKTz/9NLp06QInJyf88ssvOH36ND7++ONGZyeyeKL0KCQik1RfK3bc06oZdbQSvnz5svD0008Lzs7OQosWLYQ5c+YIJSUlOo+jVCqFZcuWCUFBQYJcLhcCAgKERYsWCaWlpTUyrV69WgAgzJw5U+f44MGDBQDCoUOH9H5+FRUVwhdffCEMGDBAcHV1FeRyudCmTRshKiqqRpv2n3/+WQgPDxdsbW2F9u3bC9u3b6+zHXh9rYrVarUQEBAgABD++c9/1npOeXm58MEHHwgdO3YU7OzshBYtWggRERHCsmXLhLy8vHqfU22t2DU+//xzoUOHDoJcLhd8fHyEmTNnCnfu3NE5Z9CgQULHjh3rfYza/Pbbb8ITTzwheHp6CnK5XGjdurUwY8YM4fr16zXO1bS3vnbtmjB06FDBwcFB8PHxEZYsWaLTKl4QBOH48eNCRESEYGtrq/Me0/e1T0pKEgAIH330kc7xutp1f/zxx4K/v79gZ2cn9OvXTzhz5kydrdjvva/m5+X06dM6x+v7ntT2utxLqVQKwcHBtT6/a9euCYMHDxbs7OwEHx8f4Y033hAOHjxYayv22r6vbdq0ER599NEax+99LEN+ngVBEL755huhf//+gqOjo+Do6Ch06NBBmD17thAbG9tgpvr88ssvQr9+/QR7e3vBxcVFGDVqlHD58mWdcxrbiv1emudc2/fk119/FYYNGya4uroKCoVCCA4OFqZNm6bTDr2292hRUZEwe/Zswd3dXXBychJGjx4txMbGCgCEf/3rXzXue+97prb2+5rv1fbt24XQ0FDBzs5O6Natm873X+PcuXPCsGHDBCcnJ8HBwUF46KGHhOPHj9f6GPe+j8vKyoTXX39d6NKli+Ds7Cw4OjoKXbp00W6PQUS1kwhCM6ySJCIiqzVt2jR8/fXXKCwsFDsKkeguXLiAbt26Yfv27Xj22WfFjkNERsY1V0RERERN4N51iUDlelOpVIqBAweKkIiImhrXXBERERE1gQ8//BBnz57FQw89BBsbG+zfvx/79+/HCy+80CzbLBBR82NxRURERNQE+vbti4MHD+Ldd99FYWEhWrdujaVLl9bYkoGILAfXXBERERERERkB11wREREREREZAYsrIiIiIiIiI+Caq1qo1WqkpqbC2dn5vjb5IyIiIiIi8yYIAgoKCtCyZUtIpfWPTbG4qkVqaiq7+BARERERkdbNmzfRqlWres9hcVULZ2dnAJUvoIuLi6hZlEolfv75ZwwdOhRyuVzULBqmmAkwzVzMpB9m0g8z6YeZ9MNM+jHFTIBp5mIm/TCTfkwpU35+PgICArQ1Qn1MorhavXo1PvroI6Snp6NLly5YtWoVevXqVeu5SqUSy5cvx9atW5GSkoL27dvjgw8+wPDhw2s9/1//+hcWLVqEuXPnYsWKFXrl0UwFdHFxMYniysHBAS4uLqK/sTRMMRNgmrmYST/MpB9m0g8z6YeZ9GOKmQDTzMVM+mEm/ZhiJn2WC4ne0GL37t2YP38+lixZgnPnzqFLly4YNmwYMjMzaz1/8eLFWL9+PVatWoXLly/jpZdewpgxY3D+/Pka554+fRrr169H586dm/ppEBERERGRlRO9uPrkk08wY8YMREVFISwsDOvWrYODgwM2bdpU6/nbtm3DG2+8gZEjR6Jt27aYOXMmRo4ciY8//ljnvMLCQjz77LPYuHEjWrRo0RxPhYiIiIiIrJio0wLLy8tx9uxZLFq0SHtMKpVi8ODBOHHiRK33KSsrg0Kh0Dlmb2+P33//XefY7Nmz8eijj2Lw4MH45z//WW+OsrIylJWVab/Oz88HUDkcqVQqDXpOxqZ5fLFzVGeKmQDTzMVM+mEm/TCTfphJP8ykH1PMBJhmLmbSDzPpx5QyGZJBIgiC0IRZ6pWamgp/f38cP34cffr00R5fsGABjh49ipiYmBr3mThxIi5evIjvvvsOwcHBOHToEJ544gmoVCptgfTVV1/hvffew+nTp6FQKPDggw+ia9euda65Wrp0KZYtW1bj+M6dO+Hg4GCcJ0tERERERGanuLgYEydORF5eXoP9GEyioYUhPvvsM8yYMQMdOnSARCJBcHAwoqKitNMIb968iblz5+LgwYM1RrjqsmjRIsyfP1/7taYjyNChQ02iocXBgwcxZMgQk1nMZ4qZANPMxUz6YSb9MJN+mEk/zKQfU8wEmGYuZtIPM+nHlDJpZrXpQ9TiytPTEzKZDBkZGTrHMzIy4OvrW+t9vLy88N1336G0tBTZ2dlo2bIlFi5ciLZt2wIAzp49i8zMTHTv3l17H5VKhd9++w2ff/45ysrKIJPJdK5pZ2cHOzu7Go8ll8tF/2ZqmFIWDVPMBJhmLmbSDzPph5n0w0z6YSb9mGImwDRzMZN+mEk/ppDJkMcXtaGFra0tIiIicOjQIe0xtVqNQ4cO6UwTrI1CoYC/vz8qKirwzTff4IknngAAPPLII/jrr79w4cIF7X89evTAs88+iwsXLtQorIiIiIiIiIxB9GmB8+fPx9SpU9GjRw/06tULK1asQFFREaKiogAAU6ZMgb+/P5YvXw4AiImJQUpKCrp27YqUlBQsXboUarUaCxYsAFC5AXB4eLjOYzg6OsLDw6PGcSIiIiIiImMRvbgaN24csrKy8PbbbyM9PR1du3ZFdHQ0fHx8AADJycmQSu8OsJWWlmLx4sVITEyEk5MTRo4ciW3btsHNzU2kZ0BERERERGQCxRUAzJkzB3PmzKn1tiNHjuh8PWjQIFy+fNmg6997DSIiIiIiImMTfRNhIiIiIiIiS8DiioiIiIiIyAhYXBERERERERkBiysiIiIiM6JSC4hJysHZ2xLEJOVApRbEjmSS+DqZL3P+3plEQwsiIiIialj0pTQs23cZaXmlAGT4Mv4M/FwVWDIqDMPD/cSOZzL4Opkvc//eceSKiIiIyAxEX0rDzO3nqj503pWeV4qZ288h+lKaSMlMC18n82UJ3zsWV0REREQmTqUWsGzfZdQ2OUpzbNm+y2Y1faop8HUyX5byvWNxRURERGTiTiXl1PhrfnUCgLS8UpxKymm+UCaIr5N5yS9V4lzyHew5fRNzvzpvEd87rrkiIiIiMmEFpUrsiLmh17mZBXV/OLUG+j7/XaeS4e9mj9YeDk2ciAAgu7AMCZmFiM8sRELVf/GZBcjILzP4Wqb+HmdxRURERGSC8oqV2Hw8CZv/uI68EqVe9/F2VjRxKtPm5WSn13k/XEzFDxdTEe7vghHhfhjZyQ9Bno5NnM40Ve/M55GUgz4h3pBJJQZfRxAEZOSXaQun6oVUTlF5nffzcbFDqLczHO1kOPB3RoOPY+rvcRZXRERERCbkTlE5/vN7ErYev46CsgoAQFtPB+QUKZFXoqx1TQoA+LrYoVeQe/MFNTEqtYBvzt1q8DxXezk6tnTGycQcXErJx6WUfHx0IBYP+LlgZLgvRnTyQ4i3UzMkFl9jOvOp1QJScku0RZR2RCqjUPt+rU2rFvYI9XZCiLcTQr2dEeLjhGAvJ7jaywFUfv/6f3AY6Xmltb7HJQB8XRUm/x5ncUVERERkAm4XlmHjsURsP3EDReUqAEB7H2e8/EgIRoT74eDldMzcfg4SoNYPn3ZyGQrLKrQfVq2JSi3gtf9exLfnUyCVAGoBNV4nzVjMB091wvBwP2QXluHg5Qz8+Fcajl/LxpW0fFxJy8fHB+PQ3scZIzr5YmQnP7TzcRbhGTU9TWe+e99Lms58n0/shgf8XGpM5buWWYQSparWa8qkErRxd6gsoHzuFlJtvRzhYFt/2SGTSrBkVFit73HN927JqLBGjao1JxZXRERERCLKzC/F+t8SsSPmBkqVagBAmJ8LXnkkFEPDfCCt+jA5PNwPayd1rzbSUMnTyRbF5SrcyC7GpC9isO25XnBzsBXluYihQqXGq3suYt/FVNhIJfhsfDfIpKjxOvneMyLj4WSH8b1aY3yv1rhTVI6DVzLw019p+CPhNmIzChCbUYAVv8QjxNtJO6LVwdcZEolpf7jXhz6d+WbvPF/n/W1lUgR5OiLEx0lnNCrQ0wF2NrJG56rrPX7v986UsbgiIiIiEkFaXgnWHbmGXadvoryisqjq0soVrzwSioc7eNf6IX54uB+GhPniREImfj4Wg6EDItEnxBux6QWY9J8Y/JWSh2e/iMH25yLRwtHyCyylSo15X13Aj3+lwUYqwecTu2N4uC8A1Po61TXq0cLRFmN7BGBsjwDkFSvxS1WhdSz+NhIyC7HycAJWHk5AW09HjOjkixHhfujY0sWsCq1SpQqJWUWIzyzAr1cz6+3Mp2Erk6K9rzNCqgqoyiLKCa3dHWAja5qm43W9x019xEqDxRURERFRM7qZU4y1R6/h6zO3UK6qLKoi2rTAK4+EYmCoZ4Mf2GVSCSKD3JF9RUBkkDtkUgnCWrpg14zeePaLk/g7NR8TNp7Ejucj4aFngwdzVF6hxsu7zuHA3xmQyyRY82wEhoT5aG+v7XXSh6uDHE9FtMJTEa2QX6rE4SuZ+OmvNByJy0Li7SKs/vUaVv96Da3dHTCiky8e7eSHTv6uJlNolZSrdJpKxGcUIiGzAMk5xTB0i6gPn+6M0d38myZoPRr7vTMFLK6IiIiImsH120VYcyQBe8+loKLqU27vtu545eFQ9An2uO8P5+19nfHVC70xYWMMrqYXYOLGGOyYEQlPCyywyipUmL3jPH65kgFbmRTrJnfHwx18Gr6jgVwUcozu5o/R3fxRWFaBw1czsf+vNPwam4nknGKsP5qI9UcT4e9mj5FVa7S6BrjV+b00Vmc+ACgsq6gsojLuNpWIzyzArTslEOooolzt5Wjn4wRnhRyHr2Y2+Bg+Lqbdmc8UsbgiIiIiakLXsgqx+nACvruQoh05GBDqiZcfDjV657MQ76oCa8NJxGYUYMKGk9gxI9Lk21cbolSpwqwd53D4aiZsbaTYMDkCD7b3bvLHdbKzweNdWuLxLi1RVFaBI7FZ+OlSGg5fyURKbgk2HkvCxmNJaOmqwPBwP4zs5IvurVto18w1pjMfAOSVKKsaShQgPuPuXlEpuSV13sfD0VbbVKKdj7N2TZSnky0kEonFdOYzRSyuiIiIiJpAbHoBPv81Af/7M1U7kvBQey+8/Egourdu0WSPG+zlhN0v9sGEDScRn1mI8RtOYteM3hYxClGqVOHFbWdxNC4LdjZSfDG1BwaEejV7Dkc7Gzza2Q+PdvZDSbkKR+My8dNf6Th0JQOpeaXY9EcSNv2RBB8XO4wI94O7oy0+PRhXZ2e+tZO6o3dbD+00Pk2L87iM+jfa9XK2Q2jVOqhQH2dtc4mGpoNaSmc+U8TiioiIiMiI/k7Nw+eHE7D/Urr22JAwH7z8cAg6t3JrlgxBno7Y/WJvTNwYg8SsIozfcBI7Z0TCz9W+WR6/KZSUq/DCtjM4Fn8b9nIZ/jO1B/qGeIodC/a2MgwP98PwcD+UKlX4LS4L+y+l45fLGcjIL8OW49frvK+mqJm141y966F8XRQI9akcfQqt1qHvfrpCWkJnPlPE4oqIiIjICP68lYuVhxLwy5UMAIBEAowI98Wch0IR1tKl2fO08XCsWoN1Ekm3izBu/UnseqE3/N3Mr8AqLq/A81vP4Pi1bDjYyrBpWk/0bushdqwaFHIZhnb0xdCOviirUOH3+NvYevw6fou/Xe/9NIWVv5u9tnjSbLQb4u0EF0XT7F1m7p35TBGLKyIiIqL7cPbGHaw6HI8jsVkAKouqUZ1bYs7DIaJvQBvg7oCvXqgcwUrOKca49Sewa0ZvBLg7iJrLEEVlFZi+5TRiknLgaCvDlum90DPQ9NcC2dnI8MgDPigsq2iwuAIqO/ON7RHQDMl0mXNnPlPE4oqIiIioFg11dotJzMbKw/H4IyEbQOWH1Ce6tsTsh0IQ7OUkVuwaWrXQFFgncT27WLsGq7WH6RdYhWUViNp8Cqev34GTnQ22Tu+FiDZNt16tKejbTCSghel/P6hhLK6IiIiI7lFXZ7e3HwuDi70cKw/FIyYpBwBgI5Xgqe6tMOuhYLTxcBQ3eB1autnjqxf6YOLGk0i8XYRxGypHsAI9TTMvABSUKjF10ymcS86Fs8IG256LRNcAN7FjGaxXkDv8XBXszGclWFwRERERVRN9KQ0zt5+r8UE4La8UM3ec035tK5PimR6tMPPBYLQyg1EHX1dF5QjWFzFIyCzUFlhtTWiUTSOvpLKwunAzF672cmx/LhKdWrmKHatR2JnPukjFDkBERERkKlRqAcv2Xa51hKG6KX3a4OiCB/HemE5mUVhpeLsosGtGb7TzcUJGfhnGbTiJhMxCsWPpyC0ux+T/xODCzVy4Ocix43nzLaw0NJ35fF11pwj6uiqwdlJ3duazIBy5IiIiIqpyKilHpy11XUaE+5ltW3MvZzvsmtEbz34Rg6vpBdo27WI33wCAO0XlmPSfGPydmg93R1tsfy5SlE6LTYGd+awDR66IiIiIqmQWNFxYGXKeqfJwssPOGb0R5ueC24VlmLDhJK6m54uaKbuwDBM2nsTfqfnwcLTFrhm9Laaw0tB05ovwZGc+S8XiioiIiKiKvp3d9D3PlLk72mLnjEiE+7sgu6gcEzacxN+peaJkuV1YhokbK0fSPJ3s8NULvdHeV/yRNCJDsbgiIiIiqtIryB2+LnZ13i4B4GdBnd3cHGyx47ne6NLKFXeKlZi4MQaXUpq3wMosKMWEDScRm1EAb+fKwirUBKYoEjUGiysiIiKiKjKpBEGetXfPs9TObq4Ocmx7PhLdWrshr0SJiRtP4uLN3GZ57Iz8UozfcBLxmYXwdVFg94t9EOJtet0LifTF4oqIiIioyp4zN3EiMRsSVE6bq86SO7u5KOT4cnov9GjTAvmlFZj0RQzOJd9p0sdMyyvB+A0nkZhVhJauCux+sTeCTHjfLSJ9sLgiIiIiAnAlLR9vfXcJAPCPoe1w+s3B2D69B6aEqrB9eg/8/n8PW2RhpeGskGPr9F7oFeSOgrIKTPnPKZy9kdMkj5WSW4Jx608i6XYR/N3ssfvFPia7ATORIVhcERERkdUrKFVi9o5zKKtQY1A7L8x6MMQqO7s52tlgS1RP9GnrgcKqAutUknELrJs5xRi3/gSSc4oR4G6P3S/2RoC7+ewVRlQfFldERERNSKUWEJOUg7O3JYhJyoFK3dD2tNTcBEHAwr1/IfF2EfxcFfh0XFdIraCQqouDrQ02TeuJ/iGeKCpXYeqmUzhxLdso107OLsb4DSdx604JAj0csPuFPma1CTNRQ1hcERERNZHoS2no/8FhTNp0Bl/GyzBp0xn0/+Awoi+liR2Nqtl28gZ+/DMNNlIJPp/YvcZaK2tkbyvDF1N7YGA7L5QoVYjacgp/JNy+r2tev12E8RtOICW3BG09HfHVC33Q0s08N2ImqguLKyIioiYQfSkNM7efQ1qe7maz6XmlmLn9HAssE3HxZi7e/d9lAMCikQ8gok0LkROZDoVchg2TI/BQey+UKtWYvuU0fovLatS1ErMKMX7DSaTmlSLYyxFfvdAbvq7mv1cY0b1YXBERERmZSi1g2b7LqG0CoObYsn2XOUVQZLnF5Zi14xyUKgHDO/pier9AsSOZHIVchnWTIzD4AW+UVajx/Jdn8GtspkHXSMisLKzS80sR6u2Er17oA28XFlZkmVhcERERGdlvcVk1RqyqEwCk5ZUavVEA6U+tFvCPPReRkluCNh4O+PCZzpBIrHedVX3sbGRY82wEhob5oLxCjRe/PItfLmfodd+4jAKM33ASmQVl6ODrjF0v9IaXc92bNBOZOxuxAxAREZmrglIl4jMLkZBRiPjMAsRnFiI+oxApuSV63T+zoO4CjJrWhmOJOHQ1E7Y2Uqye2B0uCrnYkUyarY0Uq5/tjrlfncdPf6Vj5o6z+Hxidwzr6Fvnfa6m5+PZjTHILipHmJ8Ltj8fyfVsZPFYXBER3aN6dzePpBz0CfG2ihbMlqCpvnd5xUqd4ik+swAJmYX1jk7pw9uZU6PEcCopBx8diAUALB3VEeH+riInMg9ymRQrx3eDTHoR+y6mYvaOc1g1oRtGdPKr8bPn6qDAlE0xuFOsRLi/C7Y/Fwk3BxZWZPlYXBERVRN9KQ3L9l2u+tAsw5fxZ+DnqsCSUWEWvXmoJTDG9y6nqBzxGZVFVEJm1WhURiEyC8rqvI+Pix1CvZ0R4u2EUB8nhHo7o62nI0Z9/jvS80prXXcFAN7OdugV5G74E6X7cruwDC/vOgeVWsCYbv6Y0CtA7EhmxUYmxadju0AmAb67kIo5u84jKvkOfvwzTednTyIBBAHo0soVX06PhKsDRwbJOrC4IiKqounudu+HYU13t7WTurPAMlGGfO8EQcDtwnLt6FN8RiHiMir/nV1UXudjtHRVIMTHGaHeTpX/+TghxNsZrva1f2hcMioMM7efgwSotcBSqQWk5pZw89RmpFILmPvVeWTklyHU2wnvjQnnOqtGsJFJ8fHYyr3A9p5LwRfHkmqcI1S96af2DWRhRVaFxRURERru7iZBZXe3IWG+nCJoYvTpzLfg6z/xa2wWErMKEZ9ZiNxiZZ3Xa9XCvqp4qhyNaufjjGAvRzgbuCZneLgf1k7qXm00rZK3sx0EQUBWYTnGbziJXTN6o7UHC6zmsPJQPP5IyIa9XIY1z3aHgy0/BjWWTCrBv57sjP1/paNEqar1HAmAjw7E4omu/vy9SVaDv1WIiFC5BkPf7m59gj2aLxg1KCYxu8G1T/mlFdh9+qb2a4kEaO3ugFDvytGndlXT+YK9HY36gXt4uB+GhPniREImfj4Wg6EDItEnxBu3C8swYcNJJN4uwrgNJ7BzRm8EeToa7XGppt/isrDycDwAYPmTnRDq4yxyIvN39sadOgsrgL83yTqxuCIigv5d29jdTTzlFWrcyC6qWgtVuSZKsy5KH0PCvPFY55YI8XZCsJcTFHJZEyeuJJNKEBnkjuwrAiKD3CGTSuDjosBXL/bGxI0xSMgsxLj1J7Drhd4I9nJqlkzWJi2vBPN2X4AgABMjW2N0N3+xI1kE/t4kqonFFRER9O/axu5udzVVZ77i8gpcyyzSrolKyCxEQlYhbmQX39emu9P7tTWpv557Oyvw1Qu98ezGGMRmFGDc+pPYNSOSIypGplSp8fLO88gpKkfHli54+7EwsSNZDP7eJKqJxRUREYBeQe7wc1XUO73Mx4Xd3TSM0ZnvTlE5ErIqG0poCqhrmfXvEeVoK6scefJ2Qoi3E0K8nBDk6YjJ/zmFjPzaO/NJAPi6Kkzye+fpZIddL/TGs1/E4EpaPsZvOImdM3qjvS8LLGP56EAszty4A2eFDdY8273ZRiytgeb3Zl1dMU35Z4+oqbC4IiJC5dStOQ+H4M1vL9V5jlQiQU5RObyc7ZoxmekxtDNfen6ptitfQlZlIXWtgc58Ho62OgVUSNW//VwVtXZ3W/p47Z35NGcuGRVmsgvq3R1tsWtGJCb9JwaXUvIxfsMJ7Hi+N8Jauogdzez9/Hc6NvyWCAD46OkuaOPBdW3GJJNK6uyKaQ4/e0RNgcUVEVGVv1PzAQC2MinKVWrtcS9nOygr1EjLK8X4DSewa0ZveLtY5zQXfTrzvf71nzjwdzoSs4pwLasIhWUVdV7P382+soiqVkCFeDvB3dGwzUbr6sznayZ7lLk52GLHc70xZVMMLt7Kw8QvTmL7c5Hc3PY+JGcX4x//vQgAeK5/EIaH+4qcyDKZ+88ekbGxuCIiAnAzpxh7qrrJfTm9FypUFTrd3W7dKcaEDSdxLatIO3XL19X6CqyGuioCQEFpBb49n6r9WiaVoI2HQ40CKtjLCY52Td+Zz1z+au7qIMe25yMxddMpnE/OxcSNJ7HtuUh0CXATO5rZKVWqMHvnORSUVqB7azcsHNFB7EgWzdx/9oiMicUVERGAVYfjUaEWMCDUE72DPaBUKnW6u7XxcMTuF/tgfLX22btm9EZLN3uxozcrfbt+jQz3xWNdKjvzBXo4wtZG2sTJKtXWmc+cuCjk+HJ6L0RtPo0zN+5g0hcx2PpcL3Rv3ULsaGblnz9exl8peWjhIMfnE7tDLmue9581M/efPSJj4W8bIrJ6128X4ZtzKQCAeYPb1XlegLsDdr/YGwHu9riRXYxxG07g1p3i5oppEvTt+jW5TyBGdvJDOx/nZiusLIWzQo6t03uhV5A7CsoqMOU/p3Dmeo7YsczG9xdSsP1kMiQS4NNxXa3uDyBEJC7+Px4RWb2Vh+OhUgt4sL0XItrUP0LQqoUDdr/QB208HHAzpwTj1p/EzRzrKbDS8+ru5AdULmL3Y3ew++ZoZ4MtUT3RN9gDhWUVmLLpFGISs8WOZfISMguxaO9fAIA5D4XgwfbeIiciImvD4oqIrNq1rEJ8d75y1OrVekatqmvpZo/dL/RBkKcjUnJLMG79CdzILmrKmKJTqQUs338Fr+65qD1276QfdgczLgdbG/xnak8MCPVEcbkK0zafxvGE22LHMlnF5RWYteMsistV6NPWo95RaCKipsLiiois2spD8VALwOAHvA1qHODrqsDuF3oj2MsRqXmlGLf+JJJuW2aBlVeixHNbT2P90cqW1rMeDMaaid1rNPTwdVXotGGn+2dvK8PGKT0wqJ0XSpQqRG05jWPxWWLHMjmCIGDxd5cQl1EIL2c7fDahKwt8IhIFiysislrxGQX44WJlV7vG/JXb20WBXS/0Rqi3E9LzSzFu/Qlcyyo0dkxRJWQWYszqP3AkNgsKuRQrJ3TDguEdMLKzH37/v4exfXoPTAlVYfv0Hvj9/x5mYdUEFHIZNkyJwCMdvFFWocZzW8/g19hMsWOZlD1nbmLvuRRIJcCqCd30XhtIRGRsLK6IyGqtOBQPQQCGd/Rt9H5C3s6VBVZ7H2dkFpRh3PqTiM8oMHJScRy+moExq/9A4u0itHRV4OuX+uLxLi21t2u6g0V4sjtYU7OzkWHtpAgMDfNBeYUaL355FoeuZIgdyyRcTs3H29//DQB4bVh79G7rIXIiIrJmLK6IyCpdTc/Hj3+mAQDmDQm9r2t5Otlh1wu98YCfC24XlmH8hpOITTffAksQBKw5koDntp5BQVkFega2wA8v9+eGtiKztZFi9bPdMSLcF+UqNV7afhYH/k4XO5aoCkqVmLXjLMoq1HiovRdeGhgsdiQisnIsrojIKq04GA8AeLSzHzr4utz39dwdbbFrRiTC/V2QXVSOCRtP4nJq/n1ft7mVlKvwylcX8GF0LAQBmBjZGjue7w1PJzuxoxEAuaxyauZjnf2gVAmYveMcfvorTexYohAEAf/3zZ+4nl0Mfzd7fDK2K6QcPSUikbG4IiKrcyklD9F/p0MiAeY9cn+jVtW5Odhix3O90bmVK3KKyjHxi5O4lJJntOs3tZTcEjy97jj2XUyFjVSCf44Ox/tjOnGfKhMjl0mxYlxXjO7aEhVqAS/vOo99VWsHrcmW49fx01/pkMsk+HxiN7RwtBU7EhERiysisj4rfqkctXq8S0uE+jgb9dquDnJsey4SXQPckFusxMSNJ/HnrVyjPkZTOJWUg8dX/Y6/U/Ph7miLHc9HYlLvNmLHojrYyKT4eGxXPB3RCiq1gLlfndduKWANziffwfs/XQEAvDHyAXRrXf/+dEREzYXFFRFZlYs3c/HLlQxIJcArRhy1qs7VXo5tz/VCRJsWyC+twLNfxOB88p0meSxj2BFzAxM3nkR2UTnC/Fzww5x+iGRTAJMnk0rw4VOdMb5nANQC8OqeC/j67C2xYzW5O0XlmLPzPJQqAY928sO0voFiRyIi0mJxRURW5dNf4gAAo7v5I9jLqckex1khx9bpvdAr0B0FpRWY/J9TOHsjp8kerzHKK9RY/N1fePPbS6hQC3i0sx++ntkHrVo4iB2N9CSVSvD+mE54NrI1BAF4/euL2H06WexYTUatFjB/zwWk5JYg0MMB/3qqEyQSrrMiItPB4oqIrMbZG3dwJDYLMqkErzzcNKNW1TnZ2WDL9J7o3dYdhWUVmPKfUzh93TQKrNuFZZj0nxhsP5kMiQR4fVh7fD6hGxxsbcSORgaSVq2Pm9qnDQQB+L9v/sKOmBtix2oS6367hl9js2BnI8WaZyPgrJCLHYmISAeLKyKyGiuqRq2e6u6PQE/HZnlMB1sbbJ7WC/1CPFBUrsLUTadwMjG7WR67LpdS8vDE53/gVFIOnOxs8MWUHpj9UAhHAMyYRCLB0sc7Ynq/IADAm99ewpcnrosbyshOJmbj3wdiAQDvPNERYS3vv8snEZGxsbgiIqtwKikHx+Jvw0YqwcvNMGpVnb2tDP+Z2hMDQj1RXK7CtM2ncDzhdrNm0Nh3MRVPrzuOlNwSBHk64rvZffHIAz6iZCHjkkgkeOuxB/DiwLYAgLe//xv/+T1J5FTGkVlQipd3nYdaAJ7q3gpjewSIHYmIqFYsrojIKnx6sHLUamzPAAS4N/+aIoVcho1TemBQOy+UKtWI2nIax+Kzmu3x1WoBHx24ipd3nUepUo2B7bzw3ax+CPE2brdEEpdEIsHCER0w+6HKzXTf/d9lbPjtmsip7o9KLWDurgvIKihDOx8nvDu6I0dZichksbgiIot3/NptnEjMhq1MitkPhYiWQyGXYcOUCDzcwRtlFWo8t/UMjsRmNvnj5pcqMePLM1j9a+WH7BcHtsXmaT3h6sD1KpZIIpHgtaHtMbeqG+b7P13F6l8TRE7VeCt+icOJxGw42sqw5tkIrgskIpPG4oqILJogCFhxsHJfq/G9AuDvZi9qHjsbGdZNisCQMB+UV6jxwpdncfhqRpM9XmJWIcas/gOHrmbC1kaKT8d1waKRD0Am5V/+LZlEIsGrQ9ph/pB2AICPDsTis6r93czJkdhMrDpcWRi+/2QnhHg3XYdPIiJjYHFFRBbtj4RsnLqeA1sbKWY9KN6oVXW2NlKsebY7RoT7olylxovbzuLgZeMXWEdiM/HE6j9wLasIvi4KfP1SH4zp1sroj0Om65VHQrFgeHsAldsQfPJzLARBEDmVflJzS/Dq7gsAgEm9W+OJrv7iBiIi0gOLKyKyWIIg4JODld3Fno1sDV9XhciJ7pLLpFg5oRse7ewHpUrAzO1nEX0p3SjXFgQBG367hulbTqOgtAIRbVrgh5f7oXMrN6Ncn8zLrAdD8ObIBwAAKw8n4KMDsahQqRGTlIOztyWIScqBSi1+waVSC9pMfyTcxuwdZ3GnWIlO/q5467EwseMREemFE5eJyGIdjcvCueRcKORSzHwwWOw4NchlUnw2ritkEgl+uJiK2TvPYeX4yoKrsUqVKiz85k98dyEVADCuRwDeGd0RdjYyY8UmMzRjYFvIpBK887/LWHPkGrYev46ichUAGb6MPwM/VwWWjArD8PDGv/fuR/SlNCzbdxlpeaVVmc4BABTyylFevn+JyFxw5IqILFLlqFVlh8DJvdvA29l0Rq2qs5FJ8em4rniymz9UagGvfHUe319IadS10vJK8My6E/juQipkUgmWPd4R/3qqEz+YEgBgev8gjO9Z2cK8srC6Kz2vFDO3n0P0pbRmzxV9KQ0zt5+rKqx0lSrV+Ds1r9kzERE1FkeuiMgiHbqSiT9v5cFeLsOLg0xv1Ko6mVSCj57pAqlUgq/P3sKruy9ALQgGrY86eyMHL247h9uFZWjhIMfqZ7ujb7BnE6Ymc6NSCzgaV3v7f82kwP/75i/kFishbaZW52pBwPL9V1HXpEQJgGX7LmNImC+bsBCRWWBxRUQWp/qo1dS+gfB0shM5UcNkUgk+fKozbKQSfHX6JubvuQiVGng6ouECa/fpZCz+7hKUKgEdfJ2xcUoPUfbyItN2Kimn1tGh6vJKlFi4969mStQwAUBaXilOJeWgT7CH2HGIiBrE4oqILM6BvzNwOS0fjrYyvDCwrdhx9CaVSvD+mE6QSSXYEZOM17++CJVajXE9W+ss9vdIykGfEG+oBQH//N9lbD1xAwAwItwX/36mCxzt+KudasosqL+w0ujY0gW+Ls0zjTY9vxR/p+Y3eJ6+2YmIxMb/ByYii6JWC1jxS+Wo1fT+QXB3tBU5kWGkUgn+OTocNlIJtp64gf/75i9cvJmLX2Ozqi32PwNvZzu4OcgRl1EIAJg/pB3mPBQCKadOUR30XXe4+NGwZhslOnEtGxM2nmzwPFNdM0lEdC8WV0RkUfZfSsfV9AI429ng+f7mM2pVnUQiwdLHO0IqlWDzH9ex89TNGudkFpQhs6AMdjZSrJrQDUM7+oqQlMxJryB3+LkqkJ5XWusaJwkAX1cFegW5W3UmIqL7wW6BRGQxVNVGrZ4bEARXB7nIiRpPIpHgzZEPwNG2/k5/Lgo5HnnAp5lSkTmTSSVYMqpyv6h7xzc1Xy8ZFdasjSNMMRMR0f1gcUVEFuN/f6YiPrMQLgobTO8fJHac+3b6+p0aLbPvlVVYhlNJOc2UiMzd8HA/rJ3UvcaG2r6uCqyd1F2Ufa5MMRMRUWNxWiARWYQKlRqf/RIPAHhhYFu4KMx31EpD30X8XOxPhhge7ochYb44kZCJn4/FYOiASPQJ8RZ1dMgUMxERNQaLKyKyCD9cTEXi7SK4OcgxrZ/5j1oB+i/i52J/MpRMKkFkkDuyrwiIDHI3iSLGFDMRERmK0wKJyOxVqNT47FDlqNWLA4PhZCGtyDWL/ev6iCkB4MfF/kRERCaDxRURmb2951NwI7sYHo62mNKnjdhxjIaL/YmIiMwLiysiMmvlFWqsrBq1emlQsMVtoMvF/kRERObDsj6FEJHV+frsLdy6UwIvZztM6m05o1bVcbE/ERGReWBxRURmq6xChc8PV45azXowGPYN7AllzrjYn4iIyPRxWiARma09p28iNa8UPi52mNCrtdhxiIiIyMqxuCIis1SqVOHzXxMAAHMeCoFCbrmjVkRERGQeWFwRkVnadSoZGfllaOmqwNieAWLHISIiImJxRUTmp6RchTVHrgEA5jwcCjsbjloRERGR+FhcEZHZ2RFzA1kFZWjVwh5PR7QSOw4RERERABMprlavXo3AwEAoFApERkbi1KlTdZ6rVCrxzjvvIDg4GAqFAl26dEF0dLTOOcuXL0fPnj3h7OwMb29vjB49GrGxsU39NIioGRSXV2Bt1ajVKw+HwtbGJH6NEREREYlfXO3evRvz58/HkiVLcO7cOXTp0gXDhg1DZmZmrecvXrwY69evx6pVq3D58mW89NJLGDNmDM6fP6895+jRo5g9ezZOnjyJgwcPQqlUYujQoSgqKmqup0VETeTLEzeQXVSONh4OGNPdX+w4RERERFqiF1effPIJZsyYgaioKISFhWHdunVwcHDApk2baj1/27ZteOONNzBy5Ei0bdsWM2fOxMiRI/Hxxx9rz4mOjsa0adPQsWNHdOnSBVu2bEFycjLOnj3bXE+LiJpAYVkF1h+9O2oll4n+K4yIiIhIS9RNhMvLy3H27FksWrRIe0wqlWLw4ME4ceJErfcpKyuDQqHQOWZvb4/ff/+9zsfJy8sDALi7u9d5zbKyMu3X+fn5ACqnICqVSv2eTBPRPL7YOaozxUyAaeZiJv3om+k/vyXiTrESQR4OGNnRq0mfgzm/Ts2JmfTDTPphJv2ZYi5m0g8z6ceUMhmSQSIIgtCEWeqVmpoKf39/HD9+HH369NEeX7BgAY4ePYqYmJga95k4cSIuXryI7777DsHBwTh06BCeeOIJqFQqnQJJQ61W4/HHH0dubm6dBdjSpUuxbNmyGsd37twJBweH+3iGRGQsJRXAsnMylKgkmBKqQoSnaL+6iIiIyIoUFxdj4sSJyMvLg4uLS73nijpy1RifffYZZsyYgQ4dOkAikSA4OBhRUVF1TiOcPXs2Ll26VO/I1qJFizB//nzt1/n5+QgICMDQoUMbfAGbmlKpxMGDBzFkyBDI5XJRs2iYYibANHMxk370ybTq8DWUqK4hxMsRb0zqC5lUInqm5sZM+mEm/TCTfkwxE2CauZhJP8ykH1PKpJnVpg9RiytPT0/IZDJkZGToHM/IyICvr2+t9/Hy8sJ3332H0tJSZGdno2XLlli4cCHatm1b49w5c+bgf//7H3777Te0alV3u2Y7OzvY2dnVOC6Xy0X/ZmqYUhYNU8wEmGYuZtJPXZnyipXYfPwGAODVIe2hsLMVPZOYmEk/zKQfZtKPKWYCTDMXM+mHmfRjCpkMeXxRV4Pb2toiIiIChw4d0h5Tq9U4dOiQzjTB2igUCvj7+6OiogLffPMNnnjiCe1tgiBgzpw5+Pbbb3H48GEEBQU12XMgoqb3xe+JKCirQAdfZ4wIr/0PL0RERERiE31a4Pz58zF16lT06NEDvXr1wooVK1BUVISoqCgAwJQpU+Dv74/ly5cDAGJiYpCSkoKuXbsiJSUFS5cuhVqtxoIFC7TXnD17Nnbu3Invv/8ezs7OSE9PBwC4urrC3t6++Z8kETXanaJybPo9CQAwb3A7SJt4OiARERFRY4leXI0bNw5ZWVl4++23kZ6ejq5duyI6Oho+Pj4AgOTkZEildwfYSktLsXjxYiQmJsLJyQkjR47Etm3b4Obmpj1n7dq1AIAHH3xQ57E2b96MadOmNfVTIiIj2nAsEUXlKnRs6YJhHX3EjkNERERUJ9GLK6BybdScOXNqve3IkSM6Xw8aNAiXL1+u93oiNkAkIiO6XViGrcevAwBeHdwOEglHrYiIiMh0cQdOIjJZG35LRHG5Cp1bueKRB7zFjkNERERULxZXRGSSMgtK8eWJ6wCAV4dw1IqIiIhMH4srIjJJ644kolSpRrfWbniwnZfYcYiIiIgaxOKKiExOel4ptsdU7mv1jyHtOWpFREREZoHFFRGZnDVHElBeoUavQHf0C/EQOw4RERGRXlhcEZFJScktwVenbgLgWisiIiIyLyyuiMikrP41AeUqNfq09UCfYI5aERERkflgcUVEJuPWnRLsOX131IqIiIjInLC4IiKTseZoIirUAgaEeqJXkLvYcYiIiIgMYiN2ACKybiq1gJikHBxJleD75BQAwLzBHLUiIiIi88PiiohEE30pDcv2XUZaXikAGQDAzkaKrIJScYMRERERNQKnBRKRKKIvpWHm9nNVhdVdZRVqzNx+DtGX0kRKRkRERNQ4LK6IqNmp1AKW7bsMoZ5zlu27DJW6vjOIiIiITAuLKyJqdqeScmqMWFUnAEjLK8WppJzmC0VERER0n7jmioiaTVpeCaIvpWP7yRt6nZ/JtVdERERkRlhcEVGTupFdhP2X0hF9KR0XbuYadF9vZ0XThCIiIiJqAiyuiMjo4jMKsP9SOvZfSseVtHztcYkE6NGmBYZ29MWG3xJxu6Cs1nVXEgC+rgrudUVERERmhcUVEd03QRDwd2o+9l9KQ/SldFzLKtLeJpNK0KetB4aF+2JYmA+8XSpHowJa2GPm9nOQADoFlqTqf5eMCoNMKgERERGRuWBxRUSNolYLOH/zDqKrRqhu3SnR3mYrk6J/qCeGh/tiyAM+aOFoW+P+w8P9sHZS92r7XFXydVVgyagwDA/3a5bnQURERGQsLK6ISG8VKjVOXc9B9KV0HPg7HRn5ZdrbFHIpHmrvjeHhvni4gzecFfIGrzc83A9DwnxxIiETPx+LwdABkegT4s0RKyIiIjJLLK6IqF7lFWr8ce02ov9Kx8ErGcgpKtfe5mRng0ce8MaIcF8MaucNe1uZwdeXSSWIDHJH9hUBkUHuLKyIiIjIbLG4IrIiKrWAmKQcnL0tgUdSTp2jRKVKFY7GZSH6Ujp+uZKBgtIK7W0tHOQYEuaD4eG+6BfiCTsbwwsqIiIiIkvE4orISkRfSqu2vkmGL+PPwK/a+qbCsgocvpqJ6Etp+PVqFkqUKu19vZztMKyjD0aE+yEyyB02Mu4/TkRERHQvFldEViD6Uhpmbj9Xo+15el4pXtp+Dp39XXA1oxDlFWrtbf5u9hge7osR4b7o3roFpJyuR0RERFQvFldEFk6lFrBs3+Va95PSHPszpXIvqiBPR21B1cnfFRIJCyoiIiIifbG4IrJwp5JydFqd1+XDpzrjmR6tWFARERERNRIXThBZuMyChgsrALCTS1lYEREREd0HFldEFs7bWWHU84iIiIiodiyuiCxcryB3+LnWXThJAPi5KtAryL35QhERERFZIBZXRBZOJpVg4YgOtd6mmQS4ZFQYN+8lIiIiuk8sroisQH7VJsD3FlC+rgqsndQdw8P9xIhFREREZFHYLZDIwqnVArb8kQQAeGNkB7T3dsTPx2IwdEAk+oR4c8SKiIiIyEhYXBFZuGMJt3EtqwhOdjYY2yMAChmQfUVAZJA7CysiIiIiI+K0QCILt+n3ylGrZ3q0grNCLnIaIiIiIsvF4orIgiVkFuJoXBYkEmBa30Cx4xARERFZNBZXRBZs6/HrAIBHOvigjYejuGGIiIiILByLKyILlVesxNdnbwEApvcLFDcMERERkRVgcUVkoXafSUaJUoUOvs7oE+whdhwiIiIii8fiisgCVajU2Hr8BgAgql8gJBJ2BSQiIiJqaiyuiCzQL1cykJJbghYOcjzR1V/sOERERERWgcUVkQXa9Md1AMDEyNZQyGXihiEiIiKyEiyuiCzMpZQ8nErKgY1Ugsm9A8WOQ0RERGQ1WFwRWZjNVaNWIzv5wddVIW4YIiIiIivC4orIgmQVlGHfxVQAlY0siIiIiKj5sLgisiA7Y5JRrlKja4AburVuIXYcIiIiIqvC4orIQpRVqLDtZGX79en9g0ROQ0RERGR9WFwRWYgf/0zD7cIy+LooMCLcV+w4RERERFaHxRWRBRAEQdvIYnKfNpDL+KNNRERE1Nz4CYzIApy9cQd/peTBzkaKCb1aix2HiIiIyCqxuCKyAJv+SAIAjOnmD3dHW5HTEBEREVknFldEZi4ltwQH/s4AAExj+3UiIiIi0bC4IjJzX564DpVaQN9gD3TwdRE7DhEREZHVMri4GjRoEL788kuUlJQ0RR4iMkBxeQW+OnUTABDVj+3XiYiIiMRkcHHVrVs3vPbaa/D19cWMGTNw8uTJpshFRHrYey4FeSVKtPFwwMMdvMWOQ0RERGTVDC6uVqxYgdTUVGzevBmZmZkYOHAgwsLC8O9//xsZGRlNkZGIaiEIArYcvw4AmNonEDKpRNxARERERFauUWuubGxs8OSTT+L777/HrVu3MHHiRLz11lsICAjA6NGjcfjwYWPnJKJ7HIu/jYTMQjjZ2eCZHq3EjkNERERk9e6rocWpU6ewZMkSfPzxx/D29saiRYvg6emJxx57DK+99pqxMhJRLTZXtV9/OqIVnBVykdMQERERkY2hd8jMzMS2bduwefNmxMfHY9SoUdi1axeGDRsGiaRyWtK0adMwfPhw/Pvf/zZ6YCICrmUV4tfYLEgkwLS+gWLHISIiIiI0orhq1aoVgoODMX36dEybNg1eXl41zuncuTN69uxplIBEVNPWqrVWj3TwRqCno7hhiIiIiAhAI4qrQ4cOYcCAAfWe4+Ligl9//bXRoYiobnklSnx99hYAtl8nIiIiMiUGr7lq1aoV4uPjaxyPj4/H9evXjZGJiOrx3zM3UVyuQnsfZ/QN9hA7DhERERFVMbi4mjZtGo4fP17jeExMDKZNm2aMTERUB5X6bvv1qH6B2nWORERERCQ+g4ur8+fPo1+/fjWO9+7dGxcuXDBGJiKqw8HLGbh1pwQtHOQY3c1f7DhEREREVI3BxZVEIkFBQUGN43l5eVCpVEYJRUS107Rfn9CrNRRymchpiIiIiKg6g4urgQMHYvny5TqFlEqlwvLly9G/f3+jhiOiu/5OzUNMUg5spBJM7tNG7DhEREREdA+DuwV+8MEHGDhwINq3b6/tGnjs2DHk5+fj8OHDRg9IRJU2/3EdADCikx/8XO3FDUNERERENRg8chUWFoY///wTY8eORWZmJgoKCjBlyhRcvXoV4eHhTZGRyOrdLizDDxdSAVQ2siAiIiIi02PwyBUAtGzZEu+//76xsxBRHXbGJKNcpUaXADd0b91C7DhEREREVItGFVcAUFxcjOTkZJSXl+sc79y5832HIqK7yivU2HbyBgBgOketiIiIiEyWwcVVVlYWoqKisH///lpvZ8dAIuP68a9UZBWUwcfFDiM7+Ykdh4iIiIjqYPCaq3nz5iE3NxcxMTGwt7dHdHQ0tm7ditDQUPzwww9NkZHIagmCoG1kMbl3G8hlBv/IEhEREVEzMXjk6vDhw/j+++/Ro0cPSKVStGnTBkOGDIGLiwuWL1+ORx99tClyElmlc8l38OetPNjaSDGhV2ux4xARERFRPQz+M3hRURG8vb0BAC1atEBWVhYAoFOnTjh37pxx0xFZuU1Vo1ZjuvrDw8lO3DBEREREVC+Di6v27dsjNjYWANClSxesX78eKSkpWLduHfz8uB6EyFhSc0sQfSkdABDVP1DcMERERETUIIOnBc6dOxdpaWkAgCVLlmD48OHYsWMHbG1tsWXLFmPnI7JaX564AZVaQJ+2Hujg6yJ2HCIiIiJqgMHF1aRJk7T/joiIwI0bN3D16lW0bt0anp6eRg1HZK1KylXYdSoZADcNJiIiIjIXBk0LVCqVCA4OxpUrV7THHBwc0L17dxZWREa09/wt5JUo0drdAY884CN2HCIiIiLSg0HFlVwuR2lpaVNlISJUtl/fUtXIYmrfQMikEnEDEREREZFeDG5oMXv2bHzwwQeoqKhoijxEVu/3hNuIzyyEo60Mz/RoJXYcIiIiItKTwWuuTp8+jUOHDuHnn39Gp06d4OjoqHP73r17jRaOyBppNg1+pkcAXBRyccMQERERkd4MLq7c3Nzw1FNPNUUWIquXmFWIw1czIZFUTgkkIiIiIvNhcHG1efPmpshBRAC2Hr8OAHi4vTeCPB3rP5mIiIiITIrBa66IqGnklyrx9dlbAICofkEipyEiIiIiQxk8chUUFASJpO7uZYmJifcViMha7Tl9E0XlKrTzcUK/EA+x4xARERGRgQwurubNm6fztVKpxPnz5xEdHY3XX3/dWLmIrIpKLWBL1ZTAqH71/wGDiIiIiEyTwcXV3Llzaz2+evVqnDlz5r4DEVmjX65k4NadErg5yDG6q7/YcYiIiIioEYy25mrEiBH45ptvjHU5Iquy+Y8kAMCEXq1hbysTOQ0RERERNYbRiquvv/4a7u7uxrockdW4nJqPk4k5kEklmNKnjdhxiIiIiKiRDJ4W2K1bN531IIIgID09HVlZWVizZo1RwxFZA82o1YhwX/i52ouchoiIiIgay+DiavTo0TpfS6VSeHl54cEHH0SHDh2MlYvIKmQXluH7i6kA2H6diIiIyNwZXFwtWbKkKXIQWaWdMckor1CjSytXdG/tJnYcIiIiIroPBq+5+umnn3DgwIEaxw8cOID9+/c3KsTq1asRGBgIhUKByMhInDp1qs5zlUol3nnnHQQHB0OhUKBLly6Ijo6+r2sSiaG8Qo1tJ28AAKb3Z/t1IiIiInNncHG1cOFCqFSqGscFQcDChQsNDrB7927Mnz8fS5Yswblz59ClSxcMGzYMmZmZtZ6/ePFirF+/HqtWrcLly5fx0ksvYcyYMTh//nyjr0kkhp/+SkNmQRm8ne0wItxP7DhEREREdJ8MLq7i4+MRFhZW43iHDh2QkJBgcIBPPvkEM2bMQFRUFMLCwrBu3To4ODhg06ZNtZ6/bds2vPHGGxg5ciTatm2LmTNnYuTIkfj4448bfU2i5iYIgraRxeTebWBrY7TGnUREREQkEoPXXLm6uiIxMRGBgYE6xxMSEuDo6GjQtcrLy3H27FksWrRIe0wqlWLw4ME4ceJErfcpKyuDQqHQOWZvb4/ff//9vq5ZVlam/To/Px9A5RREpVJp0HMyNs3ji52jOlPMBJhmrroynU/OxcVbebC1keKZiJbNmtmcXicxMZN+mEk/zKQfZtKfKeZiJv0wk35MKZMhGSSCIAiGXPzFF1/EiRMn8O233yI4OBhAZWH11FNPoWfPnvjiiy/0vlZqair8/f1x/Phx9OnTR3t8wYIFOHr0KGJiYmrcZ+LEibh48SK+++47BAcH49ChQ3jiiSegUqlQVlbWqGsuXboUy5Ytq3F8586dcHBw0Pv5EOlrS5wU57OliPRSY2KIWuw4RERERFSH4uJiTJw4EXl5eXBxcan3XINHrj788EMMHz4cHTp0QKtWrQAAt27dwoABA/Dvf/+7cYkN8Nlnn2HGjBno0KEDJBIJgoODERUVdV9T/hYtWoT58+drv87Pz0dAQACGDh3a4AvY1JRKJQ4ePIghQ4ZALpeLmkXDFDMBppmrtkxpeaWYH3MMgIDFY/uhg6+z6JnExkz6YSb9MJN+mEk/ppgJMM1czKQfZtKPKWXSzGrTR6OmBR4/fhwHDx7ExYsXYW9vj86dO2PgwIGGXgqenp6QyWTIyMjQOZ6RkQFfX99a7+Pl5YXvvvsOpaWlyM7ORsuWLbFw4UK0bdu20de0s7ODnZ1djeNyuVz0b6aGKWXRMMVMgGnmqp5p15lrUKkF9G7rjk4B7iaRyVQwk36YST/MpB9m0o8pZgJMMxcz6YeZ9GMKmQx5/EatopdIJBg6dChef/11zJkzp1GFFQDY2toiIiIChw4d0h5Tq9U4dOiQzpS+2igUCvj7+6OiogLffPMNnnjiifu+JlFTKylXYdepZADcNJiIiIjI0hhcXL3yyitYuXJljeOff/455s2bZ3CA+fPnY+PGjdi6dSuuXLmCmTNnoqioCFFRUQCAKVOm6DSniImJwd69e5GYmIhjx45h+PDhUKvVWLBggd7XJBLLdxdSkFusRIC7PQY/4CN2HCIiIiIyIoOnBX7zzTf44Ycfahzv27cv/vWvf2HFihUGXW/cuHHIysrC22+/jfT0dHTt2hXR0dHw8an84JmcnAyp9G4NWFpaisWLFyMxMRFOTk4YOXIktm3bBjc3N72vSSSG6u3Xp/YJhEzKTYOJiIiILInBxVV2djZcXV1rHHdxccHt27cbFWLOnDmYM2dOrbcdOXJE5+tBgwbh8uXL93VNsjwqtYCYpBycvS2BR1IO+oR4m1zx8kdCNuIyCuFoK8PYngFixyEiIiIiIzO4uAoJCUF0dHSNwmX//v3aphJEzSn6UhqW7buMtLxSADJ8GX8Gfq4KLBkVhuHhfmLH09KMWj0d0QouCtNaLEpERERE98/g4mr+/PmYM2cOsrKy8PDDDwMADh06hI8//tjgKYFE9yv6Uhpmbj+HezdrS88rxczt57B2UneTKLCuZxfhcGwmAGAaG1kQERERWSSDi6vp06ejrKwM7733Ht59910AQGBgINauXYspU6YYPSBRXVRqAcv2Xa5RWAGAAEACYNm+yxgS5iv6FMEvT96EIAAPd/BGkKejqFmIiIiIqGk0qhX7zJkzcevWLWRkZCA/Px+JiYmYMmUKcnJyjJ2PqE6nknKqpgLWTkDlhr0f/xyL88l3kFtc3nzhqimpAPaeSwEARPULFCUDERERETU9g0euqvPy8gIA/Pzzz/jiiy+wb98+lJSUGCUYUUMyC+ourKpbc+Qa1hy5BgBo4SBHkKcjgjydEOTpUPW/jgj0dICD7X39ONSgabLxdZIUReUqhHg5on+Ip1Efg4iIiIhMR6M/Td64cQObNm3C1q1bcefOHYwYMQJffvmlMbMR1cvbWaHXeQ/4OSOnqBwZ+WW4U6zEneRcnEvOrXGer4uisvDyckSQh6P23wEtHGBrY9ggr26Tjcr7ZhaU48Df6SaxBoyIiIiIjM+g4qq8vBx79+7FF198gT/++AODBw/GrVu3cP78eXTq1KmpMhLVqleQO/xcFUjPK6113ZUEgK+rAv97eQBkUgmKyipwPbsISbeLcP12ERJv3/33nWIl0vNLkZ5fihOJ2TrXkUklaNXCvnKEy8MRbb0ctf9u6WZfYz1XXU02CkqVJtVkg4iIiIiMS+/i6uWXX8auXbsQGhqKSZMmYffu3fDw8IBcLodMJmvKjES1kkklWDIqDC9tP1fjNk25s2RUmLb4cbSzQceWrujYsuY+bXeKypGUXVloJVUVXpp/F5ercCO7GDeyiwFk6dzP1kaKQA+HqqmFjgj0cMC/D8SZRZMNIiIiIjIuvYurtWvX4v/+7/+wcOFCODs7N2UmIr0ND/fDS4PaYt3RRJ3jvgbuc9XC0RYtHG3RvXULneOCICCzoAxJVYVW9f9uZBehvEKNuIxCxGUU6vU4miYbp5Jy0CfYQ6/7EBEREZF50Lu42rZtGzZt2gQ/Pz88+uijmDx5MkaMGNGU2Yj04mRX+TbuF+yOYGkWhg6IRJ8Qb6OMDEkkEvi4KODjokDvtrrFkEotIDW3pHJ6YVYhrmcX42RiNq6mFzR4XX2bcRARERGR+dC7uJowYQImTJiApKQkbNmyBbNnz0ZxcTHUajUuX76MsLCwpsxJVCfNqFGfth4IKMxEZJB7s0y5k0klCHB3QIC7Awa1q+yceeJaNiZsPNngffVtxkFERERE5sPgfa6CgoKwbNkyXL9+Hdu3b8dTTz2FSZMmoVWrVnjllVeaIiNRveIyKkeKQn2cRE5yt8lGXaWdBICfqwK9gtybMxYRERERNYNGbSIMVE6XGjZsGPbs2YPU1FS89tprOHr0qDGzETWoQqVGYlYRAKCdt/jFlabJBoAaBVZtTTaIiIiIyHI0uriqzt3dHfPmzcPFixeNcTkivV3PLka5Sg0HWxlauprGVLvh4X5YO6k7fO/J4+uqYBt2IiIiIgvW6E2EiUyBdkqgtxOkJjQaNDzcD0PCfHEiIRM/H4sxapMNIiIiIjJNLK7IrGmKq3Y+prc9gEwqQWSQO7KvCM3WZIOIiIiIxGOUaYFEYomv6hRoisUVEREREVkXvYurS5cuNWUOokaJNaFOgURERERk3fQurjp37ozIyEhs3LgRBQUNb5JK1NTKK9S4fruyU2B7X45cEREREZG49C6ujh49io4dO+If//gH/Pz8MHXqVBw7dqwpsxHVK+l2ESrUApztbODrYhqdAomIiIjIeuldXA0YMACbNm1CWloaVq1ahevXr2PQoEFo164dPvjgA6SnpzdlTqIaqk8JlEjYLIKIiIiIxGVwQwtHR0dERUXh6NGjiIuLwzPPPIPVq1ejdevWePzxx5siI1Gt4quKK04JJCIiIiJTcF/dAkNCQvDGG29g8eLFcHZ2xo8//misXEQNurvHFYsrIiIiIhJfo/e5+u2337Bp0yZ88803kEqlGDt2LJ577jljZiOqV1xVG3aOXBERERGRKTCouEpNTcWWLVuwZcsWJCQkoG/fvli5ciXGjh0LR0fHpspIVEOpUoUb2ZWdAtmGnYiIiIhMgd7F1YgRI/DLL7/A09MTU6ZMwfTp09G+ffumzEZUp4TMQqgFwM1BDi8nO7HjEBERERHpX1zJ5XJ8/fXXeOyxxyCTyZoyE1GD4jMr11u183Fmp0AiIiIiMgl6N7TYu3cvgoKCUF5eXuO24uJi/Pnnn1Cr1UYNR1QXzXqrdpwSSEREREQmQu/iavv27Zg+fTpsbW1r3GZra4vp06dj586dRg1HVJe49LsjV0REREREpkDv4uqLL77Aa6+9VuuUQBsbGyxYsAAbNmwwajiiusRlsrgiIiIiItOid3EVFxeH3r1713l7z549ceXKFaOEIqpPcXkFbuaUAGBxRURERESmQ+/iqqioCPn5+XXeXlBQgOLiYqOEIqpPfNV6K08nO7g71pymSkREREQkBr2Lq9DQUBw/frzO23///XeEhoYaJRRRfeIyNFMC2cyCiIiIiEyH3sXVxIkTsXjxYvz55581brt48SLefvttTJw40ajhiGpzt7jilEAiIiIiMh1673P16quvYv/+/YiIiMDgwYPRoUMHAMDVq1fxyy+/oF+/fnj11VebLCiRxt027CyuiIiIiMh0GLSJ8M8//4xPP/0UO3fuxG+//QZBENCuXTu89957mDdvHuRyeVNmJQIAxHNaIBERERGZIL2LK6CywFqwYAEWLFjQVHmI6pVfqkRqXikAIJQjV0RERERkQvRec0VkCjSdAn1dFHC150gpEREREZkOFldkVjRTAkM5JZCIiIiITAyLKzIrsewUSEREREQmisUVmRXNtMD2LK6IiIiIyMSwuCKzEsdpgURERERkogzqFggAKpUKW7ZswaFDh5CZmQm1Wq1z++HDh40Wjqi63OJyZBaUAWCnQCIiIiIyPQYXV3PnzsWWLVvw6KOPIjw8HBKJpClyEdWg2TzY380eTnYGv3WJiIiIiJqUwZ9Qv/rqK+zZswcjR45sijxEdYrl5sFEREREZMIMXnNla2uLkJCQpshCVC9NG/Z2vpwSSERERESmx+Di6h//+Ac+++wzCILQFHmI6qRpZtHOm8UVEREREZkeg6cF/v777/j111+xf/9+dOzYEXK5XOf2vXv3Gi0cUXWaNVfc44qIiIiITJHBxZWbmxvGjBnTFFmI6nS7sAw5ReWQSIAQb665IiIiIiLTY3BxtXnz5qbIQVQvzZTA1u4OsLeViZyGiIiIiKgmbiJMZiEuvWrzYK63IiIiIiIT1ajNgr7++mvs2bMHycnJKC8v17nt3LlzRglGVF1cZuV6q/a+nBJIRERERKbJ4JGrlStXIioqCj4+Pjh//jx69eoFDw8PJCYmYsSIEU2RkehuG3Y2syAiIiIiE2VwcbVmzRps2LABq1atgq2tLRYsWICDBw/ilVdeQV5eXlNkJCsnCAJi01lcEREREZFpM7i4Sk5ORt++fQEA9vb2KCio/NA7efJk7Nq1y7jpiABkFpQhv7QCMqkEbb0cxY5DRERERFQrg4srX19f5OTkAABat26NkydPAgCSkpK4sTA1Cc2oVRsPB9jZsFMgEREREZkmg4urhx9+GD/88AMAICoqCq+++iqGDBmCcePGcf8rahKaNuztOSWQiIiIiEyYwd0CN2zYALVaDQCYPXs2PDw8cPz4cTz++ON48cUXjR6QKD6jslNgKIsrIiIiIjJhBhdXUqkUUundAa/x48dj/PjxRg1FVF2stlMg27ATERERkelq1CbCx44dw6RJk9CnTx+kpKQAALZt24bff//dqOGIBEFAgmaPK45cEREREZEJM7i4+uabbzBs2DDY29vj/PnzKCsrAwDk5eXh/fffN3pAa6ZSC4hJysHZ2xLEJOVApba+hiGpeaUoLKuAXCZBoCc7BRIRERGR6TK4uPrnP/+JdevWYePGjZDL5drj/fr1w7lz54wazppFX0pD/w8OY9KmM/gyXoZJm86g/weHEX0pTexozSquqlNgkKcj5LJGDbQSERERETULgz+txsbGYuDAgTWOu7q6Ijc31xiZrF70pTTM3H4OaXmlOsfT80oxc/s5qyqw4jK4eTARERERmYdG7XOVkJBQ4/jvv/+Otm3bGiWUNVOpBSzbdxm1TQDUHFu277LVTBGMq+oUyOKKiIiIiEydwcXVjBkzMHfuXMTExEAikSA1NRU7duzAa6+9hpkzZzZFRqtyKimnxohVdQKAtLxSnErKab5QIuLIFRERERGZC4NbsS9cuBBqtRqPPPIIiouLMXDgQNjZ2eG1117Dyy+/3BQZrUpmQd2FVWPOM2dqtYD4TLZhJyIiIiLzYHBxJZFI8Oabb+L1119HQkICCgsLERYWBicnfvg1Bm9nhVHPM2c37xSjVKmGrY0UbTzYKZCIiIiITJvBxZWGra0twsLCjJmFAPQKcoefqwLpeaW1rruSAPB1VaBXkHtzR2t2mvVWIV5OkEklIqchIiIiIqqf3sXV9OnT9Tpv06ZNjQ5DgEwqwZJRYZi5/RwkQK0F1pJRYVZRbNxdb8VRUSIiIiIyfXoXV1u2bEGbNm3QrVs3CIJ1dKoTy/BwP6yd1B3L9l3WaW5hL5fh03FdMDzcT8R0zUdTXIWymQURERERmQG9i6uZM2di165dSEpKQlRUFCZNmgR3d8ufmiaW4eF+GBLmixMJmdgcfQqHUqXwcbGzmsIKuDstsD2LKyIiIiIyA3q3Yl+9ejXS0tKwYMEC7Nu3DwEBARg7diwOHDjAkawmIpNKEBnkjsH+akgkwPXsYmQVlIkdq1lUqNS4lsU9roiIiIjIfBi0z5WdnR0mTJiAgwcP4vLly+jYsSNmzZqFwMBAFBYWNlVGq+dgA7T3rlx3dPaGdexvdSOnGOUVatjLZWjVwl7sOEREREREDTJ4E2HtHaVSSCQSCIIAlUplzExUi4g2LQAAp6/fETlJ84jXrrdygtQKmncQERERkfkzqLgqKyvDrl27MGTIELRr1w5//fUXPv/8cyQnJ3OfqyYW0cYNAHDmunWMXGnWW4V6c0ogEREREZkHvRtazJo1C1999RUCAgIwffp07Nq1C56enk2ZjarpUTVydSk1H8XlFXCwbfQWZWYhtmrkqr0vi3YiIiIiMg96f0Jft24dWrdujbZt2+Lo0aM4evRoreft3bvXaOHoLj9XBfzd7JGSW4ILybnoG2LZhW0827ATERERkZnRu7iaMmUKJBKufRFTj8AWSLlQgtPX71h0cVVeoUZiVhEAdgokIiIiIvNh0CbCJK4ege74/kIqzlh4x8Dr2UWoUAtwsrNBS1eF2HGIiIiIiPTS6G6B1Px6Blauuzp34w4qVGqR0zSduGqdAjlaSkRERETmgsWVGWnn7QxnhQ2KylW4ml4gdpwmE1f13NqxUyARERERmREWV2ZEKpVouwaetuCW7Jo27O18WVwRERERkflgcWVmegS6AwDOWPBmwnGZVSNXPmzDTkRERETmg8WVmelZVVydvp4DQRBETmN8pUoVrt9mp0AiIiIiMj8srsxM51ausJVJkVlQhps5JWLHMbrErCKoBcDVXg5vZzux4xARERER6Y3FlZlRyGXo1MoVgGWuu4qvNiWQnQKJiIiIyJywuDJDPapaslviflexmk6BnBJIRERERGaGxZUZ6tlGs+7K8ppaaDsFsrgiIiIiIjPD4soMRVS1Y0/ILEROUbnIaYyr+gbCRERERETmhMWVGWrhaItQ78ri4+wNyxm9KilX4eadYgBAe45cEREREZGZYXFlpu7ud2U5664SMgshCICHoy08nNgpkIiIiIjMC4srM9WzqqmFJXUMjOWUQCIiIiIyY6IXV6tXr0ZgYCAUCgUiIyNx6tSpes9fsWIF2rdvD3t7ewQEBODVV19FaWmp9naVSoW33noLQUFBsLe3R3BwMN59912L23BXs5nwXyl5KFWqRE5jHPFVxRWnBBIRERGRObIR88F3796N+fPnY926dYiMjMSKFSswbNgwxMbGwtvbu8b5O3fuxMKFC7Fp0yb07dsXcXFxmDZtGiQSCT755BMAwAcffIC1a9di69at6NixI86cOYOoqCi4urrilVdeae6n2GRatbCHj4sdMvLLcPFmLiLbeogd6b7dbWbB4oqIiIiIzI+oI1effPIJZsyYgaioKISFhWHdunVwcHDApk2baj3/+PHj6NevHyZOnIjAwEAMHToUEyZM0BntOn78OJ544gk8+uijCAwMxNNPP42hQ4c2OCJmbiQSyd11VxbS1IJt2ImIiIjInIk2clVeXo6zZ89i0aJF2mNSqRSDBw/GiRMnar1P3759sX37dpw6dQq9evVCYmIifvrpJ0yePFnnnA0bNiAuLg7t2rXDxYsX8fvvv2tHtmpTVlaGsrIy7df5+fkAAKVSCaVSeb9P9b5oHr+2HN0DXPHjn2k4lZiNF/q3MYlMjVVQWoGU3BIAQJC7olHXbopc94uZ9MNM+mEm/TCTfphJP6aYCTDNXMykH2bSjyllMiSDRBBpMVJqair8/f1x/Phx9OnTR3t8wYIFOHr0KGJiYmq938qVK/Haa69BEARUVFTgpZdewtq1a7W3q9VqvPHGG/jwww8hk8mgUqnw3nvv6RRx91q6dCmWLVtW4/jOnTvh4OBwH8+yad0qAj760wb2MgHv91RBKhE7UeNdLwA+vWQDF7mAd3tYxhoyIiIiIjJ/xcXFmDhxIvLy8uDi4lLvuaKuuTLUkSNH8P7772PNmjWIjIxEQkIC5s6di3fffRdvvfUWAGDPnj3YsWMHdu7ciY4dO+LChQuYN28eWrZsialTp9Z63UWLFmH+/Pnar/Pz8xEQEIChQ4c2+AI2NaVSiYMHD2LIkCGQy+U6t1Wo1FgT+yuKylQIiRiADr7NM52uvkyN9d+zt4BLl9GptSdGjowwmVz3i5n0w0z6YSb9MJN+mEk/ppgJMM1czKQfZtKPKWXSzGrTh2jFlaenJ2QyGTIyMnSOZ2RkwNfXt9b7vPXWW5g8eTKef/55AECnTp1QVFSEF154AW+++SakUilef/11LFy4EOPHj9eec+PGDSxfvrzO4srOzg52djX3VZLL5aJ/MzVqyyKXA91bt8Cx+Nu4cCsfnQLcRc/UWNduV04JbO/rct/XNKXvmwYz6YeZ9MNM+mEm/TCTfkwxE2CauZhJP8ykH1PIZMjji9bQwtbWFhERETh06JD2mFqtxqFDh3SmCVZXXFwMqVQ3skwmAwBtq/W6zlGr1caMbzI0LdlPXzfvphaaToHtuMcVEREREZkpUacFzp8/H1OnTkWPHj3Qq1cvrFixAkVFRYiKigIATJkyBf7+/li+fDkAYNSoUfjkk0/QrVs37bTAt956C6NGjdIWWaNGjcJ7772H1q1bo2PHjjh//jw++eQTTJ8+XbTn2ZR6VG0mfMbMNxPWFlfNNLWRiIiIiMjYRC2uxo0bh6ysLLz99ttIT09H165dER0dDR8fHwBAcnKyzijU4sWLIZFIsHjxYqSkpMDLy0tbTGmsWrUKb731FmbNmoXMzEy0bNkSL774It5+++1mf37NoWuAG2ykEqTmlSIltwT+bvZiRzJYXrESGfmV3RpDvTlyRURERETmSfSGFnPmzMGcOXNqve3IkSM6X9vY2GDJkiVYsmRJnddzdnbGihUrsGLFCiOmNF0Otjbo6O+KizdzceZ6Dvy7+osdyWBxmZWjVi1dFXBWmNY8XyIiIiIifYm6iTAZR882lVMDT5vp1EBOCSQiIiIiS8DiygL0qGpqccZMm1rEZxQCANr5sLgiIiIiIvPF4soCaJpaxGYUIK9Y/F2sDRWbXjlyxfVWRERERGTOWFxZAE8nO7T1dIQgAOeSzW/0Kr5qzVV7TgskIiIiIjPG4spCaEavzG3dVXZhGW4XlgMAQjhyRURERERmjMWVhTDXdVdxVeutWrs7wMFW9OaVRERERESNxuLKQvSsKq4u3MpFWYVK5DT600wJbOfDUSsiIiIiMm8srixEoIcDPJ1sUV6hxqWUPLHj6E3bzIKdAomIiIjIzLG4shASiQQ92lSOXp02o6mBmjbs7VlcEREREZGZY3FlQTRNLc6YSVMLQRAQl6kZueK0QCIiIiIybyyuLIhm3dWZG3egVgsip2lYVkEZcouVkEqAYC8WV0RERERk3lhcWZCwli6wl8uQW6zEtaxCseM0SNMpMNDDEQq5TOQ0RERERET3h8WVBZHLpOjW2g2Aeay7isvglEAiIiIishwsrizM3f2uTH/dlaa4asdmFkRERERkAVhcWZieVU0tTt9gcUVERERE1JxYXFmYbq1bQCoBbuaUID2vVOw4dRIEQduGncUVEREREVkCFlcWxsnOBmEtXQAAZ0x49CotrxQFZRWwkUoQ5OkodhwiIiIiovvG4soCaTYTPmPCTS00UwKDPB1ha8O3IRERERGZP36qtUCa/a5Om3BTC663IiIiIiJLw+LKAvWoampxJS0fBaVKkdPULo7rrYiIiIjIwrC4skA+Lgq0dneAWgDOJ+eKHadW8dqRK+5xRURERESWgcWVherRpnL0yhT3u1KrBe3IVShHroiIiIjIQrC4slA9tOuuTK+pRUpuCUqUKtjKpAj0cBA7DhERERGRUbC4slCazYTP37wDpUotchpdmmYWbb0cYSPjW5CIiIiILAM/2VqoYC8nuDnIUapU4+/UfLHj6Ihlp0AiIiIiskAsriyUVCox2XVX8VXrrdr7srgiIiIiIsvB4sqC9TDR/a5i0ytHrkK92SmQiIiIiCwHiysLpll3deb6HQiCIHKaSiq1gGtZHLkiIiIiIsvD4sqChfu7wtZGiuyiciTdLhI7DgAgOacYZRVqKORSBLRgp0AiIiIishwsriyYnY0MXVu5AagcvTIFmimBId5OkEolIqchIiIiIjIeFlcWrkfV1EBTWXcVz06BRERERGShWFxZuJ5VTS3O3DCNkau4zMr1ViyuiIiIiMjSsLiycN1bt4BEAiTdLkJWQZnYcRCXrhm5YqdAIiIiIrIsLK4snKuDHO2rRonO3hB3aqBSpUbibY5cEREREZFlYnFlBe6uuxJ3auCN7CIoVQIcbWXwd7MXNQsRERERkbGxuLIC2nVXIje1iE2vHLUK8XGGRMJOgURERERkWVhcWYEeVcXVpdR8FJdXiJYjrqpTYHuutyIiIiIiC8Tiygr4u9mjpasCKrWAC8m5ouWIYxt2IiIiIrJgLK6shGb0Ssx1VyyuiIiIiMiSsbiyEj2rmlqcEaljYFmFCteziwGwuCIiIiIiy8TiykpoRq7O3biDCpW62R8/MasIKrUAZ4UNfFzsmv3xiYiIiIiaGosrK9HOxxnOChsUlatwtWoj3+Z0t5kFOwUSERERkWVicWUlZFIJItpo9rtq/qmB8RmVbdhDOSWQiIiIiCwUiysrcne/q+ZvahGrbWbBNuxEREREZJlYXFmRHtVGrgRBaNbHjq82LZCIiIiIyBKxuLIiXQLcIJdJkFlQhps5Jc32uKVKFW7kVHYK5LRAIiIiIrJULK6siEIuQyd/VwDNu+4qIbMQggC0cJDD08m22R6XiIiIiKg5sbiyMtp1V82431X1zYPZKZCIiIiILBWLKyuj2e/qdDM2tYitVlwREREREVkqFldWRtOOPSGzEDlF5c3ymJo27O18WVwRERERkeVicWVl3B1tEeJd2Q797I3mGb3STgv0Zht2IiIiIrJcLK6sUM/AytGrM83Q1KKorAK37lR2JuS0QCIiIiKyZCyurFCPNpp1V01fXMVnVk4J9HK2QwtHdgokIiIiIsvF4soKaToG/pWSh1Klqkkf626nQE4JJCIiIiLLxuLKCgW428Pb2Q5KlYCLN3Ob9LHi0iuLq1BvTgkkIiIiIsvG4soKSSSSavtdNW1Ti7iqaYHt2SmQiIiIiCwciysr1aOqqUVTr7vSjFxxWiARERERWToWV1ZKM3J19sYdqNRCkzxGXokS6fmlAIAQTgskIiIiIgvH4spKdfB1hqOtDAWlFdqmE8aWkFl5XT9XBVzt5U3yGEREREREpoLFlZWykUnRvU3T7ncVm1653iqU+1sRERERkRVgcWXF7u531TRNLTQjYu253oqIiIiIrACLKyvWM7BpR67iq6YFcuSKiIiIiKwBiysr1rW1G2RSCVLzSpGSW2L062umBbZjcUVEREREVoDFlRVzsLVBeEsXAMYfvbpTVI7bhWUAgFBvTgskIiIiIsvH4srK9QjUrLsybnGlWW/VqoU9HO1sjHptIiIiIiJTxOLKyt1dd2Xcphaa4opTAomIiIjIWrC4snIRVR0DYzMKkFesNNp14zK43oqIiIiIrAuLKyvn5WyHIE9HCAJwLtl4o1ex2pErrrciIiIiIuvA4orQo2ozYWOtuxIEAfGcFkhEREREVobFFaFnVVMLY627ul1YjjvFSkgkQAg7BRIRERGRlWBxRehR1dTiwq1clFWo7vt6mmYWbdwdoJDL7vt6RERERETmgMUVIcjTER6OtiivUONSSt59X4+dAomIiIjIGrG4IkgkEu3o1WkjTA1kp0AiIiIiskYsrghA9XVX99/UQjNyFcpOgURERERkRVhcEQCgh6a4unEHarXQ6OsIgqAtrtr7cuSKiIiIiKwHiysCAHRs6QKFXIrcYiWuZRU2+joZ+WUoKK2ATCpBkKejERMSEREREZk2FlcEAJDLpOgWcP/rrjSbBwd6OMDOhp0CiYiIiMh6sLgirZ5VTS3uZ91VPKcEEhEREZGVYnFFWpp1V6dvNL64ik2vambhzeKKiIiIiKwLiyvS6tbaDVIJcDOnBOl5pY26Rlxm5XotjlwRERERkbVhcUVazgo5HvBzAQCcacTolVotIEG7gTDbsBMRERGRdWFxRTru7ndleFOLlNwSFJWrIJdJ0MaDnQKJiIiIyLqwuCIdPQI1HQMNH7mKz6wctQr2coJcxrcWEREREVkXfgImHT3aVI5cXUnLR0Gp0qD7xmVUrrcK9eF6KyIiIiKyPiyuSIevqwIB7vZQC8D55FyD7htX1SmwnTfXWxERERGR9WFxRTX0bKNZd2XY1MC4qmmB7dgpkIiIiIisEIsrqkG735UBTS1UagEJVW3Y23FaIBERERFZIRZXVEPPqqYW52/egVKl1us+N3OKUapUw85GitbuDk0Zj4iIiIjIJLG4ohqCvZzg5iBHqVKNv1Pz9bpPXNX+ViHeTpBJJU0Zj4iIiIjIJLG4ohqkUgl6tKkcvdJ33VWcdvNgTgkkIiIiIuvE4opqdXfdlb7FFddbEREREZF1E724Wr16NQIDA6FQKBAZGYlTp07Ve/6KFSvQvn172NvbIyAgAK+++ipKS0t1zklJScGkSZPg4eEBe3t7dOrUCWfOnGnKp2FxNOuuzly/A0EQGjz/7sgV27ATERERkXWyEfPBd+/ejfnz52PdunWIjIzEihUrMGzYMMTGxsLb27vG+Tt37sTChQuxadMm9O3bF3FxcZg2bRokEgk++eQTAMCdO3fQr18/PPTQQ9i/fz+8vLwQHx+PFi1aNPfTM2vh/q6wtZEiu6gcSbeL0Nar7qKpQqVGYlYRAI5cEREREZH1ErW4+uSTTzBjxgxERUUBANatW4cff/wRmzZtwsKFC2ucf/z4cfTr1w8TJ04EAAQGBmLChAmIiYnRnvPBBx8gICAAmzdv1h4LCgpq4mdieexsZOjayg2nrufgzPU79RZX17OLUa5Sw8FWBn83+2ZMSURERERkOkQrrsrLy3H27FksWrRIe0wqlWLw4ME4ceJErffp27cvtm/fjlOnTqFXr15ITEzETz/9hMmTJ2vP+eGHHzBs2DA888wzOHr0KPz9/TFr1izMmDGjzixlZWUoKyvTfp2fX9khT6lUQqlU3u9TvS+axxcjR/fWrjh1PQcxSbcxpqtvnZmupOYCAEK8HKFSVUClavaoteYyBcykH2bSDzPph5n0w0z6McVMgGnmYib9MJN+TCmTIRkkgj4LappAamoq/P39cfz4cfTp00d7fMGCBTh69KjOaFR1K1euxGuvvQZBEFBRUYGXXnoJa9eu1d6uUCgAAPPnz8czzzyD06dPY+7cuVi3bh2mTp1a6zWXLl2KZcuW1Ti+c+dOODhY755Nf9+RYMNVGbwUAhZ3q7ti2n9TguhbMvTyUuPZEP32xSIiIiIiMgfFxcWYOHEi8vLy4OLiUu+5ok4LNNSRI0fw/vvvY82aNYiMjERCQgLmzp2Ld999F2+99RYAQK1Wo0ePHnj//fcBAN26dcOlS5fqLa4WLVqE+fPna7/Oz89HQEAAhg4d2uAL2NSUSiUOHjyIIUOGQC6XN+tj9ytRYuPyX5FVKkGvgY/A08mu1kzRX10EbmXg4YgOGNkvsFkzVifma1UXZtIPM+mHmfTDTPphJv2YYibANHMxk36YST+mlEkzq00fohVXnp6ekMlkyMjI0DmekZEBX1/fWu/z1ltvYfLkyXj++ecBAJ06dUJRURFeeOEFvPnmm5BKpfDz80NYWJjO/R544AF88803dWaxs7ODnZ1djeNyuVz0b6aGGFk85XK093HG1fQCXEwpwPBw3XVXmkwJVc0sOvi5msTrZUrfNw1m0g8z6YeZ9MNM+mEm/ZhiJsA0czGTfphJP6aQyZDHF60Vu62tLSIiInDo0CHtMbVajUOHDulME6yuuLgYUqluZJlMBgDaduH9+vVDbGyszjlxcXFo06aNMeNbjR5VLdlPX79T6+3lFWok3WanQCIiIiIiUfe5mj9/PjZu3IitW7fiypUrmDlzJoqKirTdA6dMmaLT8GLUqFFYu3YtvvrqKyQlJeHgwYN46623MGrUKG2R9eqrr+LkyZN4//33kZCQgJ07d2LDhg2YPXu2KM/R3PWs2kz4TB2bCSfdLkKFWoCznQ38XBXNGY2IiIiIyKSIuuZq3LhxyMrKwttvv4309HR07doV0dHR8PHxAQAkJyfrjFQtXrwYEokEixcvRkpKCry8vDBq1Ci899572nN69uyJb7/9FosWLcI777yDoKAgrFixAs8++2yzPz9L0KOquLqUmo/i8go42Oq+ZWKrNg8O9XGCRCJp9nxERERERKZC9IYWc+bMwZw5c2q97ciRIzpf29jYYMmSJViyZEm913zsscfw2GOPGSuiVfN3s0dLVwVS80pxITkXfUM8dW6Pryqu2vtySiARERERWTdRpwWSedCMXtW27ipOM3LlzeKKiIiIiKwbiytqUM+qphZnbtRcdxWXUQiAzSyIiIiIiFhcUYM0I1fnbtxBheruJsFlShVuZFd1CvR1qvW+RERERETWgsUVNaidjzOcFTYoKlfhanqB9vi120VQC4CbgxxeTjX3CSMiIiIisiYsrqhBMqkEEW00+13dnRoYr5kS6O3MToFEREREZPVYXJFe7u53dbepRXwmpwQSEREREWmwuCK99Kg2ciUIAgAgPpPNLIiIiIiINFhckV66BLhBLpMgs6AMN++UAADiqoortmEnIiIiImJxRXpSyGXo5O8KADh7IxdlKuBWVZHVzofTAomIiIiIWFyR3jTrrs4m30F6ZV0FTydbeLBTIBERERERiyvSn2a/qzM3cpFeXNkdkOutiIiIiIgq2YgdgMyHph37tawieIDFFRERERFRdRy5Ir25O9oixLtyfdX57MriKpTrrYiIiIiIALC4IgNFtHEDACjVlcVViBeLKyIiIiIigMUVGSD6UhqiL2XoHHvlq/OIvpQmUiIiIiIiItPB4or0En0pDTO3n0NeiVLneGZ+GWZuP8cCi4iIiIisHosrapBKLWDZvssQarlNc2zZvstQqWs7g4iIiIjIOrC4ogadSspBWl5pnbcLANLySnEqKaf5QhERERERmRgWV9SgzIK6C6vGnEdEREREZIlYXFGDvJ0VRj2PiIiIiMgSsbiiBvUKcoefq6Jq2+CaJAD8XBXoFeTenLGIiIiIiEwKiytqkEwqwZJRYQBQo8DSfL1kVBhk0rrKLyIiIiIiy8fiivQyPNwPayd1h6+r7tQ/X1cF1k7qjuHhfiIlIyIiIiIyDTZiByDzMTzcD0PCfHEiIRM/H4vB0AGR6BPizRErIiIiIiKwuCIDyaQSRAa5I/uKgMggdxZWRERERERVOC2QiIiIiIjICFhcERERERERGQGLKyIiIiIiIiNgcUVERERERGQELK6IiIiIiIiMgMUVERERERGREbC4IiIiIiIiMgIWV0REREREREbA4oqIiIiIiMgIWFwREREREREZAYsrIiIiIiIiI2BxRUREREREZAQsroiIiIiIiIzARuwApkgQBABAfn6+yEkApVKJ4uJi5OfnQy6Xix0HgGlmAkwzFzPph5n0w0z6YSb9MJN+TDETYJq5mEk/zKQfU8qkqQk0NUJ9WFzVoqCgAAAQEBAgchIiIiIiIjIFBQUFcHV1rfcciaBPCWZl1Go1UlNT4ezsDIlEImqW/Px8BAQE4ObNm3BxcRE1i4YpZgJMMxcz6YeZ9MNM+mEm/TCTfkwxE2CauZhJP8ykH1PKJAgCCgoK0LJlS0il9a+q4shVLaRSKVq1aiV2DB0uLi6iv7HuZYqZANPMxUz6YSb9MJN+mEk/zKQfU8wEmGYuZtIPM+nHVDI1NGKlwYYWRERERERERsDiioiIiIiIyAhYXJk4Ozs7LFmyBHZ2dmJH0TLFTIBp5mIm/TCTfphJP8ykH2bSjylmAkwzFzPph5n0Y4qZ9MGGFkREREREREbAkSsiIiIiIiIjYHFFRERERERkBCyuiIiIiIiIjIDFFRERERERkRGwuDJhv/32G0aNGoWW/9/evcfFnO9xHH+PamoqdL+MtolKkUro0MW90+U4XXDcTuuU2MXWKpe2dWxyOCjrbjuRtbkdl3UeSuxDbWxahSSGIql03EqWLeSyauZ7/vBojqkoVN/O8Xk+HvN4NL/5NfPqR9/mO7/f/EYshkAgQEpKCteelStXwtnZGV27doWRkRECAgJQXFzMtSkhIQEODg6KD5hzcXHB0aNHuTY1FhsbC4FAgIiICG4NS5YsgUAgULrY2tpy62lw584dfPzxx9DX14dIJIK9vT3OnTvHtcnCwqLJthIIBAgNDeXWJJPJEB0djZ49e0IkEsHS0hLLli0Dz/MRPX78GBEREZBIJBCJRHB1dUVeXl6HNrQ0RjLGsHjxYpiamkIkEsHDwwMlJSVcmw4ePAhPT0/o6+tDIBBAKpW2a09LTXV1dYiKioK9vT20tLQgFovxl7/8BRUVFdyagJdjlq2tLbS0tKCrqwsPDw/k5uZybXrVrFmzIBAIsH79eq5NwcHBTcYqb29vrk0AUFRUBD8/P3Tv3h1aWlpwdnbGzZs3uTU1N6YLBAJ8/fXX3Jpqa2sRFhYGMzMziEQi9O3bF5s3b263ntZ2VVVVITg4GGKxGJqamvD29m7XcbM1zy2fP3+O0NBQ6OvrQ1tbG+PHj0dVVVW7Nb0vmlx1Yk+ePIGjoyPi4+N5pwAAsrKyEBoaijNnziAjIwN1dXXw9PTEkydPuDWZmZkhNjYW+fn5OHfuHEaNGgV/f39cvnyZW9Or8vLysGXLFjg4OPBOgZ2dHSorKxWX7Oxsrj3V1dVwc3ODmpoajh49iitXrmDNmjXQ1dXl2pWXl6e0nTIyMgAAEyZM4NYUFxeHhIQEfPPNNygqKkJcXBxWrVqFTZs2cWuaMWMGMjIysGvXLhQUFMDT0xMeHh64c+dOhzW0NEauWrUKGzduxObNm5GbmwstLS14eXnh+fPn3JqePHkCd3d3xMXFtVvD2zQ9ffoU58+fR3R0NM6fP4+DBw+iuLgYfn5+3JoAoHfv3vjmm29QUFCA7OxsWFhYwNPTE7/88gu3pgbJyck4c+YMxGJxu7W8TZO3t7fSmLV3716uTWVlZXB3d4etrS1OnDiBS5cuITo6GhoaGtyaXt0+lZWV+O677yAQCDB+/HhuTfPmzUNaWhp2796NoqIiREREICwsDKmpqe3W1FIXYwwBAQG4fv06Dh06hAsXLkAikcDDw6Pdnuu15rnl3LlzcfjwYRw4cABZWVmoqKjAuHHj2qWnTTDyPwEAS05O5p2h5N69ewwAy8rK4p2iRFdXl3377be8M9jjx4+ZtbU1y8jIYMOHD2fh4eHcWmJiYpijoyO3x29OVFQUc3d3553RovDwcGZpacnkcjm3hjFjxrCQkBClZePGjWOBgYFcep4+fcpUVFTYkSNHlJYPGDCALVq0iEtT4zFSLpczExMT9vXXXyuW1dTUMHV1dbZ3714uTa8qLy9nANiFCxc6pKU1TQ3Onj3LALAbN250mqaHDx8yAOzYsWNcm27fvs169OjBCgsLmUQiYevWreuQntc1BQUFMX9//w5raKy5pkmTJrGPP/6YTxBr3f8nf39/NmrUqI4JYs032dnZsaVLlyot6+gxtHFXcXExA8AKCwsVy2QyGTM0NGRbt27tkKbGzy1ramqYmpoaO3DggGKdoqIiBoCdPn26Q5reFu25Iu/s4cOHAAA9PT3OJS/JZDLs27cPT548gYuLC+8chIaGYsyYMfDw8OCdAgAoKSmBWCxGr169EBgY2K6HaLRGamoqBg0ahAkTJsDIyAhOTk7YunUr16bGXrx4gd27dyMkJAQCgYBbh6urK44fP45r164BAC5evIjs7Gz4+Phw6amvr4dMJmvySrRIJOK+R7RBeXk57t69q/T71717dwwePBinT5/mWNb5PXz4EAKBADo6OrxTALz8PUxMTET37t3h6OjIrUMul2Pq1KmIjIyEnZ0dt47GTpw4ASMjI9jY2GD27Nl48OABtxa5XI4ffvgBvXv3hpeXF4yMjDB48GDub2t4VVVVFX744QdMnz6da4erqytSU1Nx584dMMaQmZmJa9euwdPTk1vTb7/9BgBKY3uXLl2grq7eYWN74+eW+fn5qKurUxrLbW1tYW5u3mnHcppckXcil8sREREBNzc39OvXj2tLQUEBtLW1oa6ujlmzZiE5ORl9+/bl2rRv3z6cP38eK1eu5NrRYPDgwdi+fTvS0tKQkJCA8vJyDB06FI8fP+bWdP36dSQkJMDa2hrp6emYPXs25syZgx07dnBraiwlJQU1NTUIDg7m2vHll19i8uTJsLW1hZqaGpycnBAREYHAwEAuPV27doWLiwuWLVuGiooKyGQy7N69G6dPn0ZlZSWXpsbu3r0LADA2NlZabmxsrLiNNPX8+XNERUVhypQp6NatG9eWI0eOQFtbGxoaGli3bh0yMjJgYGDArScuLg6qqqqYM2cOt4bGvL29sXPnThw/fhxxcXHIysqCj48PZDIZl5579+6htrYWsbGx8Pb2xo8//oixY8di3LhxyMrK4tLU2I4dO9C1a1fuh5Vt2rQJffv2hZmZGYRCIby9vREfH49hw4Zxa2qYtCxcuBDV1dV48eIF4uLicPv27Q4Z25t7bnn37l0IhcImL/Z05rFclXcA+d8UGhqKwsLCTvEqtY2NDaRSKR4+fIh//etfCAoKQlZWFrcJ1q1btxAeHo6MjIx2Pcb8bby6h8PBwQGDBw+GRCLB999/z+3VO7lcjkGDBmHFihUAACcnJxQWFmLz5s0ICgri0tTYtm3b4OPj0yHvrXiT77//Hv/85z+xZ88e2NnZQSqVIiIiAmKxmNu22rVrF0JCQtCjRw+oqKhgwIABmDJlCvLz87n0kPdXV1eHiRMngjGGhIQE3jkYOXIkpFIp7t+/j61bt2LixInIzc2FkZFRh7fk5+djw4YNOH/+PNe92I1NnjxZ8bW9vT0cHBxgaWmJEydOYPTo0R3eI5fLAQD+/v6YO3cuAKB///44deoUNm/ejOHDh3d4U2PfffcdAgMDuf993rRpE86cOYPU1FRIJBL8/PPPCA0NhVgs5nbEi5qaGg4ePIjp06dDT08PKioq8PDwgI+PT4ecQKkzPbd8H7Tniry1sLAwHDlyBJmZmTAzM+OdA6FQCCsrKwwcOBArV66Eo6MjNmzYwK0nPz8f9+7dw4ABA6CqqgpVVVVkZWVh48aNUFVV5faK4qt0dHTQu3dvlJaWcmswNTVtMgHu06cP98MVG9y4cQPHjh3DjBkzeKcgMjJSsffK3t4eU6dOxdy5c7nuGbW0tERWVhZqa2tx69YtnD17FnV1dejVqxe3pleZmJgAQJMzSlVVVSluI//VMLG6ceMGMjIyuO+1AgAtLS1YWVlhyJAh2LZtG1RVVbFt2zYuLSdPnsS9e/dgbm6uGNdv3LiB+fPnw8LCgktTc3r16gUDAwNuY7uBgQFUVVU77dh+8uRJFBcXcx/Xnz17hr/+9a9Yu3YtfH194eDggLCwMEyaNAmrV6/m2jZw4EBIpVLU1NSgsrISaWlpePDgQbuP7a97bmliYoIXL16gpqZGaf3OPJbT5Iq0GmMMYWFhSE5Oxk8//YSePXvyTmqWXC5XHDfMw+jRo1FQUACpVKq4DBo0CIGBgZBKpVBRUeHW1qC2thZlZWUwNTXl1uDm5tbkdKvXrl2DRCLhVKQsKSkJRkZGGDNmDO8UPH36FF26KA/XKioqileJedLS0oKpqSmqq6uRnp4Of39/3kkAgJ49e8LExATHjx9XLHv06BFyc3M7xXsyO5OGiVVJSQmOHTsGfX193knN4jm2T506FZcuXVIa18ViMSIjI5Gens6lqTm3b9/GgwcPuI3tQqEQzs7OnXZs37ZtGwYOHMj1vXvAy9+5urq6TjuuAy/fo2poaIiSkhKcO3eu3cb2lp5bDhw4EGpqakpjeXFxMW7evNlpx3I6LLATq62tVXr1qby8HFKpFHp6ejA3N+/wntDQUOzZsweHDh1C165dFce6du/eHSKRqMN7AGDhwoXw8fGBubk5Hj9+jD179uDEiRNc/9h17dq1yfvQtLS0oK+vz+39aQsWLICvry8kEgkqKioQExMDFRUVTJkyhUsP8PLUqq6urlixYgUmTpyIs2fPIjExEYmJidyaGsjlciQlJSEoKAiqqvyHSV9fXyxfvhzm5uaws7PDhQsXsHbtWoSEhHBrSk9PB2MMNjY2KC0tRWRkJGxtbTFt2rQOa2hpjIyIiMDf//53WFtbo2fPnoiOjoZYLEZAQAC3pl9//RU3b95UfI5Uw5NQExOTdnsV9k1Npqam+NOf/oTz58/jyJEjkMlkirFdT08PQqGww5v09fWxfPly+Pn5wdTUFPfv30d8fDzu3LnTrh+J0NK/XeNJp5qaGkxMTGBjY8OlSU9PD3/7298wfvx4mJiYoKysDF988QWsrKzg5eXFpcnc3ByRkZGYNGkShg0bhpEjRyItLQ2HDx/GiRMnuDUBL19cOXDgANasWdNuHW/TNHz4cERGRkIkEkEikSArKws7d+7E2rVruXYdOHAAhoaGMDc3R0FBAcLDwxEQENBuJ9po6bll9+7dMX36dMybNw96enro1q0bPv/8c7i4uGDIkCHt0vTeeJ6qkLxZZmYmA9DkEhQUxKWnuRYALCkpiUsPY4yFhIQwiUTChEIhMzQ0ZKNHj2Y//vgjt57X4X0q9kmTJjFTU1MmFApZjx492KRJk1hpaSm3ngaHDx9m/fr1Y+rq6szW1pYlJibyTmKMMZaens4AsOLiYt4pjDHGHj16xMLDw5m5uTnT0NBgvXr1YosWLWK//fYbt6b9+/ezXr16MaFQyExMTFhoaCirqanp0IaWxki5XM6io6OZsbExU1dXZ6NHj273f9OWmpKSkpq9PSYmhktTwynhm7tkZmZyaXr27BkbO3YsE4vFTCgUMlNTU+bn58fOnj3bbj0tNTWnI07F/qamp0+fMk9PT2ZoaMjU1NSYRCJhn3zyCbt79y63pgbbtm1jVlZWTENDgzk6OrKUlBTuTVu2bGEikajDxqmWmiorK1lwcDATi8VMQ0OD2djYsDVr1rT7x3601LVhwwZmZmbG1NTUmLm5Ofvqq6/a9W9Na55bPnv2jH322WdMV1eXaWpqsrFjx7LKysp2a3pfAsY64B1qhBBCCCGEEPJ/jt5zRQghhBBCCCFtgCZXhBBCCCGEENIGaHJFCCGEEEIIIW2AJleEEEIIIYQQ0gZockUIIYQQQgghbYAmV4QQQgghhBDSBmhyRQghhBBCCCFtgCZXhBBCCCGEENIGaHJFCCGEi3//+98QCASQSqW8UxSuXr2KIUOGQENDA/3792/3x7OwsMD69etbvX5rttn27duho6Pz3m2EEELeHk2uCCHkAxUcHAyBQIDY2Fil5SkpKRAIBJyq+IqJiYGWlhaKi4tx/PjxZtdpy+2Wl5eHTz/99J17CSGEdC40uSKEkA+YhoYG4uLiUF1dzTulzbx48eKdv7esrAzu7u6QSCTQ19d/7Xpttd0MDQ2hqan5XvfRUerq6ngnEEJIp0eTK0II+YB5eHjAxMQEK1eufO06S5YsaXKI3Pr162FhYaG4HhwcjICAAKxYsQLGxsbQ0dHB0qVLUV9fj8jISOjp6cHMzAxJSUlN7v/q1atwdXWFhoYG+vXrh6ysLKXbCwsL4ePjA21tbRgbG2Pq1Km4f/++4vYRI0YgLCwMERERMDAwgJeXV7M/h1wux9KlS2FmZgZ1dXX0798faWlpitsFAgHy8/OxdOlSCAQCLFmy5L22GwBkZ2dj6NChEIlE+OijjzBnzhw8efJEcXvjwwKvXr0Kd3d3aGhooG/fvjh27BgEAgFSUlKU7vf69esYOXIkNDU14ejoiNOnTzd57JSUFFhbW0NDQwNeXl64deuW0u0JCQmwtLSEUCiEjY0Ndu3apXS7QCBAQkIC/Pz8oKWlheXLl6O6uhqBgYEwNDSESCSCtbV1s/+mhBDyoaLJFSGEfMBUVFSwYsUKbNq0Cbdv336v+/rpp59QUVGBn3/+GWvXrkVMTAz++Mc/QldXF7m5uZg1axZmzpzZ5HEiIyMxf/58XLhwAS4uLvD19cWDBw8AADU1NRg1ahScnJxw7tw5pKWloaqqChMnTlS6jx07dkAoFCInJwebN29utm/Dhg1Ys2YNVq9ejUuXLsHLywt+fn4oKSkBAFRWVsLOzg7z589HZWUlFixY8NqftTXbraysDN7e3hg/fjwuXbqE/fv3Izs7G2FhYc2uL5PJEBAQAE1NTeTm5iIxMRGLFi1qdt1FixZhwYIFkEql6N27N6ZMmYL6+nrF7U+fPsXy5cuxc+dO5OTkoKamBpMnT1bcnpycjPDwcMyfPx+FhYWYOXMmpk2bhszMTKXHWbJkCcaOHYuCggKEhIQgOjoaV65cwdGjR1FUVISEhAQYGBi8djsRQsgHhxFCCPkgBQUFMX9/f8YYY0OGDGEhISGMMcaSk5PZq38eYmJimKOjo9L3rlu3jkkkEqX7kkgkTCaTKZbZ2NiwoUOHKq7X19czLS0ttnfvXsYYY+Xl5QwAi42NVaxTV1fHzMzMWFxcHGOMsWXLljFPT0+lx7516xYDwIqLixljjA0fPpw5OTm1+POKxWK2fPlypWXOzs7ss88+U1x3dHRkMTExb7yf1m636dOns08//VTpe0+ePMm6dOnCnj17xhhjTCKRsHXr1jHGGDt69ChTVVVllZWVivUzMjIYAJacnMwY++82+/bbbxXrXL58mQFgRUVFjDHGkpKSGAB25swZxTpFRUUMAMvNzWWMMebq6so++eQTpbYJEyawP/zhD4rrAFhERITSOr6+vmzatGlv3D6EEPIhoz1XhBBCEBcXhx07dqCoqOid78POzg5duvz3z4qxsTHs7e0V11VUVKCvr4979+4pfZ+Li4via1VVVQwaNEjRcfHiRWRmZkJbW1txsbW1BfByz1CDgQMHvrHt0aNHqKiogJubm9JyNze39/qZ37TdLl68iO3btyu1e3l5QS6Xo7y8vMn6xcXF+Oijj2BiYqJY9rvf/a7Zx3VwcFB8bWpqCgBK21VVVRXOzs6K67a2ttDR0VF0FhUVtWpbDBo0SOn67NmzsW/fPvTv3x9ffPEFTp061WwfIYR8qGhyRQghBMOGDYOXlxcWLlzY5LYuXbqAMaa0rLmTG6ipqSldFwgEzS6Ty+Wt7qqtrYWvry+kUqnSpaSkBMOGDVOsp6Wl1er7bEtv2m61tbWYOXOmUvfFixdRUlICS0vL93rcV7drwxkK32a7tlbj7erj44MbN25g7ty5qKiowOjRo994+CQhhHxoaHJFCCEEABAbG4vDhw83OTmCoaEh7t69qzTBasvPpjpz5ozi6/r6euTn56NPnz4AgAEDBuDy5cuwsLCAlZWV0uVtJlTdunWDWCxGTk6O0vKcnBz07dv3vfpft90GDBiAK1euNOm2srKCUChscj82Nja4desWqqqqFMvy8vLeqam+vh7nzp1TXC8uLkZNTY1iu/bp0+edt4WhoSGCgoKwe/durF+/HomJie/USAgh/49ockUIIQQAYG9vj8DAQGzcuFFp+YgRI/DLL79g1apVKCsrQ3x8PI4ePdpmjxsfH4/k5GRcvXoVoaGhqK6uRkhICAAgNDQUv/76K6ZMmYK8vDyUlZUhPT0d06ZNg0wme6vHiYyMRFxcHPbv34/i4mJ8+eWXkEqlCA8Pf6/+1223qKgonDp1CmFhYYq9bYcOHXrtCS1+//vfw9LSEkFBQbh06RJycnLw1VdfAcBbf36WmpoaPv/8c+Tm5iI/Px/BwcEYMmSI4jDDyMhIbN++HQkJCSgpKcHatWtx8ODBFvdCLV68GIcOHUJpaSkuX76MI0eOKCZshBBCaHJFCCHkFUuXLm1yeFmfPn3wj3/8A/Hx8XB0dMTZs2fb9FCw2NhYxMbGwtHREdnZ2UhNTVWcga5hb5NMJoOnpyfs7e0REREBHR0dpfd3tcacOXMwb948zJ8/H/b29khLS0Nqaiqsra3f+2dobrs5ODggKysL165dw9ChQ+Hk5ITFixdDLBY3ex8qKipISUlBbW0tnJ2dMWPGDMXZAjU0NN6qR1NTE1FRUfjzn/8MNzc3aGtrY//+/YrbAwICsGHDBqxevRp2dnbYsmULkpKSMGLEiDfer1AoxMKFC+Hg4IBhw4ZBRUUF+/bte6s2Qgj5fyZgjQ+kJ4QQQkinkJOTA3d3d5SWlr73+7QIIYS0P5pcEUIIIZ1EcnIytLW1YW1tjdLSUoSHh0NXVxfZ2dm80wghhLSCKu8AQgghhLz0+PFjREVF4ebNmzAwMICHhwfWrFnDO4sQQkgr0Z4rQgghhBBCCGkDdEILQgghhBBCCGkDNLkihBBCCCGEkDZAkytCCCGEEEIIaQM0uSKEEEIIIYSQNkCTK0IIIYQQQghpAzS5IoQQQgghhJA2QJMrQgghhBBCCGkDNLkihBBCCCGEkDbwH+2cyQijOVRPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\archive\\\\Toddler Autism dataset July 2018.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [12, 13, 14, 15, 16]]\n",
    "\n",
    "# Drop categorical columns\n",
    "features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define KNN classifier\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=1, weights='uniform', algorithm='auto', p=2, n_jobs=None)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=200, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and KNN classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=69)\n",
    "\n",
    "# Define range of values for n_neighbors\n",
    "neighbors = range(1, 21)\n",
    "mean_cv_scores = []\n",
    "\n",
    "# Calculate mean cross-validation accuracy for different values of n_neighbors\n",
    "for n_neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(metric='euclidean', n_neighbors=n_neighbor, weights='uniform', algorithm='auto', p=2, n_jobs=None)\n",
    "    pipeline_cv.steps[-1] = ('classifier', knn)  # Update classifier in pipeline\n",
    "    cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    mean_cv_scores.append(np.mean(cv_scores))\n",
    "\n",
    "# Plotting the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(neighbors, mean_cv_scores, marker='o')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Mean CV Accuracy')\n",
    "plt.title('Elbow Curve for Optimum Number of Neighbors')\n",
    "plt.grid(True)\n",
    "plt.xticks(neighbors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2195aa05-c2a9-45cc-bfb8-02f644c6c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1_Score      int64\n",
      "A2_Score      int64\n",
      "A3_Score      int64\n",
      "A4_Score      int64\n",
      "A5_Score      int64\n",
      "A6_Score      int64\n",
      "A7_Score      int64\n",
      "A8_Score      int64\n",
      "A9_Score      int64\n",
      "A10_Score     int64\n",
      "age          object\n",
      "result        int64\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"?\" at position 62",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\lib.pyx:2280\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"?\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#converting object to int64\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m features\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Fill missing values with mean\u001b[39;00m\n\u001b[0;32m     34\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mfillna(features\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\tools\\numeric.py:217\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    215\u001b[0m coerce_numeric \u001b[38;5;241m=\u001b[39m errors \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 217\u001b[0m     values, new_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]  # noqa\u001b[39;49;00m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\_libs\\lib.pyx:2322\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"?\" at position 62"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sem 6\\\\Mini Project\\\\csv_result-Autism-Adult-Data.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "features = df.iloc[:, :-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Select categorical features\n",
    "category_features = features.iloc[:, [11, 12, 13, 14, 15, 16, 18, 19]]\n",
    "\n",
    "# Drop categorical columns\n",
    "# List of column indices to remove\n",
    "columns_to_remove = [11, 12, 13, 14, 15, 16, 18, 19]\n",
    "\n",
    "# Drop the columns\n",
    "features.drop(features.columns[columns_to_remove], axis=1, inplace=True)\n",
    "# features.drop(features.columns[-6:], axis=1, inplace=True)\n",
    "print(features.dtypes)\n",
    "#converting object to int64\n",
    "features.iloc[:, 0] = pd.to_numeric(features.iloc[:, 10])\n",
    "# Fill missing values with mean\n",
    "features = features.fillna(features.mean())\n",
    "\n",
    "# One Hot Encoding without changing column names\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "category_transformed = enc.fit_transform(category_features)\n",
    "category_encoded_columns = enc.get_feature_names_out(category_features.columns)\n",
    "transformed_df = pd.DataFrame(category_transformed, columns=category_encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "result_df = pd.concat([features, transformed_df], axis=1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define AdaBoost classifier with a decision tree base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=2),n_estimators=64,learning_rate=0.5,algorithm='SAMME.R',random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('quantile', QuantileTransformer(n_quantiles=10, random_state=42))\n",
    "        ]), ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons']),\n",
    "        ('cat', Pipeline([\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ]), transformed_df.columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through any other columns without transformation\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for training with cross-validation\n",
    "pipeline_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation on training set\n",
    "cv_scores = cross_val_score(pipeline_cv, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the entire training set\n",
    "pipeline_cv.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_cv = pipeline_cv.predict(X_test)\n",
    "test_accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
    "print(\"Testing Set Accuracy with cross-validation:\", test_accuracy_cv)\n",
    "\n",
    "# Create pipeline with preprocessing and AdaBoost classifier for testing without cross-validation\n",
    "pipeline_test = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ada_boost)\n",
    "])\n",
    "\n",
    "# Train the model on the entire training set without cross-validation\n",
    "pipeline_test.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the separate testing set\n",
    "y_pred_test = pipeline_test.predict(X_test)\n",
    "test_accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Testing Set Accuracy without cross-validation:\", test_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b4dee-9101-43d3-ad0f-efaf8601f187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
